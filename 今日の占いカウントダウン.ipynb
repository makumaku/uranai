{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "今日の占いカウントダウン.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makumaku/uranai/blob/master/%E4%BB%8A%E6%97%A5%E3%81%AE%E5%8D%A0%E3%81%84%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%83%80%E3%82%A6%E3%83%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt_QoQM54hC0",
        "colab_type": "code",
        "outputId": "23e497a0-d64b-47f9-f15a-b422e37f1066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# グラフ表示のために必要\n",
        "!rm /root/.cache/matplotlib/fontlist-v300.json\n",
        "!apt-get -y install fonts-ipafont-gothic\n",
        "# ランタイムを再起動すること。"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-ipafont-mincho\n",
            "The following NEW packages will be installed:\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "0 upgraded, 2 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 8,251 kB of archives.\n",
            "After this operation, 28.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-ipafont-gothic all 00303-18ubuntu1 [3,526 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-ipafont-mincho all 00303-18ubuntu1 [4,725 kB]\n",
            "Fetched 8,251 kB in 1s (7,483 kB/s)\n",
            "Selecting previously unselected package fonts-ipafont-gothic.\n",
            "(Reading database ... 130942 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-ipafont-gothic_00303-18ubuntu1_all.deb ...\n",
            "Unpacking fonts-ipafont-gothic (00303-18ubuntu1) ...\n",
            "Selecting previously unselected package fonts-ipafont-mincho.\n",
            "Preparing to unpack .../fonts-ipafont-mincho_00303-18ubuntu1_all.deb ...\n",
            "Unpacking fonts-ipafont-mincho (00303-18ubuntu1) ...\n",
            "Setting up fonts-ipafont-gothic (00303-18ubuntu1) ...\n",
            "update-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\n",
            "Setting up fonts-ipafont-mincho (00303-18ubuntu1) ...\n",
            "update-alternatives: using /usr/share/fonts/opentype/ipafont-mincho/ipam.ttf to provide /usr/share/fonts/truetype/fonts-japanese-mincho.ttf (fonts-japanese-mincho.ttf) in auto mode\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25QtGr5z3uZC",
        "colab_type": "code",
        "outputId": "79b03af6-f1cd-4166-85d5-1c15ce3592da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# google driveへマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMJakmCmNWBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "#print(os.listdir(\"../alexander_999_taku\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7vpE4v71NZd",
        "colab_type": "code",
        "outputId": "5778130d-eb53-472d-ef99-246b0e9ae006",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "# PC上のデータをアップロード\n",
        "# データは毎日エクセルで更新した情報をアップロード\n",
        "# 動作が不安定になったが、二回実行すると動くので一旦放置\n",
        "# 動かなくなれば、ドライブをマウントする方法へ変更\n",
        "# やりたいことによってアップロード対象が異なるため注意\n",
        "# モデル予想時： data274.csv,data275.csvなどのデータ\n",
        "# 分析時：countdown_num.csv,countdown_raw.csv\n",
        "from google.colab import files\n",
        "f=files.upload()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-299363c7-60a4-4591-adca-4936ef89c5c5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-299363c7-60a4-4591-adca-4936ef89c5c5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving countdown_raw.csv to countdown_raw.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhc9zhOSmXdV",
        "colab_type": "text"
      },
      "source": [
        "ここからモデル予想"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-rhbvW8Lbso",
        "colab_type": "code",
        "outputId": "d3c4cbe9-7be2-47d6-f171-dc8ac7f05090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "# アップロードしたデータを読みこむ\n",
        "# dataの名称は都度変更すること\n",
        "data = pd.read_csv(\"data274.csv\", encoding=\"shift-jis\", engine = \"python\")\n",
        "data_predict_test = pd.read_csv(\"data275.csv\", encoding=\"shift-jis\", engine = \"python\")\n",
        "\n",
        "# 順序性による悪影響を受けないようにするため、シャッフルを実施。\n",
        "data = data.sample(frac=1, random_state=0)\n",
        "# 項番の再抽出が必要になる場合に備えるため項番を残しつつ、インデックスの振り直しをする。\n",
        "data = data.reset_index()\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>項番</th>\n",
              "      <th>年</th>\n",
              "      <th>月</th>\n",
              "      <th>日</th>\n",
              "      <th>牡牛座3日1位数</th>\n",
              "      <th>牡牛座7日1位数</th>\n",
              "      <th>牡牛座30日1位数</th>\n",
              "      <th>牡牛座365日1位数</th>\n",
              "      <th>牡牛座3日成績</th>\n",
              "      <th>牡牛座7日成績</th>\n",
              "      <th>牡牛座30日成績</th>\n",
              "      <th>牡牛座1日成績</th>\n",
              "      <th>牡牛座_絶対値_前日-前々日</th>\n",
              "      <th>牡牛座_+-_前日-前々日</th>\n",
              "      <th>牡牛_3日_EMA</th>\n",
              "      <th>牡牛_7日_EMA</th>\n",
              "      <th>牡牛_30日_EMA</th>\n",
              "      <th>牡羊座3日1位数</th>\n",
              "      <th>牡羊座7日1位数</th>\n",
              "      <th>牡羊座30日1位数</th>\n",
              "      <th>牡羊座365日1位数</th>\n",
              "      <th>牡羊座3日成績</th>\n",
              "      <th>牡羊座7日成績</th>\n",
              "      <th>牡羊座30日成績</th>\n",
              "      <th>牡羊座前日成績</th>\n",
              "      <th>牡羊座_絶対値_前日-前々日</th>\n",
              "      <th>牡羊座_+-_前日-前々日</th>\n",
              "      <th>牡羊_3日_EMA</th>\n",
              "      <th>牡羊_7日_EMA</th>\n",
              "      <th>牡羊_30日_EMA</th>\n",
              "      <th>乙女座3日1位数</th>\n",
              "      <th>乙女座7日1位数</th>\n",
              "      <th>乙女座30日1位数</th>\n",
              "      <th>乙女座365日1位数</th>\n",
              "      <th>乙女座3日成績</th>\n",
              "      <th>乙女座7日成績</th>\n",
              "      <th>乙女座30日成績</th>\n",
              "      <th>乙女座前日成績</th>\n",
              "      <th>乙女座_絶対値_前日-前々日</th>\n",
              "      <th>...</th>\n",
              "      <th>火の属性_30日_EMA</th>\n",
              "      <th>土の属性3日1位数</th>\n",
              "      <th>土の属性7日1位数</th>\n",
              "      <th>土の属性30日1位数</th>\n",
              "      <th>土の属性365日1位数</th>\n",
              "      <th>土の属性3日成績</th>\n",
              "      <th>土の属性7日成績</th>\n",
              "      <th>土の属性30日成績</th>\n",
              "      <th>土の属性前日成績</th>\n",
              "      <th>土の属性3日_EMA</th>\n",
              "      <th>土の属性_7日_EMA</th>\n",
              "      <th>土の属性_30日_EMA</th>\n",
              "      <th>風の属性3日1位数</th>\n",
              "      <th>風の属性7日1位数</th>\n",
              "      <th>風の属性30日1位数</th>\n",
              "      <th>風の属性365日1位数</th>\n",
              "      <th>風の属性3日成績</th>\n",
              "      <th>風の属性7日成績</th>\n",
              "      <th>風の属性30日成績</th>\n",
              "      <th>風の属性前日成績</th>\n",
              "      <th>風の属性3日_EMA</th>\n",
              "      <th>風の属性_7日_EMA</th>\n",
              "      <th>風の属性_30日_EMA</th>\n",
              "      <th>水の属性3日1位数</th>\n",
              "      <th>水の属性7日1位数</th>\n",
              "      <th>水の属性30日1位数</th>\n",
              "      <th>水の属性365日1位数</th>\n",
              "      <th>水の属性3日成績</th>\n",
              "      <th>水の属性7日成績</th>\n",
              "      <th>水の属性30日成績</th>\n",
              "      <th>水の属性前日成績</th>\n",
              "      <th>水の属性3日_EMA</th>\n",
              "      <th>水の属性_7日_EMA</th>\n",
              "      <th>水の属性_30日_EMA</th>\n",
              "      <th>月星座</th>\n",
              "      <th>月星座同属性1</th>\n",
              "      <th>月星座同属性2</th>\n",
              "      <th>星座</th>\n",
              "      <th>当日の回答</th>\n",
              "      <th>星座.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1946</td>\n",
              "      <td>1946</td>\n",
              "      <td>2012</td>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>40</td>\n",
              "      <td>183</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>8.280271</td>\n",
              "      <td>6.997433</td>\n",
              "      <td>6.100000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>51</td>\n",
              "      <td>194</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7.093548</td>\n",
              "      <td>6.968038</td>\n",
              "      <td>6.466667</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>43</td>\n",
              "      <td>188</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>19.633333</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>55</td>\n",
              "      <td>123</td>\n",
              "      <td>573</td>\n",
              "      <td>30</td>\n",
              "      <td>22.999394</td>\n",
              "      <td>20.787327</td>\n",
              "      <td>19.100000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>65</td>\n",
              "      <td>133</td>\n",
              "      <td>564</td>\n",
              "      <td>9</td>\n",
              "      <td>16.706667</td>\n",
              "      <td>17.760057</td>\n",
              "      <td>18.800000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>132</td>\n",
              "      <td>614</td>\n",
              "      <td>27</td>\n",
              "      <td>19.636220</td>\n",
              "      <td>19.620789</td>\n",
              "      <td>20.466667</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2012/8/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>666</td>\n",
              "      <td>666</td>\n",
              "      <td>2017</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>18</td>\n",
              "      <td>56</td>\n",
              "      <td>194</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5.085480</td>\n",
              "      <td>6.295922</td>\n",
              "      <td>6.492355</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>23</td>\n",
              "      <td>34</td>\n",
              "      <td>200</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.893042</td>\n",
              "      <td>6.623667</td>\n",
              "      <td>6.423896</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>16</td>\n",
              "      <td>48</td>\n",
              "      <td>185</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>19.579086</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>88</td>\n",
              "      <td>55</td>\n",
              "      <td>166</td>\n",
              "      <td>608</td>\n",
              "      <td>12</td>\n",
              "      <td>16.510561</td>\n",
              "      <td>19.785479</td>\n",
              "      <td>20.338505</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>99</td>\n",
              "      <td>63</td>\n",
              "      <td>112</td>\n",
              "      <td>584</td>\n",
              "      <td>28</td>\n",
              "      <td>23.626824</td>\n",
              "      <td>20.100821</td>\n",
              "      <td>19.380519</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>95</td>\n",
              "      <td>44</td>\n",
              "      <td>155</td>\n",
              "      <td>549</td>\n",
              "      <td>9</td>\n",
              "      <td>13.025461</td>\n",
              "      <td>17.282016</td>\n",
              "      <td>18.701889</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2017/4/14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>2019</td>\n",
              "      <td>8</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>34</td>\n",
              "      <td>13</td>\n",
              "      <td>35</td>\n",
              "      <td>191</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3.536041</td>\n",
              "      <td>4.618261</td>\n",
              "      <td>6.283927</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>53</td>\n",
              "      <td>203</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9.881881</td>\n",
              "      <td>8.617428</td>\n",
              "      <td>7.002271</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "      <td>33</td>\n",
              "      <td>183</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>20.616864</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>91</td>\n",
              "      <td>35</td>\n",
              "      <td>109</td>\n",
              "      <td>561</td>\n",
              "      <td>13</td>\n",
              "      <td>12.424781</td>\n",
              "      <td>14.313404</td>\n",
              "      <td>18.542395</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>92</td>\n",
              "      <td>88</td>\n",
              "      <td>175</td>\n",
              "      <td>614</td>\n",
              "      <td>29</td>\n",
              "      <td>28.595009</td>\n",
              "      <td>25.904056</td>\n",
              "      <td>21.068596</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>94</td>\n",
              "      <td>29</td>\n",
              "      <td>107</td>\n",
              "      <td>558</td>\n",
              "      <td>9</td>\n",
              "      <td>10.056423</td>\n",
              "      <td>13.410543</td>\n",
              "      <td>17.772145</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2019/8/29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>2019</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>12</td>\n",
              "      <td>42</td>\n",
              "      <td>167</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.698962</td>\n",
              "      <td>5.050786</td>\n",
              "      <td>5.617231</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>22</td>\n",
              "      <td>49</td>\n",
              "      <td>199</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9.118512</td>\n",
              "      <td>7.765206</td>\n",
              "      <td>6.934528</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>16</td>\n",
              "      <td>44</td>\n",
              "      <td>194</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>20.521699</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>93</td>\n",
              "      <td>40</td>\n",
              "      <td>130</td>\n",
              "      <td>546</td>\n",
              "      <td>7</td>\n",
              "      <td>11.309962</td>\n",
              "      <td>15.258759</td>\n",
              "      <td>17.803789</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>94</td>\n",
              "      <td>73</td>\n",
              "      <td>150</td>\n",
              "      <td>619</td>\n",
              "      <td>30</td>\n",
              "      <td>26.723965</td>\n",
              "      <td>23.640276</td>\n",
              "      <td>20.978081</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>89</td>\n",
              "      <td>59</td>\n",
              "      <td>129</td>\n",
              "      <td>567</td>\n",
              "      <td>14</td>\n",
              "      <td>16.867449</td>\n",
              "      <td>18.063775</td>\n",
              "      <td>18.696431</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>2019/5/24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>702</td>\n",
              "      <td>702</td>\n",
              "      <td>2017</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>22</td>\n",
              "      <td>44</td>\n",
              "      <td>201</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>5.195855</td>\n",
              "      <td>6.246850</td>\n",
              "      <td>6.661992</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>16</td>\n",
              "      <td>45</td>\n",
              "      <td>203</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6.931229</td>\n",
              "      <td>6.644555</td>\n",
              "      <td>6.782776</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>44</td>\n",
              "      <td>199</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>19.320196</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>90</td>\n",
              "      <td>68</td>\n",
              "      <td>145</td>\n",
              "      <td>610</td>\n",
              "      <td>9</td>\n",
              "      <td>17.860566</td>\n",
              "      <td>20.234171</td>\n",
              "      <td>20.359288</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>99</td>\n",
              "      <td>59</td>\n",
              "      <td>125</td>\n",
              "      <td>559</td>\n",
              "      <td>33</td>\n",
              "      <td>23.260737</td>\n",
              "      <td>19.666236</td>\n",
              "      <td>18.501634</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>92</td>\n",
              "      <td>71</td>\n",
              "      <td>151</td>\n",
              "      <td>579</td>\n",
              "      <td>16</td>\n",
              "      <td>20.492238</td>\n",
              "      <td>20.919484</td>\n",
              "      <td>19.818882</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>2017/2/23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 211 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   index    項番     年  月   日  ...  月星座同属性1  月星座同属性2  星座  当日の回答       星座.1\n",
              "0   1946  1946  2012  8  17  ...        9        1   5      1  2012/8/17\n",
              "1    666   666  2017  4  14  ...        1        5   1      4  2017/4/14\n",
              "2     22    22  2019  8  29  ...        9        1   6      5  2019/8/29\n",
              "3    104   104  2019  5  24  ...        3        7   3     11  2019/5/24\n",
              "4    702   702  2017  2  23  ...        2        6  12     10  2017/2/23\n",
              "\n",
              "[5 rows x 211 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4SYg693bVql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 特徴量と回答の分離\n",
        "X = data.drop([\"当日の回答\"], axis=1)\n",
        "# エクセルで使用した不要なデータは削除する。\n",
        "X = X.drop([\"星座.1\"], axis=1)\n",
        "\n",
        "Y = data[[\"当日の回答\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvhwJIDGOIq3",
        "colab_type": "code",
        "outputId": "3bc7fce9-9bb4-4f21-f967-96a30c17636a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# LightGBMでのモデル作成\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# まずは全データセットで学習\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "# LightGBM parameters\n",
        "\n",
        "params = {\n",
        "        'task': 'train',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'objective': 'multiclass',\n",
        "        'metric': {'multi_logloss'},\n",
        "        'num_class': 13,\n",
        "        'learning_rate': 0.01,\n",
        "        'num_leaves': 13,\n",
        "        'min_data_in_leaf': 5,\n",
        "        'num_iteration': 1000,\n",
        "        'verbose': 0\n",
        "}\n",
        "\n",
        "\n",
        "# Kfoldで分割して汎化性能があるか確認\n",
        "stack_xs_test = pd.DataFrame()\n",
        "stack_y_pred = []\n",
        "stack_data = pd.DataFrame()\n",
        "stack_stack_data = pd.DataFrame()\n",
        "\n",
        "#skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    xs_train = X.iloc[train_index]\n",
        "    y_train = Y.iloc[train_index]\n",
        "    xs_test = X.iloc[test_index]\n",
        "    y_test = Y.iloc[test_index] \n",
        "    xs_train_index = xs_train[[\"index\"]]\n",
        "    xs_train = xs_train.drop([\"index\"], axis=1)\n",
        "    lgb_train = lgb.Dataset(xs_train, y_train)\n",
        "    xs_test_index = xs_test[[\"index\"]]\n",
        "    xs_test = xs_test.drop([\"index\"], axis=1)\n",
        "    lgb_eval = lgb.Dataset(xs_test, y_test, reference=lgb_train)\n",
        "    gbm = lgb.train(params, lgb_train, num_boost_round=50, valid_sets=lgb_eval,early_stopping_rounds=20)\n",
        "    y_pred = gbm.predict(xs_test, num_iteration=gbm.best_iteration)\n",
        "    # 1位だけじゃなく順位も取得したいため、予想順位をy_check_percent_predに格納\n",
        "    y_check_percent_pred = y_pred\n",
        "    \n",
        "    # y_predは順位のみ\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    # 1位になる確率の低い順に星座を並べた変数\n",
        "    y_pred_percent_pred_sort = y_check_percent_pred.argsort()\n",
        "    # 1位になる星座の確率をソートしたものを格納\n",
        "    y_pred_sort = np.sort(y_check_percent_pred)\n",
        "    print(\"Accuracy\")\n",
        "    print(accuracy_score(y_test, y_pred))\n",
        "    \n",
        "    # 全データを再度分析するために、学習データ・テストデータ・予想データを取得\n",
        "    # 学習データのインデックスが邪魔になるため削除\n",
        "    xs_test = xs_test.reset_index(drop=True)\n",
        "    xs_test_index = xs_test_index.reset_index(drop=True)\n",
        "    \n",
        "    # テストデータのインデックスが邪魔になるため削除\n",
        "    y_test = y_test.reset_index(drop=True)\n",
        "    \n",
        "    # Kfoldのデータをstack_dataへ格納する。\n",
        "    stack_data = pd.DataFrame()\n",
        "    # 各データをdataframeへ変換\n",
        "    y_pred_df = pd.DataFrame(y_pred)\n",
        "    df_y_pred_percent_pred_sort = pd.DataFrame(y_pred_percent_pred_sort)\n",
        "    df_y_pred_sort = pd.DataFrame(y_pred_sort)\n",
        "    y_check_percent_pred_df = pd.DataFrame(y_check_percent_pred)\n",
        "    stack_data = pd.concat([xs_test, y_pred_df, y_test, y_check_percent_pred_df, df_y_pred_sort, df_y_pred_percent_pred_sort], axis=1)\n",
        "    # 分割したデータを結合する。\n",
        "    stack_stack_data = pd.concat([stack_stack_data, stack_data])\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's multi_logloss: 2.47666\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 2.46927\n",
            "[3]\tvalid_0's multi_logloss: 2.46192\n",
            "[4]\tvalid_0's multi_logloss: 2.45487\n",
            "[5]\tvalid_0's multi_logloss: 2.44808\n",
            "[6]\tvalid_0's multi_logloss: 2.44163\n",
            "[7]\tvalid_0's multi_logloss: 2.43502\n",
            "[8]\tvalid_0's multi_logloss: 2.42931\n",
            "[9]\tvalid_0's multi_logloss: 2.42355\n",
            "[10]\tvalid_0's multi_logloss: 2.41729\n",
            "[11]\tvalid_0's multi_logloss: 2.411\n",
            "[12]\tvalid_0's multi_logloss: 2.40577\n",
            "[13]\tvalid_0's multi_logloss: 2.39962\n",
            "[14]\tvalid_0's multi_logloss: 2.39454\n",
            "[15]\tvalid_0's multi_logloss: 2.38892\n",
            "[16]\tvalid_0's multi_logloss: 2.38349\n",
            "[17]\tvalid_0's multi_logloss: 2.37829\n",
            "[18]\tvalid_0's multi_logloss: 2.37321\n",
            "[19]\tvalid_0's multi_logloss: 2.36803\n",
            "[20]\tvalid_0's multi_logloss: 2.36318\n",
            "[21]\tvalid_0's multi_logloss: 2.35854\n",
            "[22]\tvalid_0's multi_logloss: 2.35377\n",
            "[23]\tvalid_0's multi_logloss: 2.34914\n",
            "[24]\tvalid_0's multi_logloss: 2.3448\n",
            "[25]\tvalid_0's multi_logloss: 2.34031\n",
            "[26]\tvalid_0's multi_logloss: 2.33563\n",
            "[27]\tvalid_0's multi_logloss: 2.33086\n",
            "[28]\tvalid_0's multi_logloss: 2.32658\n",
            "[29]\tvalid_0's multi_logloss: 2.3225\n",
            "[30]\tvalid_0's multi_logloss: 2.31813\n",
            "[31]\tvalid_0's multi_logloss: 2.31377\n",
            "[32]\tvalid_0's multi_logloss: 2.30976\n",
            "[33]\tvalid_0's multi_logloss: 2.30555\n",
            "[34]\tvalid_0's multi_logloss: 2.30193\n",
            "[35]\tvalid_0's multi_logloss: 2.2979\n",
            "[36]\tvalid_0's multi_logloss: 2.29376\n",
            "[37]\tvalid_0's multi_logloss: 2.28962\n",
            "[38]\tvalid_0's multi_logloss: 2.28608\n",
            "[39]\tvalid_0's multi_logloss: 2.28254\n",
            "[40]\tvalid_0's multi_logloss: 2.27907\n",
            "[41]\tvalid_0's multi_logloss: 2.27569\n",
            "[42]\tvalid_0's multi_logloss: 2.27258\n",
            "[43]\tvalid_0's multi_logloss: 2.26931\n",
            "[44]\tvalid_0's multi_logloss: 2.26584\n",
            "[45]\tvalid_0's multi_logloss: 2.2627\n",
            "[46]\tvalid_0's multi_logloss: 2.25927\n",
            "[47]\tvalid_0's multi_logloss: 2.25608\n",
            "[48]\tvalid_0's multi_logloss: 2.25286\n",
            "[49]\tvalid_0's multi_logloss: 2.24931\n",
            "[50]\tvalid_0's multi_logloss: 2.24609\n",
            "[51]\tvalid_0's multi_logloss: 2.24269\n",
            "[52]\tvalid_0's multi_logloss: 2.23944\n",
            "[53]\tvalid_0's multi_logloss: 2.23622\n",
            "[54]\tvalid_0's multi_logloss: 2.23308\n",
            "[55]\tvalid_0's multi_logloss: 2.23019\n",
            "[56]\tvalid_0's multi_logloss: 2.22689\n",
            "[57]\tvalid_0's multi_logloss: 2.22426\n",
            "[58]\tvalid_0's multi_logloss: 2.22099\n",
            "[59]\tvalid_0's multi_logloss: 2.21814\n",
            "[60]\tvalid_0's multi_logloss: 2.21486\n",
            "[61]\tvalid_0's multi_logloss: 2.21161\n",
            "[62]\tvalid_0's multi_logloss: 2.20839\n",
            "[63]\tvalid_0's multi_logloss: 2.20544\n",
            "[64]\tvalid_0's multi_logloss: 2.20246\n",
            "[65]\tvalid_0's multi_logloss: 2.19927\n",
            "[66]\tvalid_0's multi_logloss: 2.19648\n",
            "[67]\tvalid_0's multi_logloss: 2.19367\n",
            "[68]\tvalid_0's multi_logloss: 2.19073\n",
            "[69]\tvalid_0's multi_logloss: 2.18768\n",
            "[70]\tvalid_0's multi_logloss: 2.18512\n",
            "[71]\tvalid_0's multi_logloss: 2.18238\n",
            "[72]\tvalid_0's multi_logloss: 2.17994\n",
            "[73]\tvalid_0's multi_logloss: 2.17739\n",
            "[74]\tvalid_0's multi_logloss: 2.1749\n",
            "[75]\tvalid_0's multi_logloss: 2.17265\n",
            "[76]\tvalid_0's multi_logloss: 2.17003\n",
            "[77]\tvalid_0's multi_logloss: 2.16763\n",
            "[78]\tvalid_0's multi_logloss: 2.16521\n",
            "[79]\tvalid_0's multi_logloss: 2.16283\n",
            "[80]\tvalid_0's multi_logloss: 2.16064\n",
            "[81]\tvalid_0's multi_logloss: 2.15843\n",
            "[82]\tvalid_0's multi_logloss: 2.15623\n",
            "[83]\tvalid_0's multi_logloss: 2.15413\n",
            "[84]\tvalid_0's multi_logloss: 2.15203\n",
            "[85]\tvalid_0's multi_logloss: 2.14997\n",
            "[86]\tvalid_0's multi_logloss: 2.14775\n",
            "[87]\tvalid_0's multi_logloss: 2.14589\n",
            "[88]\tvalid_0's multi_logloss: 2.14354\n",
            "[89]\tvalid_0's multi_logloss: 2.14157\n",
            "[90]\tvalid_0's multi_logloss: 2.13959\n",
            "[91]\tvalid_0's multi_logloss: 2.13762\n",
            "[92]\tvalid_0's multi_logloss: 2.13558\n",
            "[93]\tvalid_0's multi_logloss: 2.1338\n",
            "[94]\tvalid_0's multi_logloss: 2.13174\n",
            "[95]\tvalid_0's multi_logloss: 2.12985\n",
            "[96]\tvalid_0's multi_logloss: 2.12801\n",
            "[97]\tvalid_0's multi_logloss: 2.12602\n",
            "[98]\tvalid_0's multi_logloss: 2.12405\n",
            "[99]\tvalid_0's multi_logloss: 2.12229\n",
            "[100]\tvalid_0's multi_logloss: 2.1204\n",
            "[101]\tvalid_0's multi_logloss: 2.11852\n",
            "[102]\tvalid_0's multi_logloss: 2.11672\n",
            "[103]\tvalid_0's multi_logloss: 2.11511\n",
            "[104]\tvalid_0's multi_logloss: 2.11343\n",
            "[105]\tvalid_0's multi_logloss: 2.11155\n",
            "[106]\tvalid_0's multi_logloss: 2.10985\n",
            "[107]\tvalid_0's multi_logloss: 2.10809\n",
            "[108]\tvalid_0's multi_logloss: 2.10618\n",
            "[109]\tvalid_0's multi_logloss: 2.10428\n",
            "[110]\tvalid_0's multi_logloss: 2.10286\n",
            "[111]\tvalid_0's multi_logloss: 2.10092\n",
            "[112]\tvalid_0's multi_logloss: 2.09945\n",
            "[113]\tvalid_0's multi_logloss: 2.09798\n",
            "[114]\tvalid_0's multi_logloss: 2.0963\n",
            "[115]\tvalid_0's multi_logloss: 2.09485\n",
            "[116]\tvalid_0's multi_logloss: 2.09341\n",
            "[117]\tvalid_0's multi_logloss: 2.0918\n",
            "[118]\tvalid_0's multi_logloss: 2.09037\n",
            "[119]\tvalid_0's multi_logloss: 2.0887\n",
            "[120]\tvalid_0's multi_logloss: 2.0872\n",
            "[121]\tvalid_0's multi_logloss: 2.08559\n",
            "[122]\tvalid_0's multi_logloss: 2.08399\n",
            "[123]\tvalid_0's multi_logloss: 2.08229\n",
            "[124]\tvalid_0's multi_logloss: 2.08063\n",
            "[125]\tvalid_0's multi_logloss: 2.07923\n",
            "[126]\tvalid_0's multi_logloss: 2.07759\n",
            "[127]\tvalid_0's multi_logloss: 2.07623\n",
            "[128]\tvalid_0's multi_logloss: 2.07459\n",
            "[129]\tvalid_0's multi_logloss: 2.07296\n",
            "[130]\tvalid_0's multi_logloss: 2.07163\n",
            "[131]\tvalid_0's multi_logloss: 2.07011\n",
            "[132]\tvalid_0's multi_logloss: 2.06849\n",
            "[133]\tvalid_0's multi_logloss: 2.06712\n",
            "[134]\tvalid_0's multi_logloss: 2.06562\n",
            "[135]\tvalid_0's multi_logloss: 2.06419\n",
            "[136]\tvalid_0's multi_logloss: 2.0628\n",
            "[137]\tvalid_0's multi_logloss: 2.06135\n",
            "[138]\tvalid_0's multi_logloss: 2.06002\n",
            "[139]\tvalid_0's multi_logloss: 2.05872\n",
            "[140]\tvalid_0's multi_logloss: 2.05731\n",
            "[141]\tvalid_0's multi_logloss: 2.05609\n",
            "[142]\tvalid_0's multi_logloss: 2.05465\n",
            "[143]\tvalid_0's multi_logloss: 2.05347\n",
            "[144]\tvalid_0's multi_logloss: 2.05212\n",
            "[145]\tvalid_0's multi_logloss: 2.05074\n",
            "[146]\tvalid_0's multi_logloss: 2.04958\n",
            "[147]\tvalid_0's multi_logloss: 2.04842\n",
            "[148]\tvalid_0's multi_logloss: 2.04723\n",
            "[149]\tvalid_0's multi_logloss: 2.04624\n",
            "[150]\tvalid_0's multi_logloss: 2.04502\n",
            "[151]\tvalid_0's multi_logloss: 2.04395\n",
            "[152]\tvalid_0's multi_logloss: 2.04283\n",
            "[153]\tvalid_0's multi_logloss: 2.04168\n",
            "[154]\tvalid_0's multi_logloss: 2.04032\n",
            "[155]\tvalid_0's multi_logloss: 2.03917\n",
            "[156]\tvalid_0's multi_logloss: 2.03833\n",
            "[157]\tvalid_0's multi_logloss: 2.03728\n",
            "[158]\tvalid_0's multi_logloss: 2.03605\n",
            "[159]\tvalid_0's multi_logloss: 2.03518\n",
            "[160]\tvalid_0's multi_logloss: 2.03399\n",
            "[161]\tvalid_0's multi_logloss: 2.03285\n",
            "[162]\tvalid_0's multi_logloss: 2.03158\n",
            "[163]\tvalid_0's multi_logloss: 2.0304\n",
            "[164]\tvalid_0's multi_logloss: 2.02934\n",
            "[165]\tvalid_0's multi_logloss: 2.02819\n",
            "[166]\tvalid_0's multi_logloss: 2.02712\n",
            "[167]\tvalid_0's multi_logloss: 2.02593\n",
            "[168]\tvalid_0's multi_logloss: 2.02466\n",
            "[169]\tvalid_0's multi_logloss: 2.02348\n",
            "[170]\tvalid_0's multi_logloss: 2.02236\n",
            "[171]\tvalid_0's multi_logloss: 2.02112\n",
            "[172]\tvalid_0's multi_logloss: 2.02008\n",
            "[173]\tvalid_0's multi_logloss: 2.01902\n",
            "[174]\tvalid_0's multi_logloss: 2.01794\n",
            "[175]\tvalid_0's multi_logloss: 2.0166\n",
            "[176]\tvalid_0's multi_logloss: 2.0158\n",
            "[177]\tvalid_0's multi_logloss: 2.01468\n",
            "[178]\tvalid_0's multi_logloss: 2.0135\n",
            "[179]\tvalid_0's multi_logloss: 2.01226\n",
            "[180]\tvalid_0's multi_logloss: 2.01124\n",
            "[181]\tvalid_0's multi_logloss: 2.01014\n",
            "[182]\tvalid_0's multi_logloss: 2.00885\n",
            "[183]\tvalid_0's multi_logloss: 2.00749\n",
            "[184]\tvalid_0's multi_logloss: 2.00644\n",
            "[185]\tvalid_0's multi_logloss: 2.00539\n",
            "[186]\tvalid_0's multi_logloss: 2.0043\n",
            "[187]\tvalid_0's multi_logloss: 2.00331\n",
            "[188]\tvalid_0's multi_logloss: 2.00218\n",
            "[189]\tvalid_0's multi_logloss: 2.00105\n",
            "[190]\tvalid_0's multi_logloss: 1.99985\n",
            "[191]\tvalid_0's multi_logloss: 1.9991\n",
            "[192]\tvalid_0's multi_logloss: 1.99804\n",
            "[193]\tvalid_0's multi_logloss: 1.99699\n",
            "[194]\tvalid_0's multi_logloss: 1.99603\n",
            "[195]\tvalid_0's multi_logloss: 1.99505\n",
            "[196]\tvalid_0's multi_logloss: 1.99413\n",
            "[197]\tvalid_0's multi_logloss: 1.99309\n",
            "[198]\tvalid_0's multi_logloss: 1.99211\n",
            "[199]\tvalid_0's multi_logloss: 1.99113\n",
            "[200]\tvalid_0's multi_logloss: 1.99031\n",
            "[201]\tvalid_0's multi_logloss: 1.98938\n",
            "[202]\tvalid_0's multi_logloss: 1.98832\n",
            "[203]\tvalid_0's multi_logloss: 1.98738\n",
            "[204]\tvalid_0's multi_logloss: 1.98655\n",
            "[205]\tvalid_0's multi_logloss: 1.98556\n",
            "[206]\tvalid_0's multi_logloss: 1.98482\n",
            "[207]\tvalid_0's multi_logloss: 1.98369\n",
            "[208]\tvalid_0's multi_logloss: 1.98297\n",
            "[209]\tvalid_0's multi_logloss: 1.98205\n",
            "[210]\tvalid_0's multi_logloss: 1.98136\n",
            "[211]\tvalid_0's multi_logloss: 1.98044\n",
            "[212]\tvalid_0's multi_logloss: 1.97981\n",
            "[213]\tvalid_0's multi_logloss: 1.97901\n",
            "[214]\tvalid_0's multi_logloss: 1.97805\n",
            "[215]\tvalid_0's multi_logloss: 1.97751\n",
            "[216]\tvalid_0's multi_logloss: 1.97649\n",
            "[217]\tvalid_0's multi_logloss: 1.97576\n",
            "[218]\tvalid_0's multi_logloss: 1.97473\n",
            "[219]\tvalid_0's multi_logloss: 1.97405\n",
            "[220]\tvalid_0's multi_logloss: 1.9734\n",
            "[221]\tvalid_0's multi_logloss: 1.97257\n",
            "[222]\tvalid_0's multi_logloss: 1.97175\n",
            "[223]\tvalid_0's multi_logloss: 1.97093\n",
            "[224]\tvalid_0's multi_logloss: 1.97\n",
            "[225]\tvalid_0's multi_logloss: 1.96916\n",
            "[226]\tvalid_0's multi_logloss: 1.96844\n",
            "[227]\tvalid_0's multi_logloss: 1.96775\n",
            "[228]\tvalid_0's multi_logloss: 1.96696\n",
            "[229]\tvalid_0's multi_logloss: 1.96619\n",
            "[230]\tvalid_0's multi_logloss: 1.96541\n",
            "[231]\tvalid_0's multi_logloss: 1.96452\n",
            "[232]\tvalid_0's multi_logloss: 1.96385\n",
            "[233]\tvalid_0's multi_logloss: 1.96304\n",
            "[234]\tvalid_0's multi_logloss: 1.96226\n",
            "[235]\tvalid_0's multi_logloss: 1.96157\n",
            "[236]\tvalid_0's multi_logloss: 1.96095\n",
            "[237]\tvalid_0's multi_logloss: 1.96012\n",
            "[238]\tvalid_0's multi_logloss: 1.95921\n",
            "[239]\tvalid_0's multi_logloss: 1.9585\n",
            "[240]\tvalid_0's multi_logloss: 1.95774\n",
            "[241]\tvalid_0's multi_logloss: 1.95716\n",
            "[242]\tvalid_0's multi_logloss: 1.95645\n",
            "[243]\tvalid_0's multi_logloss: 1.95576\n",
            "[244]\tvalid_0's multi_logloss: 1.95519\n",
            "[245]\tvalid_0's multi_logloss: 1.95464\n",
            "[246]\tvalid_0's multi_logloss: 1.95389\n",
            "[247]\tvalid_0's multi_logloss: 1.95338\n",
            "[248]\tvalid_0's multi_logloss: 1.95251\n",
            "[249]\tvalid_0's multi_logloss: 1.95195\n",
            "[250]\tvalid_0's multi_logloss: 1.95114\n",
            "[251]\tvalid_0's multi_logloss: 1.95066\n",
            "[252]\tvalid_0's multi_logloss: 1.95013\n",
            "[253]\tvalid_0's multi_logloss: 1.94932\n",
            "[254]\tvalid_0's multi_logloss: 1.94873\n",
            "[255]\tvalid_0's multi_logloss: 1.94805\n",
            "[256]\tvalid_0's multi_logloss: 1.94737\n",
            "[257]\tvalid_0's multi_logloss: 1.94699\n",
            "[258]\tvalid_0's multi_logloss: 1.94623\n",
            "[259]\tvalid_0's multi_logloss: 1.94558\n",
            "[260]\tvalid_0's multi_logloss: 1.94512\n",
            "[261]\tvalid_0's multi_logloss: 1.9444\n",
            "[262]\tvalid_0's multi_logloss: 1.94367\n",
            "[263]\tvalid_0's multi_logloss: 1.94311\n",
            "[264]\tvalid_0's multi_logloss: 1.94259\n",
            "[265]\tvalid_0's multi_logloss: 1.94204\n",
            "[266]\tvalid_0's multi_logloss: 1.94127\n",
            "[267]\tvalid_0's multi_logloss: 1.94061\n",
            "[268]\tvalid_0's multi_logloss: 1.94007\n",
            "[269]\tvalid_0's multi_logloss: 1.93943\n",
            "[270]\tvalid_0's multi_logloss: 1.93898\n",
            "[271]\tvalid_0's multi_logloss: 1.93844\n",
            "[272]\tvalid_0's multi_logloss: 1.93787\n",
            "[273]\tvalid_0's multi_logloss: 1.93724\n",
            "[274]\tvalid_0's multi_logloss: 1.93673\n",
            "[275]\tvalid_0's multi_logloss: 1.93612\n",
            "[276]\tvalid_0's multi_logloss: 1.93551\n",
            "[277]\tvalid_0's multi_logloss: 1.93509\n",
            "[278]\tvalid_0's multi_logloss: 1.93452\n",
            "[279]\tvalid_0's multi_logloss: 1.93386\n",
            "[280]\tvalid_0's multi_logloss: 1.93332\n",
            "[281]\tvalid_0's multi_logloss: 1.93264\n",
            "[282]\tvalid_0's multi_logloss: 1.93214\n",
            "[283]\tvalid_0's multi_logloss: 1.93161\n",
            "[284]\tvalid_0's multi_logloss: 1.93093\n",
            "[285]\tvalid_0's multi_logloss: 1.93026\n",
            "[286]\tvalid_0's multi_logloss: 1.92972\n",
            "[287]\tvalid_0's multi_logloss: 1.92919\n",
            "[288]\tvalid_0's multi_logloss: 1.92864\n",
            "[289]\tvalid_0's multi_logloss: 1.92814\n",
            "[290]\tvalid_0's multi_logloss: 1.92765\n",
            "[291]\tvalid_0's multi_logloss: 1.92719\n",
            "[292]\tvalid_0's multi_logloss: 1.92672\n",
            "[293]\tvalid_0's multi_logloss: 1.92638\n",
            "[294]\tvalid_0's multi_logloss: 1.92579\n",
            "[295]\tvalid_0's multi_logloss: 1.92535\n",
            "[296]\tvalid_0's multi_logloss: 1.92491\n",
            "[297]\tvalid_0's multi_logloss: 1.92452\n",
            "[298]\tvalid_0's multi_logloss: 1.92411\n",
            "[299]\tvalid_0's multi_logloss: 1.92341\n",
            "[300]\tvalid_0's multi_logloss: 1.92298\n",
            "[301]\tvalid_0's multi_logloss: 1.92274\n",
            "[302]\tvalid_0's multi_logloss: 1.92224\n",
            "[303]\tvalid_0's multi_logloss: 1.92189\n",
            "[304]\tvalid_0's multi_logloss: 1.9215\n",
            "[305]\tvalid_0's multi_logloss: 1.92097\n",
            "[306]\tvalid_0's multi_logloss: 1.92056\n",
            "[307]\tvalid_0's multi_logloss: 1.92002\n",
            "[308]\tvalid_0's multi_logloss: 1.91965\n",
            "[309]\tvalid_0's multi_logloss: 1.91912\n",
            "[310]\tvalid_0's multi_logloss: 1.91867\n",
            "[311]\tvalid_0's multi_logloss: 1.91827\n",
            "[312]\tvalid_0's multi_logloss: 1.91778\n",
            "[313]\tvalid_0's multi_logloss: 1.9174\n",
            "[314]\tvalid_0's multi_logloss: 1.91684\n",
            "[315]\tvalid_0's multi_logloss: 1.91648\n",
            "[316]\tvalid_0's multi_logloss: 1.91609\n",
            "[317]\tvalid_0's multi_logloss: 1.91583\n",
            "[318]\tvalid_0's multi_logloss: 1.91542\n",
            "[319]\tvalid_0's multi_logloss: 1.91506\n",
            "[320]\tvalid_0's multi_logloss: 1.91466\n",
            "[321]\tvalid_0's multi_logloss: 1.91423\n",
            "[322]\tvalid_0's multi_logloss: 1.91391\n",
            "[323]\tvalid_0's multi_logloss: 1.91359\n",
            "[324]\tvalid_0's multi_logloss: 1.91325\n",
            "[325]\tvalid_0's multi_logloss: 1.91286\n",
            "[326]\tvalid_0's multi_logloss: 1.9126\n",
            "[327]\tvalid_0's multi_logloss: 1.91233\n",
            "[328]\tvalid_0's multi_logloss: 1.912\n",
            "[329]\tvalid_0's multi_logloss: 1.91166\n",
            "[330]\tvalid_0's multi_logloss: 1.91124\n",
            "[331]\tvalid_0's multi_logloss: 1.91086\n",
            "[332]\tvalid_0's multi_logloss: 1.91054\n",
            "[333]\tvalid_0's multi_logloss: 1.91021\n",
            "[334]\tvalid_0's multi_logloss: 1.90985\n",
            "[335]\tvalid_0's multi_logloss: 1.90945\n",
            "[336]\tvalid_0's multi_logloss: 1.90914\n",
            "[337]\tvalid_0's multi_logloss: 1.90888\n",
            "[338]\tvalid_0's multi_logloss: 1.90858\n",
            "[339]\tvalid_0's multi_logloss: 1.90812\n",
            "[340]\tvalid_0's multi_logloss: 1.90793\n",
            "[341]\tvalid_0's multi_logloss: 1.90759\n",
            "[342]\tvalid_0's multi_logloss: 1.90729\n",
            "[343]\tvalid_0's multi_logloss: 1.9071\n",
            "[344]\tvalid_0's multi_logloss: 1.90678\n",
            "[345]\tvalid_0's multi_logloss: 1.90658\n",
            "[346]\tvalid_0's multi_logloss: 1.90625\n",
            "[347]\tvalid_0's multi_logloss: 1.90601\n",
            "[348]\tvalid_0's multi_logloss: 1.90571\n",
            "[349]\tvalid_0's multi_logloss: 1.90551\n",
            "[350]\tvalid_0's multi_logloss: 1.90524\n",
            "[351]\tvalid_0's multi_logloss: 1.90497\n",
            "[352]\tvalid_0's multi_logloss: 1.90465\n",
            "[353]\tvalid_0's multi_logloss: 1.9044\n",
            "[354]\tvalid_0's multi_logloss: 1.90407\n",
            "[355]\tvalid_0's multi_logloss: 1.9038\n",
            "[356]\tvalid_0's multi_logloss: 1.90364\n",
            "[357]\tvalid_0's multi_logloss: 1.90337\n",
            "[358]\tvalid_0's multi_logloss: 1.90314\n",
            "[359]\tvalid_0's multi_logloss: 1.90268\n",
            "[360]\tvalid_0's multi_logloss: 1.90242\n",
            "[361]\tvalid_0's multi_logloss: 1.90215\n",
            "[362]\tvalid_0's multi_logloss: 1.90198\n",
            "[363]\tvalid_0's multi_logloss: 1.90175\n",
            "[364]\tvalid_0's multi_logloss: 1.90147\n",
            "[365]\tvalid_0's multi_logloss: 1.90112\n",
            "[366]\tvalid_0's multi_logloss: 1.90088\n",
            "[367]\tvalid_0's multi_logloss: 1.90084\n",
            "[368]\tvalid_0's multi_logloss: 1.90047\n",
            "[369]\tvalid_0's multi_logloss: 1.9002\n",
            "[370]\tvalid_0's multi_logloss: 1.8999\n",
            "[371]\tvalid_0's multi_logloss: 1.89974\n",
            "[372]\tvalid_0's multi_logloss: 1.89965\n",
            "[373]\tvalid_0's multi_logloss: 1.89938\n",
            "[374]\tvalid_0's multi_logloss: 1.89904\n",
            "[375]\tvalid_0's multi_logloss: 1.89894\n",
            "[376]\tvalid_0's multi_logloss: 1.89868\n",
            "[377]\tvalid_0's multi_logloss: 1.89846\n",
            "[378]\tvalid_0's multi_logloss: 1.8982\n",
            "[379]\tvalid_0's multi_logloss: 1.89789\n",
            "[380]\tvalid_0's multi_logloss: 1.8975\n",
            "[381]\tvalid_0's multi_logloss: 1.89732\n",
            "[382]\tvalid_0's multi_logloss: 1.89699\n",
            "[383]\tvalid_0's multi_logloss: 1.89669\n",
            "[384]\tvalid_0's multi_logloss: 1.8964\n",
            "[385]\tvalid_0's multi_logloss: 1.89612\n",
            "[386]\tvalid_0's multi_logloss: 1.89577\n",
            "[387]\tvalid_0's multi_logloss: 1.89546\n",
            "[388]\tvalid_0's multi_logloss: 1.89536\n",
            "[389]\tvalid_0's multi_logloss: 1.89514\n",
            "[390]\tvalid_0's multi_logloss: 1.89484\n",
            "[391]\tvalid_0's multi_logloss: 1.89468\n",
            "[392]\tvalid_0's multi_logloss: 1.8943\n",
            "[393]\tvalid_0's multi_logloss: 1.89396\n",
            "[394]\tvalid_0's multi_logloss: 1.89355\n",
            "[395]\tvalid_0's multi_logloss: 1.89338\n",
            "[396]\tvalid_0's multi_logloss: 1.89332\n",
            "[397]\tvalid_0's multi_logloss: 1.89294\n",
            "[398]\tvalid_0's multi_logloss: 1.8927\n",
            "[399]\tvalid_0's multi_logloss: 1.89258\n",
            "[400]\tvalid_0's multi_logloss: 1.89227\n",
            "[401]\tvalid_0's multi_logloss: 1.89213\n",
            "[402]\tvalid_0's multi_logloss: 1.89172\n",
            "[403]\tvalid_0's multi_logloss: 1.89156\n",
            "[404]\tvalid_0's multi_logloss: 1.8914\n",
            "[405]\tvalid_0's multi_logloss: 1.8912\n",
            "[406]\tvalid_0's multi_logloss: 1.89098\n",
            "[407]\tvalid_0's multi_logloss: 1.89082\n",
            "[408]\tvalid_0's multi_logloss: 1.89073\n",
            "[409]\tvalid_0's multi_logloss: 1.89041\n",
            "[410]\tvalid_0's multi_logloss: 1.89027\n",
            "[411]\tvalid_0's multi_logloss: 1.89008\n",
            "[412]\tvalid_0's multi_logloss: 1.88983\n",
            "[413]\tvalid_0's multi_logloss: 1.88955\n",
            "[414]\tvalid_0's multi_logloss: 1.88947\n",
            "[415]\tvalid_0's multi_logloss: 1.88928\n",
            "[416]\tvalid_0's multi_logloss: 1.88918\n",
            "[417]\tvalid_0's multi_logloss: 1.88898\n",
            "[418]\tvalid_0's multi_logloss: 1.88886\n",
            "[419]\tvalid_0's multi_logloss: 1.88857\n",
            "[420]\tvalid_0's multi_logloss: 1.88834\n",
            "[421]\tvalid_0's multi_logloss: 1.88814\n",
            "[422]\tvalid_0's multi_logloss: 1.88795\n",
            "[423]\tvalid_0's multi_logloss: 1.88768\n",
            "[424]\tvalid_0's multi_logloss: 1.88762\n",
            "[425]\tvalid_0's multi_logloss: 1.88734\n",
            "[426]\tvalid_0's multi_logloss: 1.88706\n",
            "[427]\tvalid_0's multi_logloss: 1.88689\n",
            "[428]\tvalid_0's multi_logloss: 1.88668\n",
            "[429]\tvalid_0's multi_logloss: 1.88633\n",
            "[430]\tvalid_0's multi_logloss: 1.88631\n",
            "[431]\tvalid_0's multi_logloss: 1.88619\n",
            "[432]\tvalid_0's multi_logloss: 1.88621\n",
            "[433]\tvalid_0's multi_logloss: 1.88602\n",
            "[434]\tvalid_0's multi_logloss: 1.88566\n",
            "[435]\tvalid_0's multi_logloss: 1.88558\n",
            "[436]\tvalid_0's multi_logloss: 1.8854\n",
            "[437]\tvalid_0's multi_logloss: 1.88522\n",
            "[438]\tvalid_0's multi_logloss: 1.88502\n",
            "[439]\tvalid_0's multi_logloss: 1.88484\n",
            "[440]\tvalid_0's multi_logloss: 1.88459\n",
            "[441]\tvalid_0's multi_logloss: 1.88444\n",
            "[442]\tvalid_0's multi_logloss: 1.8843\n",
            "[443]\tvalid_0's multi_logloss: 1.88423\n",
            "[444]\tvalid_0's multi_logloss: 1.88396\n",
            "[445]\tvalid_0's multi_logloss: 1.8837\n",
            "[446]\tvalid_0's multi_logloss: 1.88365\n",
            "[447]\tvalid_0's multi_logloss: 1.88351\n",
            "[448]\tvalid_0's multi_logloss: 1.88337\n",
            "[449]\tvalid_0's multi_logloss: 1.8832\n",
            "[450]\tvalid_0's multi_logloss: 1.88309\n",
            "[451]\tvalid_0's multi_logloss: 1.88291\n",
            "[452]\tvalid_0's multi_logloss: 1.88275\n",
            "[453]\tvalid_0's multi_logloss: 1.88261\n",
            "[454]\tvalid_0's multi_logloss: 1.88247\n",
            "[455]\tvalid_0's multi_logloss: 1.88227\n",
            "[456]\tvalid_0's multi_logloss: 1.88209\n",
            "[457]\tvalid_0's multi_logloss: 1.88188\n",
            "[458]\tvalid_0's multi_logloss: 1.88182\n",
            "[459]\tvalid_0's multi_logloss: 1.88185\n",
            "[460]\tvalid_0's multi_logloss: 1.88168\n",
            "[461]\tvalid_0's multi_logloss: 1.88136\n",
            "[462]\tvalid_0's multi_logloss: 1.8812\n",
            "[463]\tvalid_0's multi_logloss: 1.88117\n",
            "[464]\tvalid_0's multi_logloss: 1.88094\n",
            "[465]\tvalid_0's multi_logloss: 1.88092\n",
            "[466]\tvalid_0's multi_logloss: 1.88073\n",
            "[467]\tvalid_0's multi_logloss: 1.88046\n",
            "[468]\tvalid_0's multi_logloss: 1.88031\n",
            "[469]\tvalid_0's multi_logloss: 1.88017\n",
            "[470]\tvalid_0's multi_logloss: 1.88008\n",
            "[471]\tvalid_0's multi_logloss: 1.87988\n",
            "[472]\tvalid_0's multi_logloss: 1.87963\n",
            "[473]\tvalid_0's multi_logloss: 1.87953\n",
            "[474]\tvalid_0's multi_logloss: 1.87951\n",
            "[475]\tvalid_0's multi_logloss: 1.87941\n",
            "[476]\tvalid_0's multi_logloss: 1.87916\n",
            "[477]\tvalid_0's multi_logloss: 1.8792\n",
            "[478]\tvalid_0's multi_logloss: 1.879\n",
            "[479]\tvalid_0's multi_logloss: 1.87882\n",
            "[480]\tvalid_0's multi_logloss: 1.8787\n",
            "[481]\tvalid_0's multi_logloss: 1.87857\n",
            "[482]\tvalid_0's multi_logloss: 1.87845\n",
            "[483]\tvalid_0's multi_logloss: 1.87828\n",
            "[484]\tvalid_0's multi_logloss: 1.87825\n",
            "[485]\tvalid_0's multi_logloss: 1.87798\n",
            "[486]\tvalid_0's multi_logloss: 1.87783\n",
            "[487]\tvalid_0's multi_logloss: 1.87767\n",
            "[488]\tvalid_0's multi_logloss: 1.87751\n",
            "[489]\tvalid_0's multi_logloss: 1.87734\n",
            "[490]\tvalid_0's multi_logloss: 1.87718\n",
            "[491]\tvalid_0's multi_logloss: 1.87714\n",
            "[492]\tvalid_0's multi_logloss: 1.87707\n",
            "[493]\tvalid_0's multi_logloss: 1.87683\n",
            "[494]\tvalid_0's multi_logloss: 1.87689\n",
            "[495]\tvalid_0's multi_logloss: 1.87675\n",
            "[496]\tvalid_0's multi_logloss: 1.87668\n",
            "[497]\tvalid_0's multi_logloss: 1.87658\n",
            "[498]\tvalid_0's multi_logloss: 1.87671\n",
            "[499]\tvalid_0's multi_logloss: 1.87651\n",
            "[500]\tvalid_0's multi_logloss: 1.8764\n",
            "[501]\tvalid_0's multi_logloss: 1.87635\n",
            "[502]\tvalid_0's multi_logloss: 1.87633\n",
            "[503]\tvalid_0's multi_logloss: 1.87633\n",
            "[504]\tvalid_0's multi_logloss: 1.87634\n",
            "[505]\tvalid_0's multi_logloss: 1.87618\n",
            "[506]\tvalid_0's multi_logloss: 1.87621\n",
            "[507]\tvalid_0's multi_logloss: 1.87592\n",
            "[508]\tvalid_0's multi_logloss: 1.87578\n",
            "[509]\tvalid_0's multi_logloss: 1.87547\n",
            "[510]\tvalid_0's multi_logloss: 1.87531\n",
            "[511]\tvalid_0's multi_logloss: 1.87529\n",
            "[512]\tvalid_0's multi_logloss: 1.87528\n",
            "[513]\tvalid_0's multi_logloss: 1.87519\n",
            "[514]\tvalid_0's multi_logloss: 1.87501\n",
            "[515]\tvalid_0's multi_logloss: 1.87484\n",
            "[516]\tvalid_0's multi_logloss: 1.8747\n",
            "[517]\tvalid_0's multi_logloss: 1.87469\n",
            "[518]\tvalid_0's multi_logloss: 1.87441\n",
            "[519]\tvalid_0's multi_logloss: 1.87432\n",
            "[520]\tvalid_0's multi_logloss: 1.87407\n",
            "[521]\tvalid_0's multi_logloss: 1.87391\n",
            "[522]\tvalid_0's multi_logloss: 1.87376\n",
            "[523]\tvalid_0's multi_logloss: 1.87366\n",
            "[524]\tvalid_0's multi_logloss: 1.87352\n",
            "[525]\tvalid_0's multi_logloss: 1.87336\n",
            "[526]\tvalid_0's multi_logloss: 1.8732\n",
            "[527]\tvalid_0's multi_logloss: 1.87305\n",
            "[528]\tvalid_0's multi_logloss: 1.87296\n",
            "[529]\tvalid_0's multi_logloss: 1.87277\n",
            "[530]\tvalid_0's multi_logloss: 1.87274\n",
            "[531]\tvalid_0's multi_logloss: 1.87292\n",
            "[532]\tvalid_0's multi_logloss: 1.87271\n",
            "[533]\tvalid_0's multi_logloss: 1.87255\n",
            "[534]\tvalid_0's multi_logloss: 1.87239\n",
            "[535]\tvalid_0's multi_logloss: 1.87221\n",
            "[536]\tvalid_0's multi_logloss: 1.87205\n",
            "[537]\tvalid_0's multi_logloss: 1.87193\n",
            "[538]\tvalid_0's multi_logloss: 1.87173\n",
            "[539]\tvalid_0's multi_logloss: 1.87158\n",
            "[540]\tvalid_0's multi_logloss: 1.87148\n",
            "[541]\tvalid_0's multi_logloss: 1.87156\n",
            "[542]\tvalid_0's multi_logloss: 1.8714\n",
            "[543]\tvalid_0's multi_logloss: 1.87129\n",
            "[544]\tvalid_0's multi_logloss: 1.87108\n",
            "[545]\tvalid_0's multi_logloss: 1.87105\n",
            "[546]\tvalid_0's multi_logloss: 1.87091\n",
            "[547]\tvalid_0's multi_logloss: 1.87088\n",
            "[548]\tvalid_0's multi_logloss: 1.87077\n",
            "[549]\tvalid_0's multi_logloss: 1.87065\n",
            "[550]\tvalid_0's multi_logloss: 1.87065\n",
            "[551]\tvalid_0's multi_logloss: 1.87058\n",
            "[552]\tvalid_0's multi_logloss: 1.87042\n",
            "[553]\tvalid_0's multi_logloss: 1.8703\n",
            "[554]\tvalid_0's multi_logloss: 1.87021\n",
            "[555]\tvalid_0's multi_logloss: 1.8701\n",
            "[556]\tvalid_0's multi_logloss: 1.86997\n",
            "[557]\tvalid_0's multi_logloss: 1.86995\n",
            "[558]\tvalid_0's multi_logloss: 1.86989\n",
            "[559]\tvalid_0's multi_logloss: 1.86988\n",
            "[560]\tvalid_0's multi_logloss: 1.86991\n",
            "[561]\tvalid_0's multi_logloss: 1.86986\n",
            "[562]\tvalid_0's multi_logloss: 1.86983\n",
            "[563]\tvalid_0's multi_logloss: 1.8697\n",
            "[564]\tvalid_0's multi_logloss: 1.86965\n",
            "[565]\tvalid_0's multi_logloss: 1.8697\n",
            "[566]\tvalid_0's multi_logloss: 1.86953\n",
            "[567]\tvalid_0's multi_logloss: 1.8696\n",
            "[568]\tvalid_0's multi_logloss: 1.86954\n",
            "[569]\tvalid_0's multi_logloss: 1.86951\n",
            "[570]\tvalid_0's multi_logloss: 1.86944\n",
            "[571]\tvalid_0's multi_logloss: 1.86941\n",
            "[572]\tvalid_0's multi_logloss: 1.86929\n",
            "[573]\tvalid_0's multi_logloss: 1.86943\n",
            "[574]\tvalid_0's multi_logloss: 1.86937\n",
            "[575]\tvalid_0's multi_logloss: 1.86921\n",
            "[576]\tvalid_0's multi_logloss: 1.86921\n",
            "[577]\tvalid_0's multi_logloss: 1.86911\n",
            "[578]\tvalid_0's multi_logloss: 1.86908\n",
            "[579]\tvalid_0's multi_logloss: 1.86912\n",
            "[580]\tvalid_0's multi_logloss: 1.86904\n",
            "[581]\tvalid_0's multi_logloss: 1.86909\n",
            "[582]\tvalid_0's multi_logloss: 1.86894\n",
            "[583]\tvalid_0's multi_logloss: 1.86877\n",
            "[584]\tvalid_0's multi_logloss: 1.86876\n",
            "[585]\tvalid_0's multi_logloss: 1.86887\n",
            "[586]\tvalid_0's multi_logloss: 1.86885\n",
            "[587]\tvalid_0's multi_logloss: 1.86879\n",
            "[588]\tvalid_0's multi_logloss: 1.86876\n",
            "[589]\tvalid_0's multi_logloss: 1.86877\n",
            "[590]\tvalid_0's multi_logloss: 1.86864\n",
            "[591]\tvalid_0's multi_logloss: 1.86862\n",
            "[592]\tvalid_0's multi_logloss: 1.86865\n",
            "[593]\tvalid_0's multi_logloss: 1.86856\n",
            "[594]\tvalid_0's multi_logloss: 1.86862\n",
            "[595]\tvalid_0's multi_logloss: 1.86856\n",
            "[596]\tvalid_0's multi_logloss: 1.86854\n",
            "[597]\tvalid_0's multi_logloss: 1.86849\n",
            "[598]\tvalid_0's multi_logloss: 1.8685\n",
            "[599]\tvalid_0's multi_logloss: 1.86849\n",
            "[600]\tvalid_0's multi_logloss: 1.86835\n",
            "[601]\tvalid_0's multi_logloss: 1.86827\n",
            "[602]\tvalid_0's multi_logloss: 1.86821\n",
            "[603]\tvalid_0's multi_logloss: 1.86813\n",
            "[604]\tvalid_0's multi_logloss: 1.86815\n",
            "[605]\tvalid_0's multi_logloss: 1.86819\n",
            "[606]\tvalid_0's multi_logloss: 1.86801\n",
            "[607]\tvalid_0's multi_logloss: 1.86795\n",
            "[608]\tvalid_0's multi_logloss: 1.86789\n",
            "[609]\tvalid_0's multi_logloss: 1.86802\n",
            "[610]\tvalid_0's multi_logloss: 1.86794\n",
            "[611]\tvalid_0's multi_logloss: 1.86786\n",
            "[612]\tvalid_0's multi_logloss: 1.86784\n",
            "[613]\tvalid_0's multi_logloss: 1.86796\n",
            "[614]\tvalid_0's multi_logloss: 1.86788\n",
            "[615]\tvalid_0's multi_logloss: 1.86777\n",
            "[616]\tvalid_0's multi_logloss: 1.86782\n",
            "[617]\tvalid_0's multi_logloss: 1.86792\n",
            "[618]\tvalid_0's multi_logloss: 1.86776\n",
            "[619]\tvalid_0's multi_logloss: 1.8676\n",
            "[620]\tvalid_0's multi_logloss: 1.8675\n",
            "[621]\tvalid_0's multi_logloss: 1.86751\n",
            "[622]\tvalid_0's multi_logloss: 1.86752\n",
            "[623]\tvalid_0's multi_logloss: 1.86749\n",
            "[624]\tvalid_0's multi_logloss: 1.86753\n",
            "[625]\tvalid_0's multi_logloss: 1.86739\n",
            "[626]\tvalid_0's multi_logloss: 1.86746\n",
            "[627]\tvalid_0's multi_logloss: 1.86747\n",
            "[628]\tvalid_0's multi_logloss: 1.8674\n",
            "[629]\tvalid_0's multi_logloss: 1.8673\n",
            "[630]\tvalid_0's multi_logloss: 1.8673\n",
            "[631]\tvalid_0's multi_logloss: 1.86725\n",
            "[632]\tvalid_0's multi_logloss: 1.86716\n",
            "[633]\tvalid_0's multi_logloss: 1.86731\n",
            "[634]\tvalid_0's multi_logloss: 1.86722\n",
            "[635]\tvalid_0's multi_logloss: 1.86722\n",
            "[636]\tvalid_0's multi_logloss: 1.86716\n",
            "[637]\tvalid_0's multi_logloss: 1.86736\n",
            "[638]\tvalid_0's multi_logloss: 1.86736\n",
            "[639]\tvalid_0's multi_logloss: 1.86735\n",
            "[640]\tvalid_0's multi_logloss: 1.86733\n",
            "[641]\tvalid_0's multi_logloss: 1.86727\n",
            "[642]\tvalid_0's multi_logloss: 1.86727\n",
            "[643]\tvalid_0's multi_logloss: 1.86737\n",
            "[644]\tvalid_0's multi_logloss: 1.86748\n",
            "[645]\tvalid_0's multi_logloss: 1.86746\n",
            "[646]\tvalid_0's multi_logloss: 1.86758\n",
            "[647]\tvalid_0's multi_logloss: 1.8676\n",
            "[648]\tvalid_0's multi_logloss: 1.86756\n",
            "[649]\tvalid_0's multi_logloss: 1.86745\n",
            "[650]\tvalid_0's multi_logloss: 1.86754\n",
            "[651]\tvalid_0's multi_logloss: 1.86751\n",
            "[652]\tvalid_0's multi_logloss: 1.86756\n",
            "[653]\tvalid_0's multi_logloss: 1.86756\n",
            "[654]\tvalid_0's multi_logloss: 1.86751\n",
            "[655]\tvalid_0's multi_logloss: 1.86766\n",
            "[656]\tvalid_0's multi_logloss: 1.86768\n",
            "Early stopping, best iteration is:\n",
            "[636]\tvalid_0's multi_logloss: 1.86716\n",
            "Accuracy\n",
            "0.3684210526315789\n",
            "[1]\tvalid_0's multi_logloss: 2.47755\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 2.47071\n",
            "[3]\tvalid_0's multi_logloss: 2.46382\n",
            "[4]\tvalid_0's multi_logloss: 2.45703\n",
            "[5]\tvalid_0's multi_logloss: 2.45036\n",
            "[6]\tvalid_0's multi_logloss: 2.44317\n",
            "[7]\tvalid_0's multi_logloss: 2.43636\n",
            "[8]\tvalid_0's multi_logloss: 2.42981\n",
            "[9]\tvalid_0's multi_logloss: 2.42368\n",
            "[10]\tvalid_0's multi_logloss: 2.41726\n",
            "[11]\tvalid_0's multi_logloss: 2.4113\n",
            "[12]\tvalid_0's multi_logloss: 2.4055\n",
            "[13]\tvalid_0's multi_logloss: 2.39931\n",
            "[14]\tvalid_0's multi_logloss: 2.39338\n",
            "[15]\tvalid_0's multi_logloss: 2.38784\n",
            "[16]\tvalid_0's multi_logloss: 2.38226\n",
            "[17]\tvalid_0's multi_logloss: 2.37733\n",
            "[18]\tvalid_0's multi_logloss: 2.37202\n",
            "[19]\tvalid_0's multi_logloss: 2.3674\n",
            "[20]\tvalid_0's multi_logloss: 2.36285\n",
            "[21]\tvalid_0's multi_logloss: 2.35795\n",
            "[22]\tvalid_0's multi_logloss: 2.35328\n",
            "[23]\tvalid_0's multi_logloss: 2.34897\n",
            "[24]\tvalid_0's multi_logloss: 2.34481\n",
            "[25]\tvalid_0's multi_logloss: 2.34082\n",
            "[26]\tvalid_0's multi_logloss: 2.33654\n",
            "[27]\tvalid_0's multi_logloss: 2.33237\n",
            "[28]\tvalid_0's multi_logloss: 2.32838\n",
            "[29]\tvalid_0's multi_logloss: 2.32443\n",
            "[30]\tvalid_0's multi_logloss: 2.32022\n",
            "[31]\tvalid_0's multi_logloss: 2.3162\n",
            "[32]\tvalid_0's multi_logloss: 2.31212\n",
            "[33]\tvalid_0's multi_logloss: 2.30825\n",
            "[34]\tvalid_0's multi_logloss: 2.30393\n",
            "[35]\tvalid_0's multi_logloss: 2.30022\n",
            "[36]\tvalid_0's multi_logloss: 2.29659\n",
            "[37]\tvalid_0's multi_logloss: 2.29276\n",
            "[38]\tvalid_0's multi_logloss: 2.28893\n",
            "[39]\tvalid_0's multi_logloss: 2.28554\n",
            "[40]\tvalid_0's multi_logloss: 2.28165\n",
            "[41]\tvalid_0's multi_logloss: 2.27797\n",
            "[42]\tvalid_0's multi_logloss: 2.27433\n",
            "[43]\tvalid_0's multi_logloss: 2.27068\n",
            "[44]\tvalid_0's multi_logloss: 2.26749\n",
            "[45]\tvalid_0's multi_logloss: 2.26363\n",
            "[46]\tvalid_0's multi_logloss: 2.2603\n",
            "[47]\tvalid_0's multi_logloss: 2.25708\n",
            "[48]\tvalid_0's multi_logloss: 2.25348\n",
            "[49]\tvalid_0's multi_logloss: 2.25022\n",
            "[50]\tvalid_0's multi_logloss: 2.247\n",
            "[51]\tvalid_0's multi_logloss: 2.24382\n",
            "[52]\tvalid_0's multi_logloss: 2.24063\n",
            "[53]\tvalid_0's multi_logloss: 2.2374\n",
            "[54]\tvalid_0's multi_logloss: 2.23414\n",
            "[55]\tvalid_0's multi_logloss: 2.23121\n",
            "[56]\tvalid_0's multi_logloss: 2.2281\n",
            "[57]\tvalid_0's multi_logloss: 2.22526\n",
            "[58]\tvalid_0's multi_logloss: 2.22215\n",
            "[59]\tvalid_0's multi_logloss: 2.21969\n",
            "[60]\tvalid_0's multi_logloss: 2.2169\n",
            "[61]\tvalid_0's multi_logloss: 2.21408\n",
            "[62]\tvalid_0's multi_logloss: 2.21099\n",
            "[63]\tvalid_0's multi_logloss: 2.20807\n",
            "[64]\tvalid_0's multi_logloss: 2.20567\n",
            "[65]\tvalid_0's multi_logloss: 2.20338\n",
            "[66]\tvalid_0's multi_logloss: 2.20061\n",
            "[67]\tvalid_0's multi_logloss: 2.19806\n",
            "[68]\tvalid_0's multi_logloss: 2.19526\n",
            "[69]\tvalid_0's multi_logloss: 2.19292\n",
            "[70]\tvalid_0's multi_logloss: 2.19036\n",
            "[71]\tvalid_0's multi_logloss: 2.1879\n",
            "[72]\tvalid_0's multi_logloss: 2.18563\n",
            "[73]\tvalid_0's multi_logloss: 2.18311\n",
            "[74]\tvalid_0's multi_logloss: 2.18085\n",
            "[75]\tvalid_0's multi_logloss: 2.17861\n",
            "[76]\tvalid_0's multi_logloss: 2.17629\n",
            "[77]\tvalid_0's multi_logloss: 2.17411\n",
            "[78]\tvalid_0's multi_logloss: 2.17178\n",
            "[79]\tvalid_0's multi_logloss: 2.16963\n",
            "[80]\tvalid_0's multi_logloss: 2.16772\n",
            "[81]\tvalid_0's multi_logloss: 2.16568\n",
            "[82]\tvalid_0's multi_logloss: 2.16337\n",
            "[83]\tvalid_0's multi_logloss: 2.16139\n",
            "[84]\tvalid_0's multi_logloss: 2.15916\n",
            "[85]\tvalid_0's multi_logloss: 2.15726\n",
            "[86]\tvalid_0's multi_logloss: 2.15532\n",
            "[87]\tvalid_0's multi_logloss: 2.15326\n",
            "[88]\tvalid_0's multi_logloss: 2.15124\n",
            "[89]\tvalid_0's multi_logloss: 2.1492\n",
            "[90]\tvalid_0's multi_logloss: 2.14732\n",
            "[91]\tvalid_0's multi_logloss: 2.14535\n",
            "[92]\tvalid_0's multi_logloss: 2.14341\n",
            "[93]\tvalid_0's multi_logloss: 2.14142\n",
            "[94]\tvalid_0's multi_logloss: 2.13948\n",
            "[95]\tvalid_0's multi_logloss: 2.13745\n",
            "[96]\tvalid_0's multi_logloss: 2.1351\n",
            "[97]\tvalid_0's multi_logloss: 2.13317\n",
            "[98]\tvalid_0's multi_logloss: 2.13128\n",
            "[99]\tvalid_0's multi_logloss: 2.1294\n",
            "[100]\tvalid_0's multi_logloss: 2.12742\n",
            "[101]\tvalid_0's multi_logloss: 2.12538\n",
            "[102]\tvalid_0's multi_logloss: 2.12343\n",
            "[103]\tvalid_0's multi_logloss: 2.12166\n",
            "[104]\tvalid_0's multi_logloss: 2.11959\n",
            "[105]\tvalid_0's multi_logloss: 2.11783\n",
            "[106]\tvalid_0's multi_logloss: 2.11595\n",
            "[107]\tvalid_0's multi_logloss: 2.1141\n",
            "[108]\tvalid_0's multi_logloss: 2.11228\n",
            "[109]\tvalid_0's multi_logloss: 2.11057\n",
            "[110]\tvalid_0's multi_logloss: 2.10883\n",
            "[111]\tvalid_0's multi_logloss: 2.10681\n",
            "[112]\tvalid_0's multi_logloss: 2.10512\n",
            "[113]\tvalid_0's multi_logloss: 2.10328\n",
            "[114]\tvalid_0's multi_logloss: 2.10177\n",
            "[115]\tvalid_0's multi_logloss: 2.10005\n",
            "[116]\tvalid_0's multi_logloss: 2.09846\n",
            "[117]\tvalid_0's multi_logloss: 2.09678\n",
            "[118]\tvalid_0's multi_logloss: 2.09507\n",
            "[119]\tvalid_0's multi_logloss: 2.09347\n",
            "[120]\tvalid_0's multi_logloss: 2.09203\n",
            "[121]\tvalid_0's multi_logloss: 2.09041\n",
            "[122]\tvalid_0's multi_logloss: 2.08891\n",
            "[123]\tvalid_0's multi_logloss: 2.08723\n",
            "[124]\tvalid_0's multi_logloss: 2.08578\n",
            "[125]\tvalid_0's multi_logloss: 2.08453\n",
            "[126]\tvalid_0's multi_logloss: 2.08311\n",
            "[127]\tvalid_0's multi_logloss: 2.08169\n",
            "[128]\tvalid_0's multi_logloss: 2.08023\n",
            "[129]\tvalid_0's multi_logloss: 2.07892\n",
            "[130]\tvalid_0's multi_logloss: 2.0775\n",
            "[131]\tvalid_0's multi_logloss: 2.07604\n",
            "[132]\tvalid_0's multi_logloss: 2.07462\n",
            "[133]\tvalid_0's multi_logloss: 2.07346\n",
            "[134]\tvalid_0's multi_logloss: 2.07205\n",
            "[135]\tvalid_0's multi_logloss: 2.0707\n",
            "[136]\tvalid_0's multi_logloss: 2.06951\n",
            "[137]\tvalid_0's multi_logloss: 2.06836\n",
            "[138]\tvalid_0's multi_logloss: 2.06711\n",
            "[139]\tvalid_0's multi_logloss: 2.06578\n",
            "[140]\tvalid_0's multi_logloss: 2.06456\n",
            "[141]\tvalid_0's multi_logloss: 2.06326\n",
            "[142]\tvalid_0's multi_logloss: 2.06204\n",
            "[143]\tvalid_0's multi_logloss: 2.06084\n",
            "[144]\tvalid_0's multi_logloss: 2.05941\n",
            "[145]\tvalid_0's multi_logloss: 2.05822\n",
            "[146]\tvalid_0's multi_logloss: 2.05692\n",
            "[147]\tvalid_0's multi_logloss: 2.05556\n",
            "[148]\tvalid_0's multi_logloss: 2.05439\n",
            "[149]\tvalid_0's multi_logloss: 2.0531\n",
            "[150]\tvalid_0's multi_logloss: 2.05206\n",
            "[151]\tvalid_0's multi_logloss: 2.05071\n",
            "[152]\tvalid_0's multi_logloss: 2.04958\n",
            "[153]\tvalid_0's multi_logloss: 2.04854\n",
            "[154]\tvalid_0's multi_logloss: 2.04737\n",
            "[155]\tvalid_0's multi_logloss: 2.04602\n",
            "[156]\tvalid_0's multi_logloss: 2.04486\n",
            "[157]\tvalid_0's multi_logloss: 2.04373\n",
            "[158]\tvalid_0's multi_logloss: 2.04282\n",
            "[159]\tvalid_0's multi_logloss: 2.04153\n",
            "[160]\tvalid_0's multi_logloss: 2.04038\n",
            "[161]\tvalid_0's multi_logloss: 2.03921\n",
            "[162]\tvalid_0's multi_logloss: 2.03799\n",
            "[163]\tvalid_0's multi_logloss: 2.03677\n",
            "[164]\tvalid_0's multi_logloss: 2.03561\n",
            "[165]\tvalid_0's multi_logloss: 2.03462\n",
            "[166]\tvalid_0's multi_logloss: 2.03374\n",
            "[167]\tvalid_0's multi_logloss: 2.03244\n",
            "[168]\tvalid_0's multi_logloss: 2.03127\n",
            "[169]\tvalid_0's multi_logloss: 2.03019\n",
            "[170]\tvalid_0's multi_logloss: 2.02895\n",
            "[171]\tvalid_0's multi_logloss: 2.02806\n",
            "[172]\tvalid_0's multi_logloss: 2.0268\n",
            "[173]\tvalid_0's multi_logloss: 2.02581\n",
            "[174]\tvalid_0's multi_logloss: 2.02463\n",
            "[175]\tvalid_0's multi_logloss: 2.02388\n",
            "[176]\tvalid_0's multi_logloss: 2.02274\n",
            "[177]\tvalid_0's multi_logloss: 2.02168\n",
            "[178]\tvalid_0's multi_logloss: 2.02067\n",
            "[179]\tvalid_0's multi_logloss: 2.01965\n",
            "[180]\tvalid_0's multi_logloss: 2.01858\n",
            "[181]\tvalid_0's multi_logloss: 2.01769\n",
            "[182]\tvalid_0's multi_logloss: 2.01669\n",
            "[183]\tvalid_0's multi_logloss: 2.0158\n",
            "[184]\tvalid_0's multi_logloss: 2.01491\n",
            "[185]\tvalid_0's multi_logloss: 2.01403\n",
            "[186]\tvalid_0's multi_logloss: 2.01313\n",
            "[187]\tvalid_0's multi_logloss: 2.01214\n",
            "[188]\tvalid_0's multi_logloss: 2.01125\n",
            "[189]\tvalid_0's multi_logloss: 2.01033\n",
            "[190]\tvalid_0's multi_logloss: 2.00944\n",
            "[191]\tvalid_0's multi_logloss: 2.0087\n",
            "[192]\tvalid_0's multi_logloss: 2.00783\n",
            "[193]\tvalid_0's multi_logloss: 2.00679\n",
            "[194]\tvalid_0's multi_logloss: 2.00598\n",
            "[195]\tvalid_0's multi_logloss: 2.00502\n",
            "[196]\tvalid_0's multi_logloss: 2.00433\n",
            "[197]\tvalid_0's multi_logloss: 2.00345\n",
            "[198]\tvalid_0's multi_logloss: 2.00276\n",
            "[199]\tvalid_0's multi_logloss: 2.0019\n",
            "[200]\tvalid_0's multi_logloss: 2.00092\n",
            "[201]\tvalid_0's multi_logloss: 2.00026\n",
            "[202]\tvalid_0's multi_logloss: 1.99953\n",
            "[203]\tvalid_0's multi_logloss: 1.99859\n",
            "[204]\tvalid_0's multi_logloss: 1.99767\n",
            "[205]\tvalid_0's multi_logloss: 1.99679\n",
            "[206]\tvalid_0's multi_logloss: 1.996\n",
            "[207]\tvalid_0's multi_logloss: 1.99506\n",
            "[208]\tvalid_0's multi_logloss: 1.99408\n",
            "[209]\tvalid_0's multi_logloss: 1.9934\n",
            "[210]\tvalid_0's multi_logloss: 1.99259\n",
            "[211]\tvalid_0's multi_logloss: 1.99157\n",
            "[212]\tvalid_0's multi_logloss: 1.99059\n",
            "[213]\tvalid_0's multi_logloss: 1.98969\n",
            "[214]\tvalid_0's multi_logloss: 1.98884\n",
            "[215]\tvalid_0's multi_logloss: 1.98777\n",
            "[216]\tvalid_0's multi_logloss: 1.98694\n",
            "[217]\tvalid_0's multi_logloss: 1.98601\n",
            "[218]\tvalid_0's multi_logloss: 1.98526\n",
            "[219]\tvalid_0's multi_logloss: 1.98429\n",
            "[220]\tvalid_0's multi_logloss: 1.98334\n",
            "[221]\tvalid_0's multi_logloss: 1.98242\n",
            "[222]\tvalid_0's multi_logloss: 1.98165\n",
            "[223]\tvalid_0's multi_logloss: 1.9808\n",
            "[224]\tvalid_0's multi_logloss: 1.97987\n",
            "[225]\tvalid_0's multi_logloss: 1.9791\n",
            "[226]\tvalid_0's multi_logloss: 1.97798\n",
            "[227]\tvalid_0's multi_logloss: 1.97728\n",
            "[228]\tvalid_0's multi_logloss: 1.97673\n",
            "[229]\tvalid_0's multi_logloss: 1.97583\n",
            "[230]\tvalid_0's multi_logloss: 1.97512\n",
            "[231]\tvalid_0's multi_logloss: 1.97431\n",
            "[232]\tvalid_0's multi_logloss: 1.97358\n",
            "[233]\tvalid_0's multi_logloss: 1.97267\n",
            "[234]\tvalid_0's multi_logloss: 1.97192\n",
            "[235]\tvalid_0's multi_logloss: 1.97112\n",
            "[236]\tvalid_0's multi_logloss: 1.97036\n",
            "[237]\tvalid_0's multi_logloss: 1.96959\n",
            "[238]\tvalid_0's multi_logloss: 1.96889\n",
            "[239]\tvalid_0's multi_logloss: 1.96835\n",
            "[240]\tvalid_0's multi_logloss: 1.96763\n",
            "[241]\tvalid_0's multi_logloss: 1.9667\n",
            "[242]\tvalid_0's multi_logloss: 1.96605\n",
            "[243]\tvalid_0's multi_logloss: 1.96541\n",
            "[244]\tvalid_0's multi_logloss: 1.96468\n",
            "[245]\tvalid_0's multi_logloss: 1.96399\n",
            "[246]\tvalid_0's multi_logloss: 1.96334\n",
            "[247]\tvalid_0's multi_logloss: 1.96236\n",
            "[248]\tvalid_0's multi_logloss: 1.96179\n",
            "[249]\tvalid_0's multi_logloss: 1.96114\n",
            "[250]\tvalid_0's multi_logloss: 1.96023\n",
            "[251]\tvalid_0's multi_logloss: 1.95961\n",
            "[252]\tvalid_0's multi_logloss: 1.95899\n",
            "[253]\tvalid_0's multi_logloss: 1.95833\n",
            "[254]\tvalid_0's multi_logloss: 1.95761\n",
            "[255]\tvalid_0's multi_logloss: 1.95691\n",
            "[256]\tvalid_0's multi_logloss: 1.95636\n",
            "[257]\tvalid_0's multi_logloss: 1.95588\n",
            "[258]\tvalid_0's multi_logloss: 1.95542\n",
            "[259]\tvalid_0's multi_logloss: 1.95484\n",
            "[260]\tvalid_0's multi_logloss: 1.9544\n",
            "[261]\tvalid_0's multi_logloss: 1.95356\n",
            "[262]\tvalid_0's multi_logloss: 1.95292\n",
            "[263]\tvalid_0's multi_logloss: 1.95234\n",
            "[264]\tvalid_0's multi_logloss: 1.95171\n",
            "[265]\tvalid_0's multi_logloss: 1.95123\n",
            "[266]\tvalid_0's multi_logloss: 1.95049\n",
            "[267]\tvalid_0's multi_logloss: 1.94996\n",
            "[268]\tvalid_0's multi_logloss: 1.94944\n",
            "[269]\tvalid_0's multi_logloss: 1.94887\n",
            "[270]\tvalid_0's multi_logloss: 1.94851\n",
            "[271]\tvalid_0's multi_logloss: 1.94804\n",
            "[272]\tvalid_0's multi_logloss: 1.94749\n",
            "[273]\tvalid_0's multi_logloss: 1.94707\n",
            "[274]\tvalid_0's multi_logloss: 1.94663\n",
            "[275]\tvalid_0's multi_logloss: 1.94591\n",
            "[276]\tvalid_0's multi_logloss: 1.94538\n",
            "[277]\tvalid_0's multi_logloss: 1.94499\n",
            "[278]\tvalid_0's multi_logloss: 1.94454\n",
            "[279]\tvalid_0's multi_logloss: 1.94389\n",
            "[280]\tvalid_0's multi_logloss: 1.9434\n",
            "[281]\tvalid_0's multi_logloss: 1.94297\n",
            "[282]\tvalid_0's multi_logloss: 1.94237\n",
            "[283]\tvalid_0's multi_logloss: 1.94184\n",
            "[284]\tvalid_0's multi_logloss: 1.94126\n",
            "[285]\tvalid_0's multi_logloss: 1.94085\n",
            "[286]\tvalid_0's multi_logloss: 1.94041\n",
            "[287]\tvalid_0's multi_logloss: 1.94002\n",
            "[288]\tvalid_0's multi_logloss: 1.93979\n",
            "[289]\tvalid_0's multi_logloss: 1.93907\n",
            "[290]\tvalid_0's multi_logloss: 1.93856\n",
            "[291]\tvalid_0's multi_logloss: 1.93792\n",
            "[292]\tvalid_0's multi_logloss: 1.93751\n",
            "[293]\tvalid_0's multi_logloss: 1.93696\n",
            "[294]\tvalid_0's multi_logloss: 1.93657\n",
            "[295]\tvalid_0's multi_logloss: 1.93613\n",
            "[296]\tvalid_0's multi_logloss: 1.93575\n",
            "[297]\tvalid_0's multi_logloss: 1.93517\n",
            "[298]\tvalid_0's multi_logloss: 1.93473\n",
            "[299]\tvalid_0's multi_logloss: 1.93429\n",
            "[300]\tvalid_0's multi_logloss: 1.93383\n",
            "[301]\tvalid_0's multi_logloss: 1.93333\n",
            "[302]\tvalid_0's multi_logloss: 1.93267\n",
            "[303]\tvalid_0's multi_logloss: 1.93236\n",
            "[304]\tvalid_0's multi_logloss: 1.93186\n",
            "[305]\tvalid_0's multi_logloss: 1.93152\n",
            "[306]\tvalid_0's multi_logloss: 1.93113\n",
            "[307]\tvalid_0's multi_logloss: 1.93057\n",
            "[308]\tvalid_0's multi_logloss: 1.93015\n",
            "[309]\tvalid_0's multi_logloss: 1.92974\n",
            "[310]\tvalid_0's multi_logloss: 1.92925\n",
            "[311]\tvalid_0's multi_logloss: 1.92888\n",
            "[312]\tvalid_0's multi_logloss: 1.9285\n",
            "[313]\tvalid_0's multi_logloss: 1.92813\n",
            "[314]\tvalid_0's multi_logloss: 1.92757\n",
            "[315]\tvalid_0's multi_logloss: 1.92715\n",
            "[316]\tvalid_0's multi_logloss: 1.9267\n",
            "[317]\tvalid_0's multi_logloss: 1.92643\n",
            "[318]\tvalid_0's multi_logloss: 1.92614\n",
            "[319]\tvalid_0's multi_logloss: 1.92552\n",
            "[320]\tvalid_0's multi_logloss: 1.92511\n",
            "[321]\tvalid_0's multi_logloss: 1.92478\n",
            "[322]\tvalid_0's multi_logloss: 1.92419\n",
            "[323]\tvalid_0's multi_logloss: 1.92398\n",
            "[324]\tvalid_0's multi_logloss: 1.92335\n",
            "[325]\tvalid_0's multi_logloss: 1.92293\n",
            "[326]\tvalid_0's multi_logloss: 1.92271\n",
            "[327]\tvalid_0's multi_logloss: 1.9222\n",
            "[328]\tvalid_0's multi_logloss: 1.92161\n",
            "[329]\tvalid_0's multi_logloss: 1.92131\n",
            "[330]\tvalid_0's multi_logloss: 1.921\n",
            "[331]\tvalid_0's multi_logloss: 1.92066\n",
            "[332]\tvalid_0's multi_logloss: 1.92017\n",
            "[333]\tvalid_0's multi_logloss: 1.91984\n",
            "[334]\tvalid_0's multi_logloss: 1.91954\n",
            "[335]\tvalid_0's multi_logloss: 1.91908\n",
            "[336]\tvalid_0's multi_logloss: 1.91872\n",
            "[337]\tvalid_0's multi_logloss: 1.91843\n",
            "[338]\tvalid_0's multi_logloss: 1.91797\n",
            "[339]\tvalid_0's multi_logloss: 1.9175\n",
            "[340]\tvalid_0's multi_logloss: 1.91727\n",
            "[341]\tvalid_0's multi_logloss: 1.9169\n",
            "[342]\tvalid_0's multi_logloss: 1.91667\n",
            "[343]\tvalid_0's multi_logloss: 1.91627\n",
            "[344]\tvalid_0's multi_logloss: 1.91612\n",
            "[345]\tvalid_0's multi_logloss: 1.91578\n",
            "[346]\tvalid_0's multi_logloss: 1.91545\n",
            "[347]\tvalid_0's multi_logloss: 1.915\n",
            "[348]\tvalid_0's multi_logloss: 1.91461\n",
            "[349]\tvalid_0's multi_logloss: 1.91438\n",
            "[350]\tvalid_0's multi_logloss: 1.91426\n",
            "[351]\tvalid_0's multi_logloss: 1.91385\n",
            "[352]\tvalid_0's multi_logloss: 1.91354\n",
            "[353]\tvalid_0's multi_logloss: 1.91328\n",
            "[354]\tvalid_0's multi_logloss: 1.91303\n",
            "[355]\tvalid_0's multi_logloss: 1.91272\n",
            "[356]\tvalid_0's multi_logloss: 1.91233\n",
            "[357]\tvalid_0's multi_logloss: 1.91216\n",
            "[358]\tvalid_0's multi_logloss: 1.91194\n",
            "[359]\tvalid_0's multi_logloss: 1.91169\n",
            "[360]\tvalid_0's multi_logloss: 1.91144\n",
            "[361]\tvalid_0's multi_logloss: 1.91129\n",
            "[362]\tvalid_0's multi_logloss: 1.9111\n",
            "[363]\tvalid_0's multi_logloss: 1.91087\n",
            "[364]\tvalid_0's multi_logloss: 1.91078\n",
            "[365]\tvalid_0's multi_logloss: 1.91041\n",
            "[366]\tvalid_0's multi_logloss: 1.91\n",
            "[367]\tvalid_0's multi_logloss: 1.90997\n",
            "[368]\tvalid_0's multi_logloss: 1.90977\n",
            "[369]\tvalid_0's multi_logloss: 1.9095\n",
            "[370]\tvalid_0's multi_logloss: 1.90927\n",
            "[371]\tvalid_0's multi_logloss: 1.90912\n",
            "[372]\tvalid_0's multi_logloss: 1.90885\n",
            "[373]\tvalid_0's multi_logloss: 1.90864\n",
            "[374]\tvalid_0's multi_logloss: 1.90835\n",
            "[375]\tvalid_0's multi_logloss: 1.90815\n",
            "[376]\tvalid_0's multi_logloss: 1.90792\n",
            "[377]\tvalid_0's multi_logloss: 1.90775\n",
            "[378]\tvalid_0's multi_logloss: 1.90731\n",
            "[379]\tvalid_0's multi_logloss: 1.90714\n",
            "[380]\tvalid_0's multi_logloss: 1.9069\n",
            "[381]\tvalid_0's multi_logloss: 1.90668\n",
            "[382]\tvalid_0's multi_logloss: 1.90632\n",
            "[383]\tvalid_0's multi_logloss: 1.90623\n",
            "[384]\tvalid_0's multi_logloss: 1.90601\n",
            "[385]\tvalid_0's multi_logloss: 1.90564\n",
            "[386]\tvalid_0's multi_logloss: 1.9055\n",
            "[387]\tvalid_0's multi_logloss: 1.9053\n",
            "[388]\tvalid_0's multi_logloss: 1.90509\n",
            "[389]\tvalid_0's multi_logloss: 1.90476\n",
            "[390]\tvalid_0's multi_logloss: 1.90459\n",
            "[391]\tvalid_0's multi_logloss: 1.9044\n",
            "[392]\tvalid_0's multi_logloss: 1.90409\n",
            "[393]\tvalid_0's multi_logloss: 1.90378\n",
            "[394]\tvalid_0's multi_logloss: 1.90364\n",
            "[395]\tvalid_0's multi_logloss: 1.90351\n",
            "[396]\tvalid_0's multi_logloss: 1.90331\n",
            "[397]\tvalid_0's multi_logloss: 1.90308\n",
            "[398]\tvalid_0's multi_logloss: 1.90299\n",
            "[399]\tvalid_0's multi_logloss: 1.90283\n",
            "[400]\tvalid_0's multi_logloss: 1.90252\n",
            "[401]\tvalid_0's multi_logloss: 1.90239\n",
            "[402]\tvalid_0's multi_logloss: 1.90222\n",
            "[403]\tvalid_0's multi_logloss: 1.9022\n",
            "[404]\tvalid_0's multi_logloss: 1.90209\n",
            "[405]\tvalid_0's multi_logloss: 1.9019\n",
            "[406]\tvalid_0's multi_logloss: 1.9017\n",
            "[407]\tvalid_0's multi_logloss: 1.90168\n",
            "[408]\tvalid_0's multi_logloss: 1.90144\n",
            "[409]\tvalid_0's multi_logloss: 1.90129\n",
            "[410]\tvalid_0's multi_logloss: 1.90108\n",
            "[411]\tvalid_0's multi_logloss: 1.90098\n",
            "[412]\tvalid_0's multi_logloss: 1.90088\n",
            "[413]\tvalid_0's multi_logloss: 1.90089\n",
            "[414]\tvalid_0's multi_logloss: 1.90079\n",
            "[415]\tvalid_0's multi_logloss: 1.9006\n",
            "[416]\tvalid_0's multi_logloss: 1.90062\n",
            "[417]\tvalid_0's multi_logloss: 1.90036\n",
            "[418]\tvalid_0's multi_logloss: 1.9003\n",
            "[419]\tvalid_0's multi_logloss: 1.90018\n",
            "[420]\tvalid_0's multi_logloss: 1.90001\n",
            "[421]\tvalid_0's multi_logloss: 1.89988\n",
            "[422]\tvalid_0's multi_logloss: 1.8997\n",
            "[423]\tvalid_0's multi_logloss: 1.89961\n",
            "[424]\tvalid_0's multi_logloss: 1.89954\n",
            "[425]\tvalid_0's multi_logloss: 1.8995\n",
            "[426]\tvalid_0's multi_logloss: 1.89939\n",
            "[427]\tvalid_0's multi_logloss: 1.89918\n",
            "[428]\tvalid_0's multi_logloss: 1.89903\n",
            "[429]\tvalid_0's multi_logloss: 1.89886\n",
            "[430]\tvalid_0's multi_logloss: 1.89873\n",
            "[431]\tvalid_0's multi_logloss: 1.89856\n",
            "[432]\tvalid_0's multi_logloss: 1.89855\n",
            "[433]\tvalid_0's multi_logloss: 1.89836\n",
            "[434]\tvalid_0's multi_logloss: 1.89827\n",
            "[435]\tvalid_0's multi_logloss: 1.89806\n",
            "[436]\tvalid_0's multi_logloss: 1.89806\n",
            "[437]\tvalid_0's multi_logloss: 1.89782\n",
            "[438]\tvalid_0's multi_logloss: 1.89757\n",
            "[439]\tvalid_0's multi_logloss: 1.89748\n",
            "[440]\tvalid_0's multi_logloss: 1.89737\n",
            "[441]\tvalid_0's multi_logloss: 1.89726\n",
            "[442]\tvalid_0's multi_logloss: 1.89728\n",
            "[443]\tvalid_0's multi_logloss: 1.89699\n",
            "[444]\tvalid_0's multi_logloss: 1.89704\n",
            "[445]\tvalid_0's multi_logloss: 1.89688\n",
            "[446]\tvalid_0's multi_logloss: 1.89659\n",
            "[447]\tvalid_0's multi_logloss: 1.89653\n",
            "[448]\tvalid_0's multi_logloss: 1.89634\n",
            "[449]\tvalid_0's multi_logloss: 1.89636\n",
            "[450]\tvalid_0's multi_logloss: 1.89617\n",
            "[451]\tvalid_0's multi_logloss: 1.89609\n",
            "[452]\tvalid_0's multi_logloss: 1.89584\n",
            "[453]\tvalid_0's multi_logloss: 1.89554\n",
            "[454]\tvalid_0's multi_logloss: 1.89555\n",
            "[455]\tvalid_0's multi_logloss: 1.89551\n",
            "[456]\tvalid_0's multi_logloss: 1.89521\n",
            "[457]\tvalid_0's multi_logloss: 1.89512\n",
            "[458]\tvalid_0's multi_logloss: 1.89499\n",
            "[459]\tvalid_0's multi_logloss: 1.89497\n",
            "[460]\tvalid_0's multi_logloss: 1.8948\n",
            "[461]\tvalid_0's multi_logloss: 1.89471\n",
            "[462]\tvalid_0's multi_logloss: 1.89443\n",
            "[463]\tvalid_0's multi_logloss: 1.89419\n",
            "[464]\tvalid_0's multi_logloss: 1.89413\n",
            "[465]\tvalid_0's multi_logloss: 1.8939\n",
            "[466]\tvalid_0's multi_logloss: 1.89365\n",
            "[467]\tvalid_0's multi_logloss: 1.89361\n",
            "[468]\tvalid_0's multi_logloss: 1.89346\n",
            "[469]\tvalid_0's multi_logloss: 1.89329\n",
            "[470]\tvalid_0's multi_logloss: 1.89311\n",
            "[471]\tvalid_0's multi_logloss: 1.89295\n",
            "[472]\tvalid_0's multi_logloss: 1.89283\n",
            "[473]\tvalid_0's multi_logloss: 1.89265\n",
            "[474]\tvalid_0's multi_logloss: 1.89256\n",
            "[475]\tvalid_0's multi_logloss: 1.89248\n",
            "[476]\tvalid_0's multi_logloss: 1.89232\n",
            "[477]\tvalid_0's multi_logloss: 1.8922\n",
            "[478]\tvalid_0's multi_logloss: 1.8921\n",
            "[479]\tvalid_0's multi_logloss: 1.89203\n",
            "[480]\tvalid_0's multi_logloss: 1.89194\n",
            "[481]\tvalid_0's multi_logloss: 1.89189\n",
            "[482]\tvalid_0's multi_logloss: 1.89178\n",
            "[483]\tvalid_0's multi_logloss: 1.89184\n",
            "[484]\tvalid_0's multi_logloss: 1.89156\n",
            "[485]\tvalid_0's multi_logloss: 1.89139\n",
            "[486]\tvalid_0's multi_logloss: 1.89132\n",
            "[487]\tvalid_0's multi_logloss: 1.89129\n",
            "[488]\tvalid_0's multi_logloss: 1.89117\n",
            "[489]\tvalid_0's multi_logloss: 1.89099\n",
            "[490]\tvalid_0's multi_logloss: 1.89078\n",
            "[491]\tvalid_0's multi_logloss: 1.8906\n",
            "[492]\tvalid_0's multi_logloss: 1.89047\n",
            "[493]\tvalid_0's multi_logloss: 1.89028\n",
            "[494]\tvalid_0's multi_logloss: 1.89019\n",
            "[495]\tvalid_0's multi_logloss: 1.89017\n",
            "[496]\tvalid_0's multi_logloss: 1.89005\n",
            "[497]\tvalid_0's multi_logloss: 1.89\n",
            "[498]\tvalid_0's multi_logloss: 1.8899\n",
            "[499]\tvalid_0's multi_logloss: 1.8899\n",
            "[500]\tvalid_0's multi_logloss: 1.88991\n",
            "[501]\tvalid_0's multi_logloss: 1.88963\n",
            "[502]\tvalid_0's multi_logloss: 1.88943\n",
            "[503]\tvalid_0's multi_logloss: 1.88941\n",
            "[504]\tvalid_0's multi_logloss: 1.88936\n",
            "[505]\tvalid_0's multi_logloss: 1.88908\n",
            "[506]\tvalid_0's multi_logloss: 1.88901\n",
            "[507]\tvalid_0's multi_logloss: 1.88896\n",
            "[508]\tvalid_0's multi_logloss: 1.88897\n",
            "[509]\tvalid_0's multi_logloss: 1.88892\n",
            "[510]\tvalid_0's multi_logloss: 1.88901\n",
            "[511]\tvalid_0's multi_logloss: 1.88877\n",
            "[512]\tvalid_0's multi_logloss: 1.88872\n",
            "[513]\tvalid_0's multi_logloss: 1.88859\n",
            "[514]\tvalid_0's multi_logloss: 1.88851\n",
            "[515]\tvalid_0's multi_logloss: 1.88835\n",
            "[516]\tvalid_0's multi_logloss: 1.88821\n",
            "[517]\tvalid_0's multi_logloss: 1.88811\n",
            "[518]\tvalid_0's multi_logloss: 1.88789\n",
            "[519]\tvalid_0's multi_logloss: 1.88785\n",
            "[520]\tvalid_0's multi_logloss: 1.88781\n",
            "[521]\tvalid_0's multi_logloss: 1.88782\n",
            "[522]\tvalid_0's multi_logloss: 1.88772\n",
            "[523]\tvalid_0's multi_logloss: 1.88761\n",
            "[524]\tvalid_0's multi_logloss: 1.8874\n",
            "[525]\tvalid_0's multi_logloss: 1.88729\n",
            "[526]\tvalid_0's multi_logloss: 1.88716\n",
            "[527]\tvalid_0's multi_logloss: 1.88716\n",
            "[528]\tvalid_0's multi_logloss: 1.88697\n",
            "[529]\tvalid_0's multi_logloss: 1.88679\n",
            "[530]\tvalid_0's multi_logloss: 1.88673\n",
            "[531]\tvalid_0's multi_logloss: 1.8868\n",
            "[532]\tvalid_0's multi_logloss: 1.8866\n",
            "[533]\tvalid_0's multi_logloss: 1.8866\n",
            "[534]\tvalid_0's multi_logloss: 1.8866\n",
            "[535]\tvalid_0's multi_logloss: 1.88658\n",
            "[536]\tvalid_0's multi_logloss: 1.88643\n",
            "[537]\tvalid_0's multi_logloss: 1.88639\n",
            "[538]\tvalid_0's multi_logloss: 1.88651\n",
            "[539]\tvalid_0's multi_logloss: 1.88645\n",
            "[540]\tvalid_0's multi_logloss: 1.88621\n",
            "[541]\tvalid_0's multi_logloss: 1.88613\n",
            "[542]\tvalid_0's multi_logloss: 1.88612\n",
            "[543]\tvalid_0's multi_logloss: 1.88591\n",
            "[544]\tvalid_0's multi_logloss: 1.88582\n",
            "[545]\tvalid_0's multi_logloss: 1.8857\n",
            "[546]\tvalid_0's multi_logloss: 1.88559\n",
            "[547]\tvalid_0's multi_logloss: 1.88541\n",
            "[548]\tvalid_0's multi_logloss: 1.88527\n",
            "[549]\tvalid_0's multi_logloss: 1.88521\n",
            "[550]\tvalid_0's multi_logloss: 1.88508\n",
            "[551]\tvalid_0's multi_logloss: 1.88497\n",
            "[552]\tvalid_0's multi_logloss: 1.88483\n",
            "[553]\tvalid_0's multi_logloss: 1.88471\n",
            "[554]\tvalid_0's multi_logloss: 1.88468\n",
            "[555]\tvalid_0's multi_logloss: 1.88461\n",
            "[556]\tvalid_0's multi_logloss: 1.88457\n",
            "[557]\tvalid_0's multi_logloss: 1.88459\n",
            "[558]\tvalid_0's multi_logloss: 1.88445\n",
            "[559]\tvalid_0's multi_logloss: 1.88431\n",
            "[560]\tvalid_0's multi_logloss: 1.88423\n",
            "[561]\tvalid_0's multi_logloss: 1.88405\n",
            "[562]\tvalid_0's multi_logloss: 1.88394\n",
            "[563]\tvalid_0's multi_logloss: 1.8838\n",
            "[564]\tvalid_0's multi_logloss: 1.88368\n",
            "[565]\tvalid_0's multi_logloss: 1.88363\n",
            "[566]\tvalid_0's multi_logloss: 1.88339\n",
            "[567]\tvalid_0's multi_logloss: 1.8834\n",
            "[568]\tvalid_0's multi_logloss: 1.88337\n",
            "[569]\tvalid_0's multi_logloss: 1.88347\n",
            "[570]\tvalid_0's multi_logloss: 1.88334\n",
            "[571]\tvalid_0's multi_logloss: 1.88334\n",
            "[572]\tvalid_0's multi_logloss: 1.88329\n",
            "[573]\tvalid_0's multi_logloss: 1.88309\n",
            "[574]\tvalid_0's multi_logloss: 1.88312\n",
            "[575]\tvalid_0's multi_logloss: 1.88309\n",
            "[576]\tvalid_0's multi_logloss: 1.88288\n",
            "[577]\tvalid_0's multi_logloss: 1.88276\n",
            "[578]\tvalid_0's multi_logloss: 1.8829\n",
            "[579]\tvalid_0's multi_logloss: 1.88283\n",
            "[580]\tvalid_0's multi_logloss: 1.88277\n",
            "[581]\tvalid_0's multi_logloss: 1.88283\n",
            "[582]\tvalid_0's multi_logloss: 1.88254\n",
            "[583]\tvalid_0's multi_logloss: 1.88246\n",
            "[584]\tvalid_0's multi_logloss: 1.88244\n",
            "[585]\tvalid_0's multi_logloss: 1.88245\n",
            "[586]\tvalid_0's multi_logloss: 1.88246\n",
            "[587]\tvalid_0's multi_logloss: 1.88246\n",
            "[588]\tvalid_0's multi_logloss: 1.88264\n",
            "[589]\tvalid_0's multi_logloss: 1.88269\n",
            "[590]\tvalid_0's multi_logloss: 1.88249\n",
            "[591]\tvalid_0's multi_logloss: 1.88259\n",
            "[592]\tvalid_0's multi_logloss: 1.88239\n",
            "[593]\tvalid_0's multi_logloss: 1.88231\n",
            "[594]\tvalid_0's multi_logloss: 1.88225\n",
            "[595]\tvalid_0's multi_logloss: 1.8822\n",
            "[596]\tvalid_0's multi_logloss: 1.88212\n",
            "[597]\tvalid_0's multi_logloss: 1.88211\n",
            "[598]\tvalid_0's multi_logloss: 1.882\n",
            "[599]\tvalid_0's multi_logloss: 1.88203\n",
            "[600]\tvalid_0's multi_logloss: 1.88202\n",
            "[601]\tvalid_0's multi_logloss: 1.88194\n",
            "[602]\tvalid_0's multi_logloss: 1.88188\n",
            "[603]\tvalid_0's multi_logloss: 1.88172\n",
            "[604]\tvalid_0's multi_logloss: 1.88163\n",
            "[605]\tvalid_0's multi_logloss: 1.88157\n",
            "[606]\tvalid_0's multi_logloss: 1.88163\n",
            "[607]\tvalid_0's multi_logloss: 1.88155\n",
            "[608]\tvalid_0's multi_logloss: 1.88151\n",
            "[609]\tvalid_0's multi_logloss: 1.88134\n",
            "[610]\tvalid_0's multi_logloss: 1.88133\n",
            "[611]\tvalid_0's multi_logloss: 1.88127\n",
            "[612]\tvalid_0's multi_logloss: 1.88133\n",
            "[613]\tvalid_0's multi_logloss: 1.88129\n",
            "[614]\tvalid_0's multi_logloss: 1.88113\n",
            "[615]\tvalid_0's multi_logloss: 1.88103\n",
            "[616]\tvalid_0's multi_logloss: 1.88092\n",
            "[617]\tvalid_0's multi_logloss: 1.88091\n",
            "[618]\tvalid_0's multi_logloss: 1.88093\n",
            "[619]\tvalid_0's multi_logloss: 1.88087\n",
            "[620]\tvalid_0's multi_logloss: 1.88094\n",
            "[621]\tvalid_0's multi_logloss: 1.88087\n",
            "[622]\tvalid_0's multi_logloss: 1.88089\n",
            "[623]\tvalid_0's multi_logloss: 1.88078\n",
            "[624]\tvalid_0's multi_logloss: 1.88081\n",
            "[625]\tvalid_0's multi_logloss: 1.88057\n",
            "[626]\tvalid_0's multi_logloss: 1.88059\n",
            "[627]\tvalid_0's multi_logloss: 1.88052\n",
            "[628]\tvalid_0's multi_logloss: 1.88047\n",
            "[629]\tvalid_0's multi_logloss: 1.88031\n",
            "[630]\tvalid_0's multi_logloss: 1.8803\n",
            "[631]\tvalid_0's multi_logloss: 1.88042\n",
            "[632]\tvalid_0's multi_logloss: 1.88046\n",
            "[633]\tvalid_0's multi_logloss: 1.88054\n",
            "[634]\tvalid_0's multi_logloss: 1.88055\n",
            "[635]\tvalid_0's multi_logloss: 1.88046\n",
            "[636]\tvalid_0's multi_logloss: 1.88051\n",
            "[637]\tvalid_0's multi_logloss: 1.88041\n",
            "[638]\tvalid_0's multi_logloss: 1.88051\n",
            "[639]\tvalid_0's multi_logloss: 1.88043\n",
            "[640]\tvalid_0's multi_logloss: 1.88041\n",
            "[641]\tvalid_0's multi_logloss: 1.88046\n",
            "[642]\tvalid_0's multi_logloss: 1.88043\n",
            "[643]\tvalid_0's multi_logloss: 1.88051\n",
            "[644]\tvalid_0's multi_logloss: 1.88037\n",
            "[645]\tvalid_0's multi_logloss: 1.88026\n",
            "[646]\tvalid_0's multi_logloss: 1.88031\n",
            "[647]\tvalid_0's multi_logloss: 1.88024\n",
            "[648]\tvalid_0's multi_logloss: 1.88029\n",
            "[649]\tvalid_0's multi_logloss: 1.88023\n",
            "[650]\tvalid_0's multi_logloss: 1.88031\n",
            "[651]\tvalid_0's multi_logloss: 1.88015\n",
            "[652]\tvalid_0's multi_logloss: 1.88016\n",
            "[653]\tvalid_0's multi_logloss: 1.88022\n",
            "[654]\tvalid_0's multi_logloss: 1.88019\n",
            "[655]\tvalid_0's multi_logloss: 1.88006\n",
            "[656]\tvalid_0's multi_logloss: 1.88002\n",
            "[657]\tvalid_0's multi_logloss: 1.88009\n",
            "[658]\tvalid_0's multi_logloss: 1.87998\n",
            "[659]\tvalid_0's multi_logloss: 1.88001\n",
            "[660]\tvalid_0's multi_logloss: 1.88014\n",
            "[661]\tvalid_0's multi_logloss: 1.88009\n",
            "[662]\tvalid_0's multi_logloss: 1.88001\n",
            "[663]\tvalid_0's multi_logloss: 1.87995\n",
            "[664]\tvalid_0's multi_logloss: 1.87979\n",
            "[665]\tvalid_0's multi_logloss: 1.87982\n",
            "[666]\tvalid_0's multi_logloss: 1.87973\n",
            "[667]\tvalid_0's multi_logloss: 1.87957\n",
            "[668]\tvalid_0's multi_logloss: 1.87961\n",
            "[669]\tvalid_0's multi_logloss: 1.87972\n",
            "[670]\tvalid_0's multi_logloss: 1.87975\n",
            "[671]\tvalid_0's multi_logloss: 1.87975\n",
            "[672]\tvalid_0's multi_logloss: 1.87984\n",
            "[673]\tvalid_0's multi_logloss: 1.87972\n",
            "[674]\tvalid_0's multi_logloss: 1.87973\n",
            "[675]\tvalid_0's multi_logloss: 1.87982\n",
            "[676]\tvalid_0's multi_logloss: 1.87983\n",
            "[677]\tvalid_0's multi_logloss: 1.87967\n",
            "[678]\tvalid_0's multi_logloss: 1.87961\n",
            "[679]\tvalid_0's multi_logloss: 1.87952\n",
            "[680]\tvalid_0's multi_logloss: 1.87967\n",
            "[681]\tvalid_0's multi_logloss: 1.87953\n",
            "[682]\tvalid_0's multi_logloss: 1.87943\n",
            "[683]\tvalid_0's multi_logloss: 1.87942\n",
            "[684]\tvalid_0's multi_logloss: 1.87942\n",
            "[685]\tvalid_0's multi_logloss: 1.87933\n",
            "[686]\tvalid_0's multi_logloss: 1.87928\n",
            "[687]\tvalid_0's multi_logloss: 1.87934\n",
            "[688]\tvalid_0's multi_logloss: 1.87932\n",
            "[689]\tvalid_0's multi_logloss: 1.87931\n",
            "[690]\tvalid_0's multi_logloss: 1.87934\n",
            "[691]\tvalid_0's multi_logloss: 1.87916\n",
            "[692]\tvalid_0's multi_logloss: 1.87909\n",
            "[693]\tvalid_0's multi_logloss: 1.8791\n",
            "[694]\tvalid_0's multi_logloss: 1.87912\n",
            "[695]\tvalid_0's multi_logloss: 1.87911\n",
            "[696]\tvalid_0's multi_logloss: 1.87901\n",
            "[697]\tvalid_0's multi_logloss: 1.87899\n",
            "[698]\tvalid_0's multi_logloss: 1.8789\n",
            "[699]\tvalid_0's multi_logloss: 1.87889\n",
            "[700]\tvalid_0's multi_logloss: 1.87883\n",
            "[701]\tvalid_0's multi_logloss: 1.87883\n",
            "[702]\tvalid_0's multi_logloss: 1.87876\n",
            "[703]\tvalid_0's multi_logloss: 1.87866\n",
            "[704]\tvalid_0's multi_logloss: 1.87857\n",
            "[705]\tvalid_0's multi_logloss: 1.87865\n",
            "[706]\tvalid_0's multi_logloss: 1.87867\n",
            "[707]\tvalid_0's multi_logloss: 1.87874\n",
            "[708]\tvalid_0's multi_logloss: 1.8787\n",
            "[709]\tvalid_0's multi_logloss: 1.87858\n",
            "[710]\tvalid_0's multi_logloss: 1.8786\n",
            "[711]\tvalid_0's multi_logloss: 1.87855\n",
            "[712]\tvalid_0's multi_logloss: 1.87852\n",
            "[713]\tvalid_0's multi_logloss: 1.87867\n",
            "[714]\tvalid_0's multi_logloss: 1.87875\n",
            "[715]\tvalid_0's multi_logloss: 1.87876\n",
            "[716]\tvalid_0's multi_logloss: 1.87847\n",
            "[717]\tvalid_0's multi_logloss: 1.87838\n",
            "[718]\tvalid_0's multi_logloss: 1.87841\n",
            "[719]\tvalid_0's multi_logloss: 1.87852\n",
            "[720]\tvalid_0's multi_logloss: 1.87855\n",
            "[721]\tvalid_0's multi_logloss: 1.87851\n",
            "[722]\tvalid_0's multi_logloss: 1.87871\n",
            "[723]\tvalid_0's multi_logloss: 1.87874\n",
            "[724]\tvalid_0's multi_logloss: 1.87871\n",
            "[725]\tvalid_0's multi_logloss: 1.87883\n",
            "[726]\tvalid_0's multi_logloss: 1.87883\n",
            "[727]\tvalid_0's multi_logloss: 1.87889\n",
            "[728]\tvalid_0's multi_logloss: 1.87886\n",
            "[729]\tvalid_0's multi_logloss: 1.87887\n",
            "[730]\tvalid_0's multi_logloss: 1.87892\n",
            "[731]\tvalid_0's multi_logloss: 1.87894\n",
            "[732]\tvalid_0's multi_logloss: 1.87891\n",
            "[733]\tvalid_0's multi_logloss: 1.87902\n",
            "[734]\tvalid_0's multi_logloss: 1.87901\n",
            "[735]\tvalid_0's multi_logloss: 1.87904\n",
            "[736]\tvalid_0's multi_logloss: 1.87911\n",
            "[737]\tvalid_0's multi_logloss: 1.8791\n",
            "Early stopping, best iteration is:\n",
            "[717]\tvalid_0's multi_logloss: 1.87838\n",
            "Accuracy\n",
            "0.3640124095139607\n",
            "[1]\tvalid_0's multi_logloss: 2.47587\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 2.46836\n",
            "[3]\tvalid_0's multi_logloss: 2.4605\n",
            "[4]\tvalid_0's multi_logloss: 2.45344\n",
            "[5]\tvalid_0's multi_logloss: 2.44631\n",
            "[6]\tvalid_0's multi_logloss: 2.43936\n",
            "[7]\tvalid_0's multi_logloss: 2.43273\n",
            "[8]\tvalid_0's multi_logloss: 2.42608\n",
            "[9]\tvalid_0's multi_logloss: 2.41915\n",
            "[10]\tvalid_0's multi_logloss: 2.4129\n",
            "[11]\tvalid_0's multi_logloss: 2.40671\n",
            "[12]\tvalid_0's multi_logloss: 2.40113\n",
            "[13]\tvalid_0's multi_logloss: 2.39487\n",
            "[14]\tvalid_0's multi_logloss: 2.38894\n",
            "[15]\tvalid_0's multi_logloss: 2.38275\n",
            "[16]\tvalid_0's multi_logloss: 2.37749\n",
            "[17]\tvalid_0's multi_logloss: 2.37178\n",
            "[18]\tvalid_0's multi_logloss: 2.3663\n",
            "[19]\tvalid_0's multi_logloss: 2.36092\n",
            "[20]\tvalid_0's multi_logloss: 2.35609\n",
            "[21]\tvalid_0's multi_logloss: 2.35067\n",
            "[22]\tvalid_0's multi_logloss: 2.34566\n",
            "[23]\tvalid_0's multi_logloss: 2.34106\n",
            "[24]\tvalid_0's multi_logloss: 2.3363\n",
            "[25]\tvalid_0's multi_logloss: 2.33178\n",
            "[26]\tvalid_0's multi_logloss: 2.32719\n",
            "[27]\tvalid_0's multi_logloss: 2.32251\n",
            "[28]\tvalid_0's multi_logloss: 2.31842\n",
            "[29]\tvalid_0's multi_logloss: 2.31401\n",
            "[30]\tvalid_0's multi_logloss: 2.30981\n",
            "[31]\tvalid_0's multi_logloss: 2.30555\n",
            "[32]\tvalid_0's multi_logloss: 2.30145\n",
            "[33]\tvalid_0's multi_logloss: 2.29732\n",
            "[34]\tvalid_0's multi_logloss: 2.29344\n",
            "[35]\tvalid_0's multi_logloss: 2.28935\n",
            "[36]\tvalid_0's multi_logloss: 2.28551\n",
            "[37]\tvalid_0's multi_logloss: 2.28171\n",
            "[38]\tvalid_0's multi_logloss: 2.27777\n",
            "[39]\tvalid_0's multi_logloss: 2.2738\n",
            "[40]\tvalid_0's multi_logloss: 2.27026\n",
            "[41]\tvalid_0's multi_logloss: 2.26665\n",
            "[42]\tvalid_0's multi_logloss: 2.2626\n",
            "[43]\tvalid_0's multi_logloss: 2.25927\n",
            "[44]\tvalid_0's multi_logloss: 2.25598\n",
            "[45]\tvalid_0's multi_logloss: 2.25266\n",
            "[46]\tvalid_0's multi_logloss: 2.24922\n",
            "[47]\tvalid_0's multi_logloss: 2.24618\n",
            "[48]\tvalid_0's multi_logloss: 2.24261\n",
            "[49]\tvalid_0's multi_logloss: 2.23954\n",
            "[50]\tvalid_0's multi_logloss: 2.23623\n",
            "[51]\tvalid_0's multi_logloss: 2.2333\n",
            "[52]\tvalid_0's multi_logloss: 2.23027\n",
            "[53]\tvalid_0's multi_logloss: 2.22713\n",
            "[54]\tvalid_0's multi_logloss: 2.2244\n",
            "[55]\tvalid_0's multi_logloss: 2.22132\n",
            "[56]\tvalid_0's multi_logloss: 2.21871\n",
            "[57]\tvalid_0's multi_logloss: 2.21535\n",
            "[58]\tvalid_0's multi_logloss: 2.21279\n",
            "[59]\tvalid_0's multi_logloss: 2.20994\n",
            "[60]\tvalid_0's multi_logloss: 2.20721\n",
            "[61]\tvalid_0's multi_logloss: 2.20441\n",
            "[62]\tvalid_0's multi_logloss: 2.20173\n",
            "[63]\tvalid_0's multi_logloss: 2.19911\n",
            "[64]\tvalid_0's multi_logloss: 2.19657\n",
            "[65]\tvalid_0's multi_logloss: 2.19383\n",
            "[66]\tvalid_0's multi_logloss: 2.19127\n",
            "[67]\tvalid_0's multi_logloss: 2.1886\n",
            "[68]\tvalid_0's multi_logloss: 2.18608\n",
            "[69]\tvalid_0's multi_logloss: 2.18387\n",
            "[70]\tvalid_0's multi_logloss: 2.18147\n",
            "[71]\tvalid_0's multi_logloss: 2.17932\n",
            "[72]\tvalid_0's multi_logloss: 2.17657\n",
            "[73]\tvalid_0's multi_logloss: 2.17445\n",
            "[74]\tvalid_0's multi_logloss: 2.17202\n",
            "[75]\tvalid_0's multi_logloss: 2.16965\n",
            "[76]\tvalid_0's multi_logloss: 2.16754\n",
            "[77]\tvalid_0's multi_logloss: 2.16519\n",
            "[78]\tvalid_0's multi_logloss: 2.16282\n",
            "[79]\tvalid_0's multi_logloss: 2.16037\n",
            "[80]\tvalid_0's multi_logloss: 2.15817\n",
            "[81]\tvalid_0's multi_logloss: 2.15605\n",
            "[82]\tvalid_0's multi_logloss: 2.15359\n",
            "[83]\tvalid_0's multi_logloss: 2.15122\n",
            "[84]\tvalid_0's multi_logloss: 2.1487\n",
            "[85]\tvalid_0's multi_logloss: 2.14641\n",
            "[86]\tvalid_0's multi_logloss: 2.14416\n",
            "[87]\tvalid_0's multi_logloss: 2.14182\n",
            "[88]\tvalid_0's multi_logloss: 2.1398\n",
            "[89]\tvalid_0's multi_logloss: 2.13764\n",
            "[90]\tvalid_0's multi_logloss: 2.13529\n",
            "[91]\tvalid_0's multi_logloss: 2.13295\n",
            "[92]\tvalid_0's multi_logloss: 2.13093\n",
            "[93]\tvalid_0's multi_logloss: 2.12872\n",
            "[94]\tvalid_0's multi_logloss: 2.12666\n",
            "[95]\tvalid_0's multi_logloss: 2.12461\n",
            "[96]\tvalid_0's multi_logloss: 2.12253\n",
            "[97]\tvalid_0's multi_logloss: 2.12053\n",
            "[98]\tvalid_0's multi_logloss: 2.11836\n",
            "[99]\tvalid_0's multi_logloss: 2.11648\n",
            "[100]\tvalid_0's multi_logloss: 2.11428\n",
            "[101]\tvalid_0's multi_logloss: 2.11242\n",
            "[102]\tvalid_0's multi_logloss: 2.11036\n",
            "[103]\tvalid_0's multi_logloss: 2.10837\n",
            "[104]\tvalid_0's multi_logloss: 2.10646\n",
            "[105]\tvalid_0's multi_logloss: 2.10417\n",
            "[106]\tvalid_0's multi_logloss: 2.10241\n",
            "[107]\tvalid_0's multi_logloss: 2.10046\n",
            "[108]\tvalid_0's multi_logloss: 2.09883\n",
            "[109]\tvalid_0's multi_logloss: 2.09682\n",
            "[110]\tvalid_0's multi_logloss: 2.0952\n",
            "[111]\tvalid_0's multi_logloss: 2.0934\n",
            "[112]\tvalid_0's multi_logloss: 2.09149\n",
            "[113]\tvalid_0's multi_logloss: 2.08978\n",
            "[114]\tvalid_0's multi_logloss: 2.0882\n",
            "[115]\tvalid_0's multi_logloss: 2.08653\n",
            "[116]\tvalid_0's multi_logloss: 2.08483\n",
            "[117]\tvalid_0's multi_logloss: 2.08321\n",
            "[118]\tvalid_0's multi_logloss: 2.08157\n",
            "[119]\tvalid_0's multi_logloss: 2.07999\n",
            "[120]\tvalid_0's multi_logloss: 2.07861\n",
            "[121]\tvalid_0's multi_logloss: 2.07701\n",
            "[122]\tvalid_0's multi_logloss: 2.07537\n",
            "[123]\tvalid_0's multi_logloss: 2.0741\n",
            "[124]\tvalid_0's multi_logloss: 2.07249\n",
            "[125]\tvalid_0's multi_logloss: 2.07082\n",
            "[126]\tvalid_0's multi_logloss: 2.0694\n",
            "[127]\tvalid_0's multi_logloss: 2.06796\n",
            "[128]\tvalid_0's multi_logloss: 2.06657\n",
            "[129]\tvalid_0's multi_logloss: 2.06504\n",
            "[130]\tvalid_0's multi_logloss: 2.06355\n",
            "[131]\tvalid_0's multi_logloss: 2.06201\n",
            "[132]\tvalid_0's multi_logloss: 2.06038\n",
            "[133]\tvalid_0's multi_logloss: 2.05887\n",
            "[134]\tvalid_0's multi_logloss: 2.05741\n",
            "[135]\tvalid_0's multi_logloss: 2.05589\n",
            "[136]\tvalid_0's multi_logloss: 2.05455\n",
            "[137]\tvalid_0's multi_logloss: 2.05306\n",
            "[138]\tvalid_0's multi_logloss: 2.05161\n",
            "[139]\tvalid_0's multi_logloss: 2.05021\n",
            "[140]\tvalid_0's multi_logloss: 2.04893\n",
            "[141]\tvalid_0's multi_logloss: 2.04745\n",
            "[142]\tvalid_0's multi_logloss: 2.04643\n",
            "[143]\tvalid_0's multi_logloss: 2.04498\n",
            "[144]\tvalid_0's multi_logloss: 2.04374\n",
            "[145]\tvalid_0's multi_logloss: 2.04258\n",
            "[146]\tvalid_0's multi_logloss: 2.04119\n",
            "[147]\tvalid_0's multi_logloss: 2.03992\n",
            "[148]\tvalid_0's multi_logloss: 2.03864\n",
            "[149]\tvalid_0's multi_logloss: 2.03756\n",
            "[150]\tvalid_0's multi_logloss: 2.03637\n",
            "[151]\tvalid_0's multi_logloss: 2.035\n",
            "[152]\tvalid_0's multi_logloss: 2.03384\n",
            "[153]\tvalid_0's multi_logloss: 2.03258\n",
            "[154]\tvalid_0's multi_logloss: 2.0314\n",
            "[155]\tvalid_0's multi_logloss: 2.02996\n",
            "[156]\tvalid_0's multi_logloss: 2.02892\n",
            "[157]\tvalid_0's multi_logloss: 2.0277\n",
            "[158]\tvalid_0's multi_logloss: 2.0264\n",
            "[159]\tvalid_0's multi_logloss: 2.02513\n",
            "[160]\tvalid_0's multi_logloss: 2.0238\n",
            "[161]\tvalid_0's multi_logloss: 2.02271\n",
            "[162]\tvalid_0's multi_logloss: 2.02154\n",
            "[163]\tvalid_0's multi_logloss: 2.02019\n",
            "[164]\tvalid_0's multi_logloss: 2.0192\n",
            "[165]\tvalid_0's multi_logloss: 2.01791\n",
            "[166]\tvalid_0's multi_logloss: 2.01678\n",
            "[167]\tvalid_0's multi_logloss: 2.01555\n",
            "[168]\tvalid_0's multi_logloss: 2.01449\n",
            "[169]\tvalid_0's multi_logloss: 2.01359\n",
            "[170]\tvalid_0's multi_logloss: 2.01233\n",
            "[171]\tvalid_0's multi_logloss: 2.01122\n",
            "[172]\tvalid_0's multi_logloss: 2.0103\n",
            "[173]\tvalid_0's multi_logloss: 2.00923\n",
            "[174]\tvalid_0's multi_logloss: 2.00818\n",
            "[175]\tvalid_0's multi_logloss: 2.00714\n",
            "[176]\tvalid_0's multi_logloss: 2.00592\n",
            "[177]\tvalid_0's multi_logloss: 2.00507\n",
            "[178]\tvalid_0's multi_logloss: 2.0041\n",
            "[179]\tvalid_0's multi_logloss: 2.00316\n",
            "[180]\tvalid_0's multi_logloss: 2.00213\n",
            "[181]\tvalid_0's multi_logloss: 2.00101\n",
            "[182]\tvalid_0's multi_logloss: 1.99974\n",
            "[183]\tvalid_0's multi_logloss: 1.99854\n",
            "[184]\tvalid_0's multi_logloss: 1.9974\n",
            "[185]\tvalid_0's multi_logloss: 1.9964\n",
            "[186]\tvalid_0's multi_logloss: 1.99536\n",
            "[187]\tvalid_0's multi_logloss: 1.99432\n",
            "[188]\tvalid_0's multi_logloss: 1.99334\n",
            "[189]\tvalid_0's multi_logloss: 1.9924\n",
            "[190]\tvalid_0's multi_logloss: 1.99145\n",
            "[191]\tvalid_0's multi_logloss: 1.99054\n",
            "[192]\tvalid_0's multi_logloss: 1.98963\n",
            "[193]\tvalid_0's multi_logloss: 1.9887\n",
            "[194]\tvalid_0's multi_logloss: 1.98775\n",
            "[195]\tvalid_0's multi_logloss: 1.98674\n",
            "[196]\tvalid_0's multi_logloss: 1.9858\n",
            "[197]\tvalid_0's multi_logloss: 1.98485\n",
            "[198]\tvalid_0's multi_logloss: 1.98406\n",
            "[199]\tvalid_0's multi_logloss: 1.98317\n",
            "[200]\tvalid_0's multi_logloss: 1.9823\n",
            "[201]\tvalid_0's multi_logloss: 1.98151\n",
            "[202]\tvalid_0's multi_logloss: 1.98065\n",
            "[203]\tvalid_0's multi_logloss: 1.97972\n",
            "[204]\tvalid_0's multi_logloss: 1.9789\n",
            "[205]\tvalid_0's multi_logloss: 1.97787\n",
            "[206]\tvalid_0's multi_logloss: 1.97708\n",
            "[207]\tvalid_0's multi_logloss: 1.97623\n",
            "[208]\tvalid_0's multi_logloss: 1.97532\n",
            "[209]\tvalid_0's multi_logloss: 1.97442\n",
            "[210]\tvalid_0's multi_logloss: 1.97352\n",
            "[211]\tvalid_0's multi_logloss: 1.97253\n",
            "[212]\tvalid_0's multi_logloss: 1.97163\n",
            "[213]\tvalid_0's multi_logloss: 1.97069\n",
            "[214]\tvalid_0's multi_logloss: 1.96997\n",
            "[215]\tvalid_0's multi_logloss: 1.96898\n",
            "[216]\tvalid_0's multi_logloss: 1.9681\n",
            "[217]\tvalid_0's multi_logloss: 1.96728\n",
            "[218]\tvalid_0's multi_logloss: 1.96627\n",
            "[219]\tvalid_0's multi_logloss: 1.96555\n",
            "[220]\tvalid_0's multi_logloss: 1.96457\n",
            "[221]\tvalid_0's multi_logloss: 1.96368\n",
            "[222]\tvalid_0's multi_logloss: 1.96284\n",
            "[223]\tvalid_0's multi_logloss: 1.96196\n",
            "[224]\tvalid_0's multi_logloss: 1.96118\n",
            "[225]\tvalid_0's multi_logloss: 1.96051\n",
            "[226]\tvalid_0's multi_logloss: 1.95979\n",
            "[227]\tvalid_0's multi_logloss: 1.959\n",
            "[228]\tvalid_0's multi_logloss: 1.95836\n",
            "[229]\tvalid_0's multi_logloss: 1.95756\n",
            "[230]\tvalid_0's multi_logloss: 1.95695\n",
            "[231]\tvalid_0's multi_logloss: 1.95615\n",
            "[232]\tvalid_0's multi_logloss: 1.95543\n",
            "[233]\tvalid_0's multi_logloss: 1.95473\n",
            "[234]\tvalid_0's multi_logloss: 1.95401\n",
            "[235]\tvalid_0's multi_logloss: 1.95337\n",
            "[236]\tvalid_0's multi_logloss: 1.95247\n",
            "[237]\tvalid_0's multi_logloss: 1.95179\n",
            "[238]\tvalid_0's multi_logloss: 1.95089\n",
            "[239]\tvalid_0's multi_logloss: 1.9503\n",
            "[240]\tvalid_0's multi_logloss: 1.94938\n",
            "[241]\tvalid_0's multi_logloss: 1.94871\n",
            "[242]\tvalid_0's multi_logloss: 1.94802\n",
            "[243]\tvalid_0's multi_logloss: 1.94718\n",
            "[244]\tvalid_0's multi_logloss: 1.94642\n",
            "[245]\tvalid_0's multi_logloss: 1.94584\n",
            "[246]\tvalid_0's multi_logloss: 1.94523\n",
            "[247]\tvalid_0's multi_logloss: 1.94441\n",
            "[248]\tvalid_0's multi_logloss: 1.94393\n",
            "[249]\tvalid_0's multi_logloss: 1.94296\n",
            "[250]\tvalid_0's multi_logloss: 1.94204\n",
            "[251]\tvalid_0's multi_logloss: 1.94131\n",
            "[252]\tvalid_0's multi_logloss: 1.94077\n",
            "[253]\tvalid_0's multi_logloss: 1.94007\n",
            "[254]\tvalid_0's multi_logloss: 1.93922\n",
            "[255]\tvalid_0's multi_logloss: 1.93836\n",
            "[256]\tvalid_0's multi_logloss: 1.93773\n",
            "[257]\tvalid_0's multi_logloss: 1.93707\n",
            "[258]\tvalid_0's multi_logloss: 1.93649\n",
            "[259]\tvalid_0's multi_logloss: 1.93585\n",
            "[260]\tvalid_0's multi_logloss: 1.9351\n",
            "[261]\tvalid_0's multi_logloss: 1.93424\n",
            "[262]\tvalid_0's multi_logloss: 1.93368\n",
            "[263]\tvalid_0's multi_logloss: 1.93311\n",
            "[264]\tvalid_0's multi_logloss: 1.93233\n",
            "[265]\tvalid_0's multi_logloss: 1.93159\n",
            "[266]\tvalid_0's multi_logloss: 1.93089\n",
            "[267]\tvalid_0's multi_logloss: 1.93048\n",
            "[268]\tvalid_0's multi_logloss: 1.92974\n",
            "[269]\tvalid_0's multi_logloss: 1.92911\n",
            "[270]\tvalid_0's multi_logloss: 1.92855\n",
            "[271]\tvalid_0's multi_logloss: 1.92784\n",
            "[272]\tvalid_0's multi_logloss: 1.92725\n",
            "[273]\tvalid_0's multi_logloss: 1.92667\n",
            "[274]\tvalid_0's multi_logloss: 1.92598\n",
            "[275]\tvalid_0's multi_logloss: 1.92539\n",
            "[276]\tvalid_0's multi_logloss: 1.92469\n",
            "[277]\tvalid_0's multi_logloss: 1.92408\n",
            "[278]\tvalid_0's multi_logloss: 1.92365\n",
            "[279]\tvalid_0's multi_logloss: 1.92282\n",
            "[280]\tvalid_0's multi_logloss: 1.92215\n",
            "[281]\tvalid_0's multi_logloss: 1.92155\n",
            "[282]\tvalid_0's multi_logloss: 1.92104\n",
            "[283]\tvalid_0's multi_logloss: 1.92032\n",
            "[284]\tvalid_0's multi_logloss: 1.91952\n",
            "[285]\tvalid_0's multi_logloss: 1.91885\n",
            "[286]\tvalid_0's multi_logloss: 1.91819\n",
            "[287]\tvalid_0's multi_logloss: 1.91752\n",
            "[288]\tvalid_0's multi_logloss: 1.91698\n",
            "[289]\tvalid_0's multi_logloss: 1.9165\n",
            "[290]\tvalid_0's multi_logloss: 1.91602\n",
            "[291]\tvalid_0's multi_logloss: 1.91528\n",
            "[292]\tvalid_0's multi_logloss: 1.91499\n",
            "[293]\tvalid_0's multi_logloss: 1.91443\n",
            "[294]\tvalid_0's multi_logloss: 1.91393\n",
            "[295]\tvalid_0's multi_logloss: 1.91322\n",
            "[296]\tvalid_0's multi_logloss: 1.91262\n",
            "[297]\tvalid_0's multi_logloss: 1.91204\n",
            "[298]\tvalid_0's multi_logloss: 1.91151\n",
            "[299]\tvalid_0's multi_logloss: 1.91113\n",
            "[300]\tvalid_0's multi_logloss: 1.91042\n",
            "[301]\tvalid_0's multi_logloss: 1.90985\n",
            "[302]\tvalid_0's multi_logloss: 1.90928\n",
            "[303]\tvalid_0's multi_logloss: 1.90871\n",
            "[304]\tvalid_0's multi_logloss: 1.90819\n",
            "[305]\tvalid_0's multi_logloss: 1.90778\n",
            "[306]\tvalid_0's multi_logloss: 1.90723\n",
            "[307]\tvalid_0's multi_logloss: 1.9067\n",
            "[308]\tvalid_0's multi_logloss: 1.90613\n",
            "[309]\tvalid_0's multi_logloss: 1.90564\n",
            "[310]\tvalid_0's multi_logloss: 1.90506\n",
            "[311]\tvalid_0's multi_logloss: 1.90451\n",
            "[312]\tvalid_0's multi_logloss: 1.90414\n",
            "[313]\tvalid_0's multi_logloss: 1.90366\n",
            "[314]\tvalid_0's multi_logloss: 1.90324\n",
            "[315]\tvalid_0's multi_logloss: 1.90289\n",
            "[316]\tvalid_0's multi_logloss: 1.90237\n",
            "[317]\tvalid_0's multi_logloss: 1.90184\n",
            "[318]\tvalid_0's multi_logloss: 1.90128\n",
            "[319]\tvalid_0's multi_logloss: 1.90092\n",
            "[320]\tvalid_0's multi_logloss: 1.90036\n",
            "[321]\tvalid_0's multi_logloss: 1.90007\n",
            "[322]\tvalid_0's multi_logloss: 1.89957\n",
            "[323]\tvalid_0's multi_logloss: 1.89901\n",
            "[324]\tvalid_0's multi_logloss: 1.89866\n",
            "[325]\tvalid_0's multi_logloss: 1.89816\n",
            "[326]\tvalid_0's multi_logloss: 1.89759\n",
            "[327]\tvalid_0's multi_logloss: 1.89715\n",
            "[328]\tvalid_0's multi_logloss: 1.89654\n",
            "[329]\tvalid_0's multi_logloss: 1.89606\n",
            "[330]\tvalid_0's multi_logloss: 1.89552\n",
            "[331]\tvalid_0's multi_logloss: 1.89507\n",
            "[332]\tvalid_0's multi_logloss: 1.89444\n",
            "[333]\tvalid_0's multi_logloss: 1.89389\n",
            "[334]\tvalid_0's multi_logloss: 1.89338\n",
            "[335]\tvalid_0's multi_logloss: 1.89298\n",
            "[336]\tvalid_0's multi_logloss: 1.89245\n",
            "[337]\tvalid_0's multi_logloss: 1.89217\n",
            "[338]\tvalid_0's multi_logloss: 1.89189\n",
            "[339]\tvalid_0's multi_logloss: 1.89154\n",
            "[340]\tvalid_0's multi_logloss: 1.89111\n",
            "[341]\tvalid_0's multi_logloss: 1.89063\n",
            "[342]\tvalid_0's multi_logloss: 1.89022\n",
            "[343]\tvalid_0's multi_logloss: 1.88984\n",
            "[344]\tvalid_0's multi_logloss: 1.88942\n",
            "[345]\tvalid_0's multi_logloss: 1.88901\n",
            "[346]\tvalid_0's multi_logloss: 1.88862\n",
            "[347]\tvalid_0's multi_logloss: 1.88834\n",
            "[348]\tvalid_0's multi_logloss: 1.88783\n",
            "[349]\tvalid_0's multi_logloss: 1.88753\n",
            "[350]\tvalid_0's multi_logloss: 1.88716\n",
            "[351]\tvalid_0's multi_logloss: 1.88685\n",
            "[352]\tvalid_0's multi_logloss: 1.88667\n",
            "[353]\tvalid_0's multi_logloss: 1.88621\n",
            "[354]\tvalid_0's multi_logloss: 1.88589\n",
            "[355]\tvalid_0's multi_logloss: 1.88553\n",
            "[356]\tvalid_0's multi_logloss: 1.8852\n",
            "[357]\tvalid_0's multi_logloss: 1.88497\n",
            "[358]\tvalid_0's multi_logloss: 1.88473\n",
            "[359]\tvalid_0's multi_logloss: 1.88442\n",
            "[360]\tvalid_0's multi_logloss: 1.88393\n",
            "[361]\tvalid_0's multi_logloss: 1.88364\n",
            "[362]\tvalid_0's multi_logloss: 1.88328\n",
            "[363]\tvalid_0's multi_logloss: 1.88298\n",
            "[364]\tvalid_0's multi_logloss: 1.8826\n",
            "[365]\tvalid_0's multi_logloss: 1.88231\n",
            "[366]\tvalid_0's multi_logloss: 1.882\n",
            "[367]\tvalid_0's multi_logloss: 1.8818\n",
            "[368]\tvalid_0's multi_logloss: 1.88132\n",
            "[369]\tvalid_0's multi_logloss: 1.88105\n",
            "[370]\tvalid_0's multi_logloss: 1.8809\n",
            "[371]\tvalid_0's multi_logloss: 1.88073\n",
            "[372]\tvalid_0's multi_logloss: 1.88049\n",
            "[373]\tvalid_0's multi_logloss: 1.88024\n",
            "[374]\tvalid_0's multi_logloss: 1.87997\n",
            "[375]\tvalid_0's multi_logloss: 1.87955\n",
            "[376]\tvalid_0's multi_logloss: 1.87931\n",
            "[377]\tvalid_0's multi_logloss: 1.87908\n",
            "[378]\tvalid_0's multi_logloss: 1.87872\n",
            "[379]\tvalid_0's multi_logloss: 1.87844\n",
            "[380]\tvalid_0's multi_logloss: 1.87819\n",
            "[381]\tvalid_0's multi_logloss: 1.87792\n",
            "[382]\tvalid_0's multi_logloss: 1.8777\n",
            "[383]\tvalid_0's multi_logloss: 1.8774\n",
            "[384]\tvalid_0's multi_logloss: 1.87721\n",
            "[385]\tvalid_0's multi_logloss: 1.87694\n",
            "[386]\tvalid_0's multi_logloss: 1.87667\n",
            "[387]\tvalid_0's multi_logloss: 1.87641\n",
            "[388]\tvalid_0's multi_logloss: 1.87616\n",
            "[389]\tvalid_0's multi_logloss: 1.87598\n",
            "[390]\tvalid_0's multi_logloss: 1.87566\n",
            "[391]\tvalid_0's multi_logloss: 1.87554\n",
            "[392]\tvalid_0's multi_logloss: 1.87528\n",
            "[393]\tvalid_0's multi_logloss: 1.87495\n",
            "[394]\tvalid_0's multi_logloss: 1.87476\n",
            "[395]\tvalid_0's multi_logloss: 1.87459\n",
            "[396]\tvalid_0's multi_logloss: 1.87438\n",
            "[397]\tvalid_0's multi_logloss: 1.87407\n",
            "[398]\tvalid_0's multi_logloss: 1.87368\n",
            "[399]\tvalid_0's multi_logloss: 1.87343\n",
            "[400]\tvalid_0's multi_logloss: 1.87322\n",
            "[401]\tvalid_0's multi_logloss: 1.87291\n",
            "[402]\tvalid_0's multi_logloss: 1.87261\n",
            "[403]\tvalid_0's multi_logloss: 1.87244\n",
            "[404]\tvalid_0's multi_logloss: 1.87227\n",
            "[405]\tvalid_0's multi_logloss: 1.87202\n",
            "[406]\tvalid_0's multi_logloss: 1.87182\n",
            "[407]\tvalid_0's multi_logloss: 1.87171\n",
            "[408]\tvalid_0's multi_logloss: 1.87155\n",
            "[409]\tvalid_0's multi_logloss: 1.87136\n",
            "[410]\tvalid_0's multi_logloss: 1.87121\n",
            "[411]\tvalid_0's multi_logloss: 1.87098\n",
            "[412]\tvalid_0's multi_logloss: 1.87075\n",
            "[413]\tvalid_0's multi_logloss: 1.87048\n",
            "[414]\tvalid_0's multi_logloss: 1.87034\n",
            "[415]\tvalid_0's multi_logloss: 1.86988\n",
            "[416]\tvalid_0's multi_logloss: 1.86957\n",
            "[417]\tvalid_0's multi_logloss: 1.86932\n",
            "[418]\tvalid_0's multi_logloss: 1.86913\n",
            "[419]\tvalid_0's multi_logloss: 1.86905\n",
            "[420]\tvalid_0's multi_logloss: 1.86883\n",
            "[421]\tvalid_0's multi_logloss: 1.86868\n",
            "[422]\tvalid_0's multi_logloss: 1.86859\n",
            "[423]\tvalid_0's multi_logloss: 1.86844\n",
            "[424]\tvalid_0's multi_logloss: 1.86819\n",
            "[425]\tvalid_0's multi_logloss: 1.86804\n",
            "[426]\tvalid_0's multi_logloss: 1.8679\n",
            "[427]\tvalid_0's multi_logloss: 1.86774\n",
            "[428]\tvalid_0's multi_logloss: 1.86752\n",
            "[429]\tvalid_0's multi_logloss: 1.8674\n",
            "[430]\tvalid_0's multi_logloss: 1.86713\n",
            "[431]\tvalid_0's multi_logloss: 1.86702\n",
            "[432]\tvalid_0's multi_logloss: 1.86689\n",
            "[433]\tvalid_0's multi_logloss: 1.86659\n",
            "[434]\tvalid_0's multi_logloss: 1.86652\n",
            "[435]\tvalid_0's multi_logloss: 1.86623\n",
            "[436]\tvalid_0's multi_logloss: 1.86598\n",
            "[437]\tvalid_0's multi_logloss: 1.86573\n",
            "[438]\tvalid_0's multi_logloss: 1.86567\n",
            "[439]\tvalid_0's multi_logloss: 1.86564\n",
            "[440]\tvalid_0's multi_logloss: 1.86539\n",
            "[441]\tvalid_0's multi_logloss: 1.86517\n",
            "[442]\tvalid_0's multi_logloss: 1.86495\n",
            "[443]\tvalid_0's multi_logloss: 1.86476\n",
            "[444]\tvalid_0's multi_logloss: 1.86473\n",
            "[445]\tvalid_0's multi_logloss: 1.86464\n",
            "[446]\tvalid_0's multi_logloss: 1.86432\n",
            "[447]\tvalid_0's multi_logloss: 1.86402\n",
            "[448]\tvalid_0's multi_logloss: 1.86376\n",
            "[449]\tvalid_0's multi_logloss: 1.86371\n",
            "[450]\tvalid_0's multi_logloss: 1.86355\n",
            "[451]\tvalid_0's multi_logloss: 1.86334\n",
            "[452]\tvalid_0's multi_logloss: 1.86337\n",
            "[453]\tvalid_0's multi_logloss: 1.86322\n",
            "[454]\tvalid_0's multi_logloss: 1.86307\n",
            "[455]\tvalid_0's multi_logloss: 1.86296\n",
            "[456]\tvalid_0's multi_logloss: 1.86267\n",
            "[457]\tvalid_0's multi_logloss: 1.86255\n",
            "[458]\tvalid_0's multi_logloss: 1.86246\n",
            "[459]\tvalid_0's multi_logloss: 1.86225\n",
            "[460]\tvalid_0's multi_logloss: 1.86212\n",
            "[461]\tvalid_0's multi_logloss: 1.86168\n",
            "[462]\tvalid_0's multi_logloss: 1.8615\n",
            "[463]\tvalid_0's multi_logloss: 1.86139\n",
            "[464]\tvalid_0's multi_logloss: 1.86143\n",
            "[465]\tvalid_0's multi_logloss: 1.86139\n",
            "[466]\tvalid_0's multi_logloss: 1.86119\n",
            "[467]\tvalid_0's multi_logloss: 1.86117\n",
            "[468]\tvalid_0's multi_logloss: 1.86092\n",
            "[469]\tvalid_0's multi_logloss: 1.86064\n",
            "[470]\tvalid_0's multi_logloss: 1.86031\n",
            "[471]\tvalid_0's multi_logloss: 1.86007\n",
            "[472]\tvalid_0's multi_logloss: 1.85994\n",
            "[473]\tvalid_0's multi_logloss: 1.86003\n",
            "[474]\tvalid_0's multi_logloss: 1.85974\n",
            "[475]\tvalid_0's multi_logloss: 1.85967\n",
            "[476]\tvalid_0's multi_logloss: 1.85962\n",
            "[477]\tvalid_0's multi_logloss: 1.85942\n",
            "[478]\tvalid_0's multi_logloss: 1.85927\n",
            "[479]\tvalid_0's multi_logloss: 1.85906\n",
            "[480]\tvalid_0's multi_logloss: 1.85887\n",
            "[481]\tvalid_0's multi_logloss: 1.85867\n",
            "[482]\tvalid_0's multi_logloss: 1.85845\n",
            "[483]\tvalid_0's multi_logloss: 1.85824\n",
            "[484]\tvalid_0's multi_logloss: 1.85814\n",
            "[485]\tvalid_0's multi_logloss: 1.85792\n",
            "[486]\tvalid_0's multi_logloss: 1.85778\n",
            "[487]\tvalid_0's multi_logloss: 1.85758\n",
            "[488]\tvalid_0's multi_logloss: 1.85733\n",
            "[489]\tvalid_0's multi_logloss: 1.85716\n",
            "[490]\tvalid_0's multi_logloss: 1.85708\n",
            "[491]\tvalid_0's multi_logloss: 1.85699\n",
            "[492]\tvalid_0's multi_logloss: 1.85684\n",
            "[493]\tvalid_0's multi_logloss: 1.85682\n",
            "[494]\tvalid_0's multi_logloss: 1.85672\n",
            "[495]\tvalid_0's multi_logloss: 1.85654\n",
            "[496]\tvalid_0's multi_logloss: 1.85653\n",
            "[497]\tvalid_0's multi_logloss: 1.85656\n",
            "[498]\tvalid_0's multi_logloss: 1.85636\n",
            "[499]\tvalid_0's multi_logloss: 1.85614\n",
            "[500]\tvalid_0's multi_logloss: 1.85601\n",
            "[501]\tvalid_0's multi_logloss: 1.85588\n",
            "[502]\tvalid_0's multi_logloss: 1.85574\n",
            "[503]\tvalid_0's multi_logloss: 1.85556\n",
            "[504]\tvalid_0's multi_logloss: 1.8555\n",
            "[505]\tvalid_0's multi_logloss: 1.85532\n",
            "[506]\tvalid_0's multi_logloss: 1.85509\n",
            "[507]\tvalid_0's multi_logloss: 1.85501\n",
            "[508]\tvalid_0's multi_logloss: 1.855\n",
            "[509]\tvalid_0's multi_logloss: 1.85495\n",
            "[510]\tvalid_0's multi_logloss: 1.85485\n",
            "[511]\tvalid_0's multi_logloss: 1.85459\n",
            "[512]\tvalid_0's multi_logloss: 1.85453\n",
            "[513]\tvalid_0's multi_logloss: 1.85442\n",
            "[514]\tvalid_0's multi_logloss: 1.85432\n",
            "[515]\tvalid_0's multi_logloss: 1.85421\n",
            "[516]\tvalid_0's multi_logloss: 1.85396\n",
            "[517]\tvalid_0's multi_logloss: 1.85394\n",
            "[518]\tvalid_0's multi_logloss: 1.85387\n",
            "[519]\tvalid_0's multi_logloss: 1.85372\n",
            "[520]\tvalid_0's multi_logloss: 1.85362\n",
            "[521]\tvalid_0's multi_logloss: 1.85344\n",
            "[522]\tvalid_0's multi_logloss: 1.85341\n",
            "[523]\tvalid_0's multi_logloss: 1.85324\n",
            "[524]\tvalid_0's multi_logloss: 1.85323\n",
            "[525]\tvalid_0's multi_logloss: 1.85304\n",
            "[526]\tvalid_0's multi_logloss: 1.85272\n",
            "[527]\tvalid_0's multi_logloss: 1.85261\n",
            "[528]\tvalid_0's multi_logloss: 1.85251\n",
            "[529]\tvalid_0's multi_logloss: 1.85247\n",
            "[530]\tvalid_0's multi_logloss: 1.85233\n",
            "[531]\tvalid_0's multi_logloss: 1.85228\n",
            "[532]\tvalid_0's multi_logloss: 1.85226\n",
            "[533]\tvalid_0's multi_logloss: 1.85219\n",
            "[534]\tvalid_0's multi_logloss: 1.85213\n",
            "[535]\tvalid_0's multi_logloss: 1.8519\n",
            "[536]\tvalid_0's multi_logloss: 1.85183\n",
            "[537]\tvalid_0's multi_logloss: 1.85173\n",
            "[538]\tvalid_0's multi_logloss: 1.85162\n",
            "[539]\tvalid_0's multi_logloss: 1.85145\n",
            "[540]\tvalid_0's multi_logloss: 1.85137\n",
            "[541]\tvalid_0's multi_logloss: 1.85137\n",
            "[542]\tvalid_0's multi_logloss: 1.85125\n",
            "[543]\tvalid_0's multi_logloss: 1.85127\n",
            "[544]\tvalid_0's multi_logloss: 1.8513\n",
            "[545]\tvalid_0's multi_logloss: 1.85123\n",
            "[546]\tvalid_0's multi_logloss: 1.85116\n",
            "[547]\tvalid_0's multi_logloss: 1.85095\n",
            "[548]\tvalid_0's multi_logloss: 1.85097\n",
            "[549]\tvalid_0's multi_logloss: 1.85069\n",
            "[550]\tvalid_0's multi_logloss: 1.8508\n",
            "[551]\tvalid_0's multi_logloss: 1.8508\n",
            "[552]\tvalid_0's multi_logloss: 1.85078\n",
            "[553]\tvalid_0's multi_logloss: 1.85072\n",
            "[554]\tvalid_0's multi_logloss: 1.85064\n",
            "[555]\tvalid_0's multi_logloss: 1.85058\n",
            "[556]\tvalid_0's multi_logloss: 1.8506\n",
            "[557]\tvalid_0's multi_logloss: 1.85061\n",
            "[558]\tvalid_0's multi_logloss: 1.85037\n",
            "[559]\tvalid_0's multi_logloss: 1.85025\n",
            "[560]\tvalid_0's multi_logloss: 1.85018\n",
            "[561]\tvalid_0's multi_logloss: 1.85004\n",
            "[562]\tvalid_0's multi_logloss: 1.85018\n",
            "[563]\tvalid_0's multi_logloss: 1.8501\n",
            "[564]\tvalid_0's multi_logloss: 1.85009\n",
            "[565]\tvalid_0's multi_logloss: 1.85007\n",
            "[566]\tvalid_0's multi_logloss: 1.85012\n",
            "[567]\tvalid_0's multi_logloss: 1.85011\n",
            "[568]\tvalid_0's multi_logloss: 1.85008\n",
            "[569]\tvalid_0's multi_logloss: 1.84999\n",
            "[570]\tvalid_0's multi_logloss: 1.84992\n",
            "[571]\tvalid_0's multi_logloss: 1.84983\n",
            "[572]\tvalid_0's multi_logloss: 1.84965\n",
            "[573]\tvalid_0's multi_logloss: 1.84959\n",
            "[574]\tvalid_0's multi_logloss: 1.84954\n",
            "[575]\tvalid_0's multi_logloss: 1.84937\n",
            "[576]\tvalid_0's multi_logloss: 1.84947\n",
            "[577]\tvalid_0's multi_logloss: 1.84966\n",
            "[578]\tvalid_0's multi_logloss: 1.84965\n",
            "[579]\tvalid_0's multi_logloss: 1.84959\n",
            "[580]\tvalid_0's multi_logloss: 1.84948\n",
            "[581]\tvalid_0's multi_logloss: 1.84955\n",
            "[582]\tvalid_0's multi_logloss: 1.84966\n",
            "[583]\tvalid_0's multi_logloss: 1.84966\n",
            "[584]\tvalid_0's multi_logloss: 1.84955\n",
            "[585]\tvalid_0's multi_logloss: 1.84959\n",
            "[586]\tvalid_0's multi_logloss: 1.84961\n",
            "[587]\tvalid_0's multi_logloss: 1.84976\n",
            "[588]\tvalid_0's multi_logloss: 1.84971\n",
            "[589]\tvalid_0's multi_logloss: 1.84965\n",
            "[590]\tvalid_0's multi_logloss: 1.84959\n",
            "[591]\tvalid_0's multi_logloss: 1.84963\n",
            "[592]\tvalid_0's multi_logloss: 1.84983\n",
            "[593]\tvalid_0's multi_logloss: 1.84992\n",
            "[594]\tvalid_0's multi_logloss: 1.84986\n",
            "[595]\tvalid_0's multi_logloss: 1.84989\n",
            "Early stopping, best iteration is:\n",
            "[575]\tvalid_0's multi_logloss: 1.84937\n",
            "Accuracy\n",
            "0.3850156087408949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnP3rkYuGO9Q",
        "colab_type": "code",
        "outputId": "a690774e-4362-4054-e8fe-dcdf2040702e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# 予想を実行する。\n",
        "# 的中率算出時に小数表示をするために設定を変更\n",
        "# \n",
        "np.set_printoptions(formatter={'float': '{:.2f}'.format})\n",
        "X_data_test = data_predict_test.drop([\"当日の回答\",\"星座.1\"], axis=1)\n",
        "y_pred_today = gbm.predict(X_data_test, num_iteration=gbm.best_iteration)\n",
        "y_pred_today_answer = np.argmax(y_pred_today, axis=1)\n",
        "print(\"順位を下から表示。番号は0から(どれでもない,牡羊,牡牛,双子,蟹,獅子,乙女,天秤,蠍,射手,山羊,水瓶,魚)\")\n",
        "print(y_pred_today[0].argsort())\n",
        "print(\"各星座の的中率(どれでもない,牡羊,牡牛,双子,蟹,獅子,乙女,天秤,蠍,射手,山羊,水瓶,魚)\")\n",
        "print(y_pred_today[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "順位を下から表示。番号は0から(どれでもない,牡羊,牡牛,双子,蟹,獅子,乙女,天秤,蠍,射手,山羊,水瓶,魚)\n",
            "[ 0  5  6  7  4  2  9  1 10 12  8  3 11]\n",
            "各星座の的中率(どれでもない,牡羊,牡牛,双子,蟹,獅子,乙女,天秤,蠍,射手,山羊,水瓶,魚)\n",
            "[0.00 0.07 0.05 0.14 0.05 0.02 0.03 0.04 0.09 0.06 0.07 0.29 0.09]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3zO8Yz1lrJA",
        "colab_type": "text"
      },
      "source": [
        "ここから分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF-kLdFAg1GP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 分析用にアップロードしたデータを読みこむ\n",
        "countdown_raw = pd.read_csv(\"countdown_raw.csv\", encoding=\"shift-jis\", engine = \"python\")\n",
        "countdown_num = pd.read_csv(\"countdown_num.csv\", encoding=\"shift-jis\", engine = \"python\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuxTWvfQ-UdC",
        "colab_type": "code",
        "outputId": "51cbb669-e36e-4f48-dcde-858dce8d25fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# アップロードされたデータの確認\n",
        "# 不要なデータは削除すること\n",
        "!ls -ltr /content/\n",
        "!rm -fr /content/countdown_raw.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 5896\n",
            "drwxr-xr-x 1 root root    4096 Aug 27 16:17 sample_data\n",
            "-rw-r--r-- 1 root root 2832067 Sep 29 13:21 data272.csv\n",
            "-rw-r--r-- 1 root root    4255 Sep 29 13:21 data273.csv\n",
            "-rw-r--r-- 1 root root 1149881 Sep 29 13:32 countdown.csv\n",
            "-rw-r--r-- 1 root root 2035998 Sep 29 13:33 countdown_plus.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mVIWUnDOgl0",
        "colab_type": "code",
        "outputId": "81432d37-6f1c-4b48-d113-f0b228b71d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "countdown_raw.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>年</th>\n",
              "      <th>月</th>\n",
              "      <th>日</th>\n",
              "      <th>1位</th>\n",
              "      <th>2位</th>\n",
              "      <th>3位</th>\n",
              "      <th>4位</th>\n",
              "      <th>5位</th>\n",
              "      <th>6位</th>\n",
              "      <th>7位</th>\n",
              "      <th>8位</th>\n",
              "      <th>9位</th>\n",
              "      <th>10位</th>\n",
              "      <th>11位</th>\n",
              "      <th>12位</th>\n",
              "      <th>星座</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>乙女</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>山羊</td>\n",
              "      <td>蠍</td>\n",
              "      <td>蟹</td>\n",
              "      <td>魚</td>\n",
              "      <td>獅子</td>\n",
              "      <td>天秤</td>\n",
              "      <td>射手</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>双子</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>26</td>\n",
              "      <td>射手</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>獅子</td>\n",
              "      <td>蟹</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>天秤</td>\n",
              "      <td>双子</td>\n",
              "      <td>蠍</td>\n",
              "      <td>山羊</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>魚</td>\n",
              "      <td>乙女</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>獅子</td>\n",
              "      <td>天秤</td>\n",
              "      <td>双子</td>\n",
              "      <td>射手</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>魚</td>\n",
              "      <td>乙女</td>\n",
              "      <td>蠍</td>\n",
              "      <td>山羊</td>\n",
              "      <td>蟹</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>24</td>\n",
              "      <td>蟹</td>\n",
              "      <td>蠍</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>魚</td>\n",
              "      <td>山羊</td>\n",
              "      <td>乙女</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>獅子</td>\n",
              "      <td>双子</td>\n",
              "      <td>射手</td>\n",
              "      <td>天秤</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>蠍</td>\n",
              "      <td>魚</td>\n",
              "      <td>蟹</td>\n",
              "      <td>乙女</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>双子</td>\n",
              "      <td>山羊</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>天秤</td>\n",
              "      <td>射手</td>\n",
              "      <td>獅子</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      年  月   日  1位  2位  3位  4位  5位  6位  7位  8位  9位 10位 11位 12位  星座\n",
              "0  2019  9  27  乙女  牡牛  山羊   蠍   蟹   魚  獅子  天秤  射手  牡羊  双子  水瓶   7\n",
              "1  2019  9  26  射手  牡羊  獅子   蟹  水瓶  天秤  双子   蠍  山羊  牡牛   魚  乙女   7\n",
              "2  2019  9  25  獅子  天秤  双子  射手  牡羊  水瓶   魚  乙女   蠍  山羊   蟹  牡牛   7\n",
              "3  2019  9  24   蟹   蠍  牡牛   魚  山羊  乙女  水瓶  牡羊  獅子  双子  射手  天秤   7\n",
              "4  2019  9  23   蠍   魚   蟹  乙女  牡牛  双子  山羊  水瓶  天秤  射手  獅子  牡羊   7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txRX7UFvnjRr",
        "colab_type": "code",
        "outputId": "c752a72f-d6dd-4c35-8cc8-df6c26c17f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        }
      },
      "source": [
        "# 当日の星座によって各星座の順位が異なっている可能性があるため調査\n",
        "# 必要なデータを残す。\n",
        "countdown_1_con = countdown_raw[['星座','1位']]\n",
        "# 1位の星座をonehot化する\n",
        "countdown_1_con = pd.get_dummies(countdown_1_con, drop_first=False, columns=['1位'], prefix='1位', prefix_sep='_')\n",
        "# 当日の星座でgroupbyする\n",
        "countdown_1_con_grouped = countdown_1_con.groupby('星座')\n",
        "# sumすることで、各星座が当日の星座ごとに1位になった回数を算出\n",
        "sum = countdown_1_con_grouped.sum()\n",
        "sum_graph = sum.rename(index={1: \"牡羊\", 2: \"牡牛\", 3: \"双子\", 4: \"蟹\", 5: \"獅子\", 6: \"乙女\", 7: \"天秤\", 8: \"蠍\", 9: \"射手\", 10: \"山羊\", 11: \"水瓶\", 12: \"魚\", })\n",
        "sum_graph.head(12)\n",
        "# それぞれのデータをグラフ表示\n",
        "sum_graph.plot(figsize=(16, 9),subplots=True, layout=(4, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f5f426a76d8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f453a9be0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f41bdf4a8>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f5f41b97908>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f41b12d68>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f41adb208>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f5f41a91668>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f41a4fb00>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f41a4fb38>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f5f4199c3c8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f4191a828>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5f418d4c88>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAHuCAYAAACbNIEKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 1152x648 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T1wh9tTg4X5",
        "colab_type": "code",
        "outputId": "c4479933-5255-4d9d-eb73-9e4e30ac792b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "countdown_raw.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>項番</th>\n",
              "      <th>年</th>\n",
              "      <th>月</th>\n",
              "      <th>日</th>\n",
              "      <th>1位</th>\n",
              "      <th>2位</th>\n",
              "      <th>3位</th>\n",
              "      <th>4位</th>\n",
              "      <th>5位</th>\n",
              "      <th>6位</th>\n",
              "      <th>7位</th>\n",
              "      <th>8位</th>\n",
              "      <th>9位</th>\n",
              "      <th>10位</th>\n",
              "      <th>11位</th>\n",
              "      <th>12位</th>\n",
              "      <th>牡牛座3日1位数</th>\n",
              "      <th>牡牛座7日1位数</th>\n",
              "      <th>牡牛座30日1位数</th>\n",
              "      <th>牡牛座365日1位数</th>\n",
              "      <th>牡牛座3日成績</th>\n",
              "      <th>牡牛座7日成績</th>\n",
              "      <th>牡牛座30日成績</th>\n",
              "      <th>牡牛座1日成績</th>\n",
              "      <th>牡牛座_絶対値_前日-前々日</th>\n",
              "      <th>牡牛座_+-_前日-前々日</th>\n",
              "      <th>牡牛_3日_EMA</th>\n",
              "      <th>牡牛_7日_EMA</th>\n",
              "      <th>牡牛_30日_EMA</th>\n",
              "      <th>牡羊座3日1位数</th>\n",
              "      <th>牡羊座7日1位数</th>\n",
              "      <th>牡羊座30日1位数</th>\n",
              "      <th>牡羊座365日1位数</th>\n",
              "      <th>牡羊座3日成績</th>\n",
              "      <th>牡羊座7日成績</th>\n",
              "      <th>牡羊座30日成績</th>\n",
              "      <th>牡羊座前日成績</th>\n",
              "      <th>牡羊座_絶対値_前日-前々日</th>\n",
              "      <th>牡羊座_+-_前日-前々日</th>\n",
              "      <th>牡羊_3日_EMA</th>\n",
              "      <th>...</th>\n",
              "      <th>火の属性_30日_EMA</th>\n",
              "      <th>土の属性3日1位数</th>\n",
              "      <th>土の属性7日1位数</th>\n",
              "      <th>土の属性30日1位数</th>\n",
              "      <th>土の属性365日1位数</th>\n",
              "      <th>土の属性3日成績</th>\n",
              "      <th>土の属性7日成績</th>\n",
              "      <th>土の属性30日成績</th>\n",
              "      <th>土の属性前日成績</th>\n",
              "      <th>土の属性3日_EMA</th>\n",
              "      <th>土の属性_7日_EMA</th>\n",
              "      <th>土の属性_30日_EMA</th>\n",
              "      <th>風の属性3日1位数</th>\n",
              "      <th>風の属性7日1位数</th>\n",
              "      <th>風の属性30日1位数</th>\n",
              "      <th>風の属性365日1位数</th>\n",
              "      <th>風の属性3日成績</th>\n",
              "      <th>風の属性7日成績</th>\n",
              "      <th>風の属性30日成績</th>\n",
              "      <th>風の属性前日成績</th>\n",
              "      <th>風の属性3日_EMA</th>\n",
              "      <th>風の属性_7日_EMA</th>\n",
              "      <th>風の属性_30日_EMA</th>\n",
              "      <th>水の属性3日1位数</th>\n",
              "      <th>水の属性7日1位数</th>\n",
              "      <th>水の属性30日1位数</th>\n",
              "      <th>水の属性365日1位数</th>\n",
              "      <th>水の属性3日成績</th>\n",
              "      <th>水の属性7日成績</th>\n",
              "      <th>水の属性30日成績</th>\n",
              "      <th>水の属性前日成績</th>\n",
              "      <th>水の属性3日_EMA</th>\n",
              "      <th>水の属性_7日_EMA</th>\n",
              "      <th>水の属性_30日_EMA</th>\n",
              "      <th>月星座</th>\n",
              "      <th>月星座同属性1</th>\n",
              "      <th>月星座同属性2</th>\n",
              "      <th>星座</th>\n",
              "      <th>当日の回答</th>\n",
              "      <th>星座.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>27</td>\n",
              "      <td>乙女</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>山羊</td>\n",
              "      <td>蠍</td>\n",
              "      <td>蟹</td>\n",
              "      <td>魚</td>\n",
              "      <td>獅子</td>\n",
              "      <td>天秤</td>\n",
              "      <td>射手</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>双子</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>199</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8.866308</td>\n",
              "      <td>7.082212</td>\n",
              "      <td>6.736422</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>48</td>\n",
              "      <td>201</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4.381373</td>\n",
              "      <td>...</td>\n",
              "      <td>19.281343</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "      <td>75</td>\n",
              "      <td>125</td>\n",
              "      <td>579</td>\n",
              "      <td>31</td>\n",
              "      <td>26.766899</td>\n",
              "      <td>22.399565</td>\n",
              "      <td>20.055684</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>91</td>\n",
              "      <td>58</td>\n",
              "      <td>152</td>\n",
              "      <td>615</td>\n",
              "      <td>18</td>\n",
              "      <td>17.980360</td>\n",
              "      <td>19.315281</td>\n",
              "      <td>19.713153</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>93</td>\n",
              "      <td>57</td>\n",
              "      <td>119</td>\n",
              "      <td>566</td>\n",
              "      <td>23</td>\n",
              "      <td>20.87008</td>\n",
              "      <td>19.117450</td>\n",
              "      <td>18.949819</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>2019/9/27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>26</td>\n",
              "      <td>射手</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>獅子</td>\n",
              "      <td>蟹</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>天秤</td>\n",
              "      <td>双子</td>\n",
              "      <td>蠍</td>\n",
              "      <td>山羊</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>魚</td>\n",
              "      <td>乙女</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>32</td>\n",
              "      <td>201</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>7.732616</td>\n",
              "      <td>6.109616</td>\n",
              "      <td>6.511348</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>49</td>\n",
              "      <td>203</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6.762747</td>\n",
              "      <td>...</td>\n",
              "      <td>20.197298</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>89</td>\n",
              "      <td>60</td>\n",
              "      <td>118</td>\n",
              "      <td>580</td>\n",
              "      <td>30</td>\n",
              "      <td>22.533798</td>\n",
              "      <td>19.532753</td>\n",
              "      <td>19.300904</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>91</td>\n",
              "      <td>63</td>\n",
              "      <td>147</td>\n",
              "      <td>603</td>\n",
              "      <td>11</td>\n",
              "      <td>17.960721</td>\n",
              "      <td>19.753708</td>\n",
              "      <td>19.831302</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>93</td>\n",
              "      <td>40</td>\n",
              "      <td>128</td>\n",
              "      <td>568</td>\n",
              "      <td>27</td>\n",
              "      <td>18.74016</td>\n",
              "      <td>17.823266</td>\n",
              "      <td>18.670496</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>2019/9/26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>獅子</td>\n",
              "      <td>天秤</td>\n",
              "      <td>双子</td>\n",
              "      <td>射手</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>魚</td>\n",
              "      <td>乙女</td>\n",
              "      <td>蠍</td>\n",
              "      <td>山羊</td>\n",
              "      <td>蟹</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>11</td>\n",
              "      <td>29</td>\n",
              "      <td>202</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3.465232</td>\n",
              "      <td>4.146155</td>\n",
              "      <td>6.132820</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>46</td>\n",
              "      <td>207</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8.525493</td>\n",
              "      <td>...</td>\n",
              "      <td>20.900560</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>89</td>\n",
              "      <td>52</td>\n",
              "      <td>119</td>\n",
              "      <td>574</td>\n",
              "      <td>14</td>\n",
              "      <td>15.067595</td>\n",
              "      <td>16.043671</td>\n",
              "      <td>18.563035</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>91</td>\n",
              "      <td>63</td>\n",
              "      <td>151</td>\n",
              "      <td>609</td>\n",
              "      <td>29</td>\n",
              "      <td>24.921441</td>\n",
              "      <td>22.671610</td>\n",
              "      <td>20.440357</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>94</td>\n",
              "      <td>39</td>\n",
              "      <td>126</td>\n",
              "      <td>551</td>\n",
              "      <td>7</td>\n",
              "      <td>10.48032</td>\n",
              "      <td>14.764355</td>\n",
              "      <td>18.096048</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2019/9/25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>24</td>\n",
              "      <td>蟹</td>\n",
              "      <td>蠍</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>魚</td>\n",
              "      <td>山羊</td>\n",
              "      <td>乙女</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>獅子</td>\n",
              "      <td>双子</td>\n",
              "      <td>射手</td>\n",
              "      <td>天秤</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>204</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3.930464</td>\n",
              "      <td>4.528207</td>\n",
              "      <td>6.348876</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>26</td>\n",
              "      <td>46</td>\n",
              "      <td>210</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>9.050987</td>\n",
              "      <td>...</td>\n",
              "      <td>20.410944</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>89</td>\n",
              "      <td>44</td>\n",
              "      <td>120</td>\n",
              "      <td>583</td>\n",
              "      <td>16</td>\n",
              "      <td>16.135191</td>\n",
              "      <td>16.724894</td>\n",
              "      <td>18.877727</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>91</td>\n",
              "      <td>64</td>\n",
              "      <td>151</td>\n",
              "      <td>593</td>\n",
              "      <td>23</td>\n",
              "      <td>20.842883</td>\n",
              "      <td>20.562147</td>\n",
              "      <td>19.850037</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>94</td>\n",
              "      <td>47</td>\n",
              "      <td>125</td>\n",
              "      <td>558</td>\n",
              "      <td>6</td>\n",
              "      <td>13.96064</td>\n",
              "      <td>17.352473</td>\n",
              "      <td>18.861292</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>2019/9/24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2019</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>蠍</td>\n",
              "      <td>魚</td>\n",
              "      <td>蟹</td>\n",
              "      <td>乙女</td>\n",
              "      <td>牡牛</td>\n",
              "      <td>双子</td>\n",
              "      <td>山羊</td>\n",
              "      <td>水瓶</td>\n",
              "      <td>天秤</td>\n",
              "      <td>射手</td>\n",
              "      <td>獅子</td>\n",
              "      <td>牡羊</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "      <td>213</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2.860928</td>\n",
              "      <td>4.370942</td>\n",
              "      <td>6.441902</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>21</td>\n",
              "      <td>41</td>\n",
              "      <td>195</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6.101974</td>\n",
              "      <td>...</td>\n",
              "      <td>19.542733</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>89</td>\n",
              "      <td>34</td>\n",
              "      <td>121</td>\n",
              "      <td>608</td>\n",
              "      <td>22</td>\n",
              "      <td>16.270381</td>\n",
              "      <td>16.966526</td>\n",
              "      <td>19.076191</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>92</td>\n",
              "      <td>71</td>\n",
              "      <td>138</td>\n",
              "      <td>571</td>\n",
              "      <td>11</td>\n",
              "      <td>18.685765</td>\n",
              "      <td>19.749529</td>\n",
              "      <td>19.632798</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>93</td>\n",
              "      <td>56</td>\n",
              "      <td>152</td>\n",
              "      <td>586</td>\n",
              "      <td>26</td>\n",
              "      <td>21.92128</td>\n",
              "      <td>21.136631</td>\n",
              "      <td>19.748278</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>2019/9/23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 222 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   項番     年  月   日  1位  2位  ... 月星座 月星座同属性1 月星座同属性2 星座 当日の回答       星座.1\n",
              "0   1  2019  9  27  乙女  牡牛  ...   6      10       2  7     6  2019/9/27\n",
              "1   2  2019  9  26  射手  牡羊  ...   6      10       2  7     9  2019/9/26\n",
              "2   3  2019  9  25  獅子  天秤  ...   5       9       1  7     5  2019/9/25\n",
              "3   4  2019  9  24   蟹   蠍  ...   5       9       1  7     4  2019/9/24\n",
              "4   5  2019  9  23   蠍   魚  ...   4       8      12  7     8  2019/9/23\n",
              "\n",
              "[5 rows x 222 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl-LfIxrtJK5",
        "colab_type": "code",
        "outputId": "8a36ce9c-4bea-4cf4-9181-b4969f43a11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "# 各星座の日(例えばうお座だと2/19～3/20)で成績が偏る可能性を考慮し、groupbyし、平均を出す。\n",
        "grouped = countdown_num.groupby('星座')\n",
        "mean = grouped.mean()\n",
        "mean.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>項番</th>\n",
              "      <th>年</th>\n",
              "      <th>月</th>\n",
              "      <th>日</th>\n",
              "      <th>1位</th>\n",
              "      <th>2位</th>\n",
              "      <th>3位</th>\n",
              "      <th>4位</th>\n",
              "      <th>5位</th>\n",
              "      <th>6位</th>\n",
              "      <th>7位</th>\n",
              "      <th>8位</th>\n",
              "      <th>9位</th>\n",
              "      <th>10位</th>\n",
              "      <th>11位</th>\n",
              "      <th>12位</th>\n",
              "      <th>2座3日1位数</th>\n",
              "      <th>2座7日1位数</th>\n",
              "      <th>2座30日1位数</th>\n",
              "      <th>2座365日1位数</th>\n",
              "      <th>2座3日成績</th>\n",
              "      <th>2座7日成績</th>\n",
              "      <th>2座30日成績</th>\n",
              "      <th>2座1日成績</th>\n",
              "      <th>2座_絶対値_前日-前々日</th>\n",
              "      <th>2座_+-_前日-前々日</th>\n",
              "      <th>2_3日_EMA</th>\n",
              "      <th>2_7日_EMA</th>\n",
              "      <th>2_30日_EMA</th>\n",
              "      <th>1座3日1位数</th>\n",
              "      <th>1座7日1位数</th>\n",
              "      <th>1座30日1位数</th>\n",
              "      <th>1座365日1位数</th>\n",
              "      <th>1座3日成績</th>\n",
              "      <th>1座7日成績</th>\n",
              "      <th>1座30日成績</th>\n",
              "      <th>1座前日成績</th>\n",
              "      <th>1座_絶対値_前日-前々日</th>\n",
              "      <th>1座_+-_前日-前々日</th>\n",
              "      <th>1_3日_EMA</th>\n",
              "      <th>...</th>\n",
              "      <th>火の属性3日_EMA</th>\n",
              "      <th>火の属性_7日_EMA</th>\n",
              "      <th>火の属性_30日_EMA</th>\n",
              "      <th>土の属性3日1位数</th>\n",
              "      <th>土の属性7日1位数</th>\n",
              "      <th>土の属性30日1位数</th>\n",
              "      <th>土の属性365日1位数</th>\n",
              "      <th>土の属性3日成績</th>\n",
              "      <th>土の属性7日成績</th>\n",
              "      <th>土の属性30日成績</th>\n",
              "      <th>土の属性前日成績</th>\n",
              "      <th>土の属性3日_EMA</th>\n",
              "      <th>土の属性_7日_EMA</th>\n",
              "      <th>土の属性_30日_EMA</th>\n",
              "      <th>風の属性3日1位数</th>\n",
              "      <th>風の属性7日1位数</th>\n",
              "      <th>風の属性30日1位数</th>\n",
              "      <th>風の属性365日1位数</th>\n",
              "      <th>風の属性3日成績</th>\n",
              "      <th>風の属性7日成績</th>\n",
              "      <th>風の属性30日成績</th>\n",
              "      <th>風の属性前日成績</th>\n",
              "      <th>風の属性3日_EMA</th>\n",
              "      <th>風の属性_7日_EMA</th>\n",
              "      <th>風の属性_30日_EMA</th>\n",
              "      <th>水の属性3日1位数</th>\n",
              "      <th>水の属性7日1位数</th>\n",
              "      <th>水の属性30日1位数</th>\n",
              "      <th>水の属性365日1位数</th>\n",
              "      <th>水の属性3日成績</th>\n",
              "      <th>水の属性7日成績</th>\n",
              "      <th>水の属性30日成績</th>\n",
              "      <th>水の属性前日成績</th>\n",
              "      <th>水の属性3日_EMA</th>\n",
              "      <th>水の属性_7日_EMA</th>\n",
              "      <th>水の属性_30日_EMA</th>\n",
              "      <th>月星座</th>\n",
              "      <th>月星座同属性1</th>\n",
              "      <th>月星座同属性2</th>\n",
              "      <th>当日の回答</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>星座</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1401.563559</td>\n",
              "      <td>2014.389831</td>\n",
              "      <td>3.631356</td>\n",
              "      <td>15.911017</td>\n",
              "      <td>6.550847</td>\n",
              "      <td>6.508475</td>\n",
              "      <td>6.432203</td>\n",
              "      <td>6.330508</td>\n",
              "      <td>6.351695</td>\n",
              "      <td>6.758475</td>\n",
              "      <td>6.622881</td>\n",
              "      <td>6.745763</td>\n",
              "      <td>6.593220</td>\n",
              "      <td>6.275424</td>\n",
              "      <td>6.533898</td>\n",
              "      <td>6.296610</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.652542</td>\n",
              "      <td>2.711864</td>\n",
              "      <td>17.944915</td>\n",
              "      <td>19.110169</td>\n",
              "      <td>44.970339</td>\n",
              "      <td>193.144068</td>\n",
              "      <td>6.279661</td>\n",
              "      <td>4.165254</td>\n",
              "      <td>0.491525</td>\n",
              "      <td>6.340320</td>\n",
              "      <td>6.376997</td>\n",
              "      <td>6.448421</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.601695</td>\n",
              "      <td>2.576271</td>\n",
              "      <td>15.677966</td>\n",
              "      <td>18.970339</td>\n",
              "      <td>43.622881</td>\n",
              "      <td>190.105932</td>\n",
              "      <td>6.415254</td>\n",
              "      <td>3.868644</td>\n",
              "      <td>0.483051</td>\n",
              "      <td>6.343700</td>\n",
              "      <td>...</td>\n",
              "      <td>19.509099</td>\n",
              "      <td>19.395310</td>\n",
              "      <td>19.509132</td>\n",
              "      <td>0.699153</td>\n",
              "      <td>1.597458</td>\n",
              "      <td>7.161017</td>\n",
              "      <td>50.059322</td>\n",
              "      <td>59.970339</td>\n",
              "      <td>141.144068</td>\n",
              "      <td>596.491525</td>\n",
              "      <td>19.750000</td>\n",
              "      <td>19.923873</td>\n",
              "      <td>20.012632</td>\n",
              "      <td>19.895371</td>\n",
              "      <td>0.728814</td>\n",
              "      <td>1.699153</td>\n",
              "      <td>6.970339</td>\n",
              "      <td>52.745763</td>\n",
              "      <td>58.766949</td>\n",
              "      <td>135.911017</td>\n",
              "      <td>587.716102</td>\n",
              "      <td>19.745763</td>\n",
              "      <td>19.634766</td>\n",
              "      <td>19.556631</td>\n",
              "      <td>19.536846</td>\n",
              "      <td>0.826271</td>\n",
              "      <td>1.902542</td>\n",
              "      <td>8.046610</td>\n",
              "      <td>52.601695</td>\n",
              "      <td>56.940678</td>\n",
              "      <td>134.351695</td>\n",
              "      <td>569.775424</td>\n",
              "      <td>18.792373</td>\n",
              "      <td>18.932262</td>\n",
              "      <td>19.035428</td>\n",
              "      <td>19.058651</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>6.635593</td>\n",
              "      <td>6.415254</td>\n",
              "      <td>6.550847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1391.847737</td>\n",
              "      <td>2014.337449</td>\n",
              "      <td>4.646091</td>\n",
              "      <td>15.576132</td>\n",
              "      <td>6.168724</td>\n",
              "      <td>6.695473</td>\n",
              "      <td>5.950617</td>\n",
              "      <td>6.547325</td>\n",
              "      <td>6.637860</td>\n",
              "      <td>6.473251</td>\n",
              "      <td>6.580247</td>\n",
              "      <td>6.810700</td>\n",
              "      <td>6.436214</td>\n",
              "      <td>6.465021</td>\n",
              "      <td>6.975309</td>\n",
              "      <td>6.259259</td>\n",
              "      <td>0.283951</td>\n",
              "      <td>0.641975</td>\n",
              "      <td>2.588477</td>\n",
              "      <td>18.028807</td>\n",
              "      <td>18.584362</td>\n",
              "      <td>43.502058</td>\n",
              "      <td>190.502058</td>\n",
              "      <td>6.283951</td>\n",
              "      <td>3.621399</td>\n",
              "      <td>0.456790</td>\n",
              "      <td>6.228218</td>\n",
              "      <td>6.234115</td>\n",
              "      <td>6.338815</td>\n",
              "      <td>0.255144</td>\n",
              "      <td>0.559671</td>\n",
              "      <td>2.559671</td>\n",
              "      <td>15.983539</td>\n",
              "      <td>18.991770</td>\n",
              "      <td>44.345679</td>\n",
              "      <td>187.699588</td>\n",
              "      <td>6.209877</td>\n",
              "      <td>3.954733</td>\n",
              "      <td>0.530864</td>\n",
              "      <td>6.291379</td>\n",
              "      <td>...</td>\n",
              "      <td>19.468521</td>\n",
              "      <td>19.500761</td>\n",
              "      <td>19.372286</td>\n",
              "      <td>0.716049</td>\n",
              "      <td>1.670782</td>\n",
              "      <td>6.798354</td>\n",
              "      <td>50.399177</td>\n",
              "      <td>58.716049</td>\n",
              "      <td>137.349794</td>\n",
              "      <td>598.127572</td>\n",
              "      <td>19.810700</td>\n",
              "      <td>19.658917</td>\n",
              "      <td>19.672687</td>\n",
              "      <td>19.917954</td>\n",
              "      <td>0.798354</td>\n",
              "      <td>1.876543</td>\n",
              "      <td>7.662551</td>\n",
              "      <td>53.539095</td>\n",
              "      <td>57.790123</td>\n",
              "      <td>134.930041</td>\n",
              "      <td>578.641975</td>\n",
              "      <td>19.053498</td>\n",
              "      <td>19.189560</td>\n",
              "      <td>19.231114</td>\n",
              "      <td>19.256614</td>\n",
              "      <td>0.757202</td>\n",
              "      <td>1.753086</td>\n",
              "      <td>7.600823</td>\n",
              "      <td>52.646091</td>\n",
              "      <td>58.777778</td>\n",
              "      <td>136.781893</td>\n",
              "      <td>582.444444</td>\n",
              "      <td>19.872428</td>\n",
              "      <td>19.683003</td>\n",
              "      <td>19.595438</td>\n",
              "      <td>19.453147</td>\n",
              "      <td>6.547325</td>\n",
              "      <td>6.547325</td>\n",
              "      <td>6.497942</td>\n",
              "      <td>6.168724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1352.611111</td>\n",
              "      <td>2014.388889</td>\n",
              "      <td>5.654762</td>\n",
              "      <td>16.170635</td>\n",
              "      <td>6.511905</td>\n",
              "      <td>6.388889</td>\n",
              "      <td>6.650794</td>\n",
              "      <td>6.460317</td>\n",
              "      <td>6.436508</td>\n",
              "      <td>6.615079</td>\n",
              "      <td>6.777778</td>\n",
              "      <td>6.365079</td>\n",
              "      <td>6.289683</td>\n",
              "      <td>6.527778</td>\n",
              "      <td>6.587302</td>\n",
              "      <td>6.388889</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.599206</td>\n",
              "      <td>2.531746</td>\n",
              "      <td>18.031746</td>\n",
              "      <td>19.666667</td>\n",
              "      <td>45.674603</td>\n",
              "      <td>193.099206</td>\n",
              "      <td>6.543651</td>\n",
              "      <td>4.035714</td>\n",
              "      <td>0.507937</td>\n",
              "      <td>6.549164</td>\n",
              "      <td>6.532623</td>\n",
              "      <td>6.463820</td>\n",
              "      <td>0.242063</td>\n",
              "      <td>0.599206</td>\n",
              "      <td>2.492063</td>\n",
              "      <td>16.198413</td>\n",
              "      <td>19.563492</td>\n",
              "      <td>45.527778</td>\n",
              "      <td>190.952381</td>\n",
              "      <td>6.626984</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>0.480159</td>\n",
              "      <td>6.553102</td>\n",
              "      <td>...</td>\n",
              "      <td>19.571922</td>\n",
              "      <td>19.525636</td>\n",
              "      <td>19.405396</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>1.801587</td>\n",
              "      <td>7.083333</td>\n",
              "      <td>50.952381</td>\n",
              "      <td>59.023810</td>\n",
              "      <td>137.269841</td>\n",
              "      <td>594.035714</td>\n",
              "      <td>19.511905</td>\n",
              "      <td>19.611704</td>\n",
              "      <td>19.644026</td>\n",
              "      <td>19.801000</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>1.813492</td>\n",
              "      <td>7.904762</td>\n",
              "      <td>54.111111</td>\n",
              "      <td>57.432540</td>\n",
              "      <td>134.662698</td>\n",
              "      <td>572.099206</td>\n",
              "      <td>19.305556</td>\n",
              "      <td>19.214078</td>\n",
              "      <td>19.196382</td>\n",
              "      <td>19.097179</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>1.702381</td>\n",
              "      <td>7.317460</td>\n",
              "      <td>52.916667</td>\n",
              "      <td>59.063492</td>\n",
              "      <td>137.337302</td>\n",
              "      <td>591.638889</td>\n",
              "      <td>19.472222</td>\n",
              "      <td>19.602296</td>\n",
              "      <td>19.633956</td>\n",
              "      <td>19.696425</td>\n",
              "      <td>6.650794</td>\n",
              "      <td>6.507937</td>\n",
              "      <td>6.460317</td>\n",
              "      <td>6.511905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1341.958848</td>\n",
              "      <td>2014.358025</td>\n",
              "      <td>6.707819</td>\n",
              "      <td>15.728395</td>\n",
              "      <td>6.497942</td>\n",
              "      <td>6.534979</td>\n",
              "      <td>6.448560</td>\n",
              "      <td>6.539095</td>\n",
              "      <td>6.588477</td>\n",
              "      <td>6.526749</td>\n",
              "      <td>6.613169</td>\n",
              "      <td>6.283951</td>\n",
              "      <td>6.633745</td>\n",
              "      <td>6.502058</td>\n",
              "      <td>6.419753</td>\n",
              "      <td>6.411523</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.497942</td>\n",
              "      <td>2.477366</td>\n",
              "      <td>18.263374</td>\n",
              "      <td>19.559671</td>\n",
              "      <td>46.061728</td>\n",
              "      <td>195.115226</td>\n",
              "      <td>6.485597</td>\n",
              "      <td>3.979424</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>6.515699</td>\n",
              "      <td>6.546161</td>\n",
              "      <td>6.512120</td>\n",
              "      <td>0.218107</td>\n",
              "      <td>0.506173</td>\n",
              "      <td>2.267490</td>\n",
              "      <td>16.193416</td>\n",
              "      <td>20.242798</td>\n",
              "      <td>46.810700</td>\n",
              "      <td>200.271605</td>\n",
              "      <td>6.670782</td>\n",
              "      <td>3.909465</td>\n",
              "      <td>0.514403</td>\n",
              "      <td>6.715998</td>\n",
              "      <td>...</td>\n",
              "      <td>19.871278</td>\n",
              "      <td>19.826892</td>\n",
              "      <td>19.868695</td>\n",
              "      <td>0.695473</td>\n",
              "      <td>1.592593</td>\n",
              "      <td>7.456790</td>\n",
              "      <td>51.777778</td>\n",
              "      <td>59.053498</td>\n",
              "      <td>138.979424</td>\n",
              "      <td>583.662551</td>\n",
              "      <td>19.728395</td>\n",
              "      <td>19.725554</td>\n",
              "      <td>19.744569</td>\n",
              "      <td>19.497949</td>\n",
              "      <td>0.773663</td>\n",
              "      <td>1.843621</td>\n",
              "      <td>7.654321</td>\n",
              "      <td>54.267490</td>\n",
              "      <td>58.810700</td>\n",
              "      <td>135.810700</td>\n",
              "      <td>586.942387</td>\n",
              "      <td>19.559671</td>\n",
              "      <td>19.553347</td>\n",
              "      <td>19.503571</td>\n",
              "      <td>19.588015</td>\n",
              "      <td>0.810700</td>\n",
              "      <td>1.831276</td>\n",
              "      <td>7.596708</td>\n",
              "      <td>54.012346</td>\n",
              "      <td>56.325103</td>\n",
              "      <td>133.152263</td>\n",
              "      <td>573.411523</td>\n",
              "      <td>18.884774</td>\n",
              "      <td>18.849821</td>\n",
              "      <td>18.924968</td>\n",
              "      <td>19.045341</td>\n",
              "      <td>6.481481</td>\n",
              "      <td>6.432099</td>\n",
              "      <td>6.481481</td>\n",
              "      <td>6.497942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1409.015267</td>\n",
              "      <td>2014.026718</td>\n",
              "      <td>7.729008</td>\n",
              "      <td>15.759542</td>\n",
              "      <td>6.564885</td>\n",
              "      <td>6.248092</td>\n",
              "      <td>6.255725</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>6.324427</td>\n",
              "      <td>6.515267</td>\n",
              "      <td>6.606870</td>\n",
              "      <td>6.538168</td>\n",
              "      <td>6.370229</td>\n",
              "      <td>6.774809</td>\n",
              "      <td>6.809160</td>\n",
              "      <td>6.492366</td>\n",
              "      <td>0.194656</td>\n",
              "      <td>0.469466</td>\n",
              "      <td>1.931298</td>\n",
              "      <td>17.057252</td>\n",
              "      <td>20.156489</td>\n",
              "      <td>46.389313</td>\n",
              "      <td>198.545802</td>\n",
              "      <td>6.729008</td>\n",
              "      <td>4.064885</td>\n",
              "      <td>0.511450</td>\n",
              "      <td>6.709268</td>\n",
              "      <td>6.667849</td>\n",
              "      <td>6.593702</td>\n",
              "      <td>0.274809</td>\n",
              "      <td>0.595420</td>\n",
              "      <td>2.354962</td>\n",
              "      <td>15.488550</td>\n",
              "      <td>18.881679</td>\n",
              "      <td>44.862595</td>\n",
              "      <td>195.064885</td>\n",
              "      <td>6.316794</td>\n",
              "      <td>4.206107</td>\n",
              "      <td>0.473282</td>\n",
              "      <td>6.315747</td>\n",
              "      <td>...</td>\n",
              "      <td>18.915976</td>\n",
              "      <td>19.032827</td>\n",
              "      <td>19.222384</td>\n",
              "      <td>0.748092</td>\n",
              "      <td>1.790076</td>\n",
              "      <td>7.019084</td>\n",
              "      <td>49.076336</td>\n",
              "      <td>60.477099</td>\n",
              "      <td>139.557252</td>\n",
              "      <td>602.564885</td>\n",
              "      <td>20.194656</td>\n",
              "      <td>20.140059</td>\n",
              "      <td>20.058828</td>\n",
              "      <td>20.034850</td>\n",
              "      <td>0.748092</td>\n",
              "      <td>1.729008</td>\n",
              "      <td>7.637405</td>\n",
              "      <td>51.950382</td>\n",
              "      <td>56.797710</td>\n",
              "      <td>133.809160</td>\n",
              "      <td>570.209924</td>\n",
              "      <td>18.916031</td>\n",
              "      <td>18.950076</td>\n",
              "      <td>19.001658</td>\n",
              "      <td>19.027451</td>\n",
              "      <td>0.648855</td>\n",
              "      <td>1.572519</td>\n",
              "      <td>6.961832</td>\n",
              "      <td>50.847328</td>\n",
              "      <td>60.099237</td>\n",
              "      <td>138.305344</td>\n",
              "      <td>589.320611</td>\n",
              "      <td>20.019084</td>\n",
              "      <td>19.993889</td>\n",
              "      <td>19.906406</td>\n",
              "      <td>19.715314</td>\n",
              "      <td>6.393130</td>\n",
              "      <td>6.408397</td>\n",
              "      <td>6.652672</td>\n",
              "      <td>6.564885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             項番            年         月  ...   月星座同属性1   月星座同属性2     当日の回答\n",
              "星座                                      ...                              \n",
              "1   1401.563559  2014.389831  3.631356  ...  6.635593  6.415254  6.550847\n",
              "2   1391.847737  2014.337449  4.646091  ...  6.547325  6.497942  6.168724\n",
              "3   1352.611111  2014.388889  5.654762  ...  6.507937  6.460317  6.511905\n",
              "4   1341.958848  2014.358025  6.707819  ...  6.432099  6.481481  6.497942\n",
              "5   1409.015267  2014.026718  7.729008  ...  6.408397  6.652672  6.564885\n",
              "\n",
              "[5 rows x 220 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYZofmf7Hn8o",
        "colab_type": "code",
        "outputId": "ef758c28-57b9-4ab3-d3a1-6943195b520e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(font='IPAGothic')\n",
        "mean = pd.DataFrame(mean)\n",
        "mean_graph = mean.drop([\"年\",\"月\",\"日\",\"項番\"], axis=1)\n",
        "mean_graph = mean_graph.rename(index={1: \"牡羊\", 2: \"牡牛\", 3: \"双子\", 4: \"蟹\", 5: \"獅子\", 6: \"乙女\", 7: \"天秤\", 8: \"蠍\", 9: \"射手\", 10: \"山羊\", 11: \"水瓶\", 12: \"魚\", })\n",
        "mean_graph.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1位</th>\n",
              "      <th>2位</th>\n",
              "      <th>3位</th>\n",
              "      <th>4位</th>\n",
              "      <th>5位</th>\n",
              "      <th>6位</th>\n",
              "      <th>7位</th>\n",
              "      <th>8位</th>\n",
              "      <th>9位</th>\n",
              "      <th>10位</th>\n",
              "      <th>11位</th>\n",
              "      <th>12位</th>\n",
              "      <th>2座3日1位数</th>\n",
              "      <th>2座7日1位数</th>\n",
              "      <th>2座30日1位数</th>\n",
              "      <th>2座365日1位数</th>\n",
              "      <th>2座3日成績</th>\n",
              "      <th>2座7日成績</th>\n",
              "      <th>2座30日成績</th>\n",
              "      <th>2座1日成績</th>\n",
              "      <th>2座_絶対値_前日-前々日</th>\n",
              "      <th>2座_+-_前日-前々日</th>\n",
              "      <th>2_3日_EMA</th>\n",
              "      <th>2_7日_EMA</th>\n",
              "      <th>2_30日_EMA</th>\n",
              "      <th>1座3日1位数</th>\n",
              "      <th>1座7日1位数</th>\n",
              "      <th>1座30日1位数</th>\n",
              "      <th>1座365日1位数</th>\n",
              "      <th>1座3日成績</th>\n",
              "      <th>1座7日成績</th>\n",
              "      <th>1座30日成績</th>\n",
              "      <th>1座前日成績</th>\n",
              "      <th>1座_絶対値_前日-前々日</th>\n",
              "      <th>1座_+-_前日-前々日</th>\n",
              "      <th>1_3日_EMA</th>\n",
              "      <th>1_7日_EMA</th>\n",
              "      <th>1_30日_EMA</th>\n",
              "      <th>6座3日1位数</th>\n",
              "      <th>6座7日1位数</th>\n",
              "      <th>...</th>\n",
              "      <th>火の属性3日_EMA</th>\n",
              "      <th>火の属性_7日_EMA</th>\n",
              "      <th>火の属性_30日_EMA</th>\n",
              "      <th>土の属性3日1位数</th>\n",
              "      <th>土の属性7日1位数</th>\n",
              "      <th>土の属性30日1位数</th>\n",
              "      <th>土の属性365日1位数</th>\n",
              "      <th>土の属性3日成績</th>\n",
              "      <th>土の属性7日成績</th>\n",
              "      <th>土の属性30日成績</th>\n",
              "      <th>土の属性前日成績</th>\n",
              "      <th>土の属性3日_EMA</th>\n",
              "      <th>土の属性_7日_EMA</th>\n",
              "      <th>土の属性_30日_EMA</th>\n",
              "      <th>風の属性3日1位数</th>\n",
              "      <th>風の属性7日1位数</th>\n",
              "      <th>風の属性30日1位数</th>\n",
              "      <th>風の属性365日1位数</th>\n",
              "      <th>風の属性3日成績</th>\n",
              "      <th>風の属性7日成績</th>\n",
              "      <th>風の属性30日成績</th>\n",
              "      <th>風の属性前日成績</th>\n",
              "      <th>風の属性3日_EMA</th>\n",
              "      <th>風の属性_7日_EMA</th>\n",
              "      <th>風の属性_30日_EMA</th>\n",
              "      <th>水の属性3日1位数</th>\n",
              "      <th>水の属性7日1位数</th>\n",
              "      <th>水の属性30日1位数</th>\n",
              "      <th>水の属性365日1位数</th>\n",
              "      <th>水の属性3日成績</th>\n",
              "      <th>水の属性7日成績</th>\n",
              "      <th>水の属性30日成績</th>\n",
              "      <th>水の属性前日成績</th>\n",
              "      <th>水の属性3日_EMA</th>\n",
              "      <th>水の属性_7日_EMA</th>\n",
              "      <th>水の属性_30日_EMA</th>\n",
              "      <th>月星座</th>\n",
              "      <th>月星座同属性1</th>\n",
              "      <th>月星座同属性2</th>\n",
              "      <th>当日の回答</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>星座</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>牡羊</th>\n",
              "      <td>6.550847</td>\n",
              "      <td>6.508475</td>\n",
              "      <td>6.432203</td>\n",
              "      <td>6.330508</td>\n",
              "      <td>6.351695</td>\n",
              "      <td>6.758475</td>\n",
              "      <td>6.622881</td>\n",
              "      <td>6.745763</td>\n",
              "      <td>6.593220</td>\n",
              "      <td>6.275424</td>\n",
              "      <td>6.533898</td>\n",
              "      <td>6.296610</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.652542</td>\n",
              "      <td>2.711864</td>\n",
              "      <td>17.944915</td>\n",
              "      <td>19.110169</td>\n",
              "      <td>44.970339</td>\n",
              "      <td>193.144068</td>\n",
              "      <td>6.279661</td>\n",
              "      <td>4.165254</td>\n",
              "      <td>0.491525</td>\n",
              "      <td>6.340320</td>\n",
              "      <td>6.376997</td>\n",
              "      <td>6.448421</td>\n",
              "      <td>0.237288</td>\n",
              "      <td>0.601695</td>\n",
              "      <td>2.576271</td>\n",
              "      <td>15.677966</td>\n",
              "      <td>18.970339</td>\n",
              "      <td>43.622881</td>\n",
              "      <td>190.105932</td>\n",
              "      <td>6.415254</td>\n",
              "      <td>3.868644</td>\n",
              "      <td>0.483051</td>\n",
              "      <td>6.343700</td>\n",
              "      <td>6.296285</td>\n",
              "      <td>6.343002</td>\n",
              "      <td>0.245763</td>\n",
              "      <td>0.555085</td>\n",
              "      <td>...</td>\n",
              "      <td>19.509099</td>\n",
              "      <td>19.395310</td>\n",
              "      <td>19.509132</td>\n",
              "      <td>0.699153</td>\n",
              "      <td>1.597458</td>\n",
              "      <td>7.161017</td>\n",
              "      <td>50.059322</td>\n",
              "      <td>59.970339</td>\n",
              "      <td>141.144068</td>\n",
              "      <td>596.491525</td>\n",
              "      <td>19.750000</td>\n",
              "      <td>19.923873</td>\n",
              "      <td>20.012632</td>\n",
              "      <td>19.895371</td>\n",
              "      <td>0.728814</td>\n",
              "      <td>1.699153</td>\n",
              "      <td>6.970339</td>\n",
              "      <td>52.745763</td>\n",
              "      <td>58.766949</td>\n",
              "      <td>135.911017</td>\n",
              "      <td>587.716102</td>\n",
              "      <td>19.745763</td>\n",
              "      <td>19.634766</td>\n",
              "      <td>19.556631</td>\n",
              "      <td>19.536846</td>\n",
              "      <td>0.826271</td>\n",
              "      <td>1.902542</td>\n",
              "      <td>8.046610</td>\n",
              "      <td>52.601695</td>\n",
              "      <td>56.940678</td>\n",
              "      <td>134.351695</td>\n",
              "      <td>569.775424</td>\n",
              "      <td>18.792373</td>\n",
              "      <td>18.932262</td>\n",
              "      <td>19.035428</td>\n",
              "      <td>19.058651</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>6.635593</td>\n",
              "      <td>6.415254</td>\n",
              "      <td>6.550847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>牡牛</th>\n",
              "      <td>6.168724</td>\n",
              "      <td>6.695473</td>\n",
              "      <td>5.950617</td>\n",
              "      <td>6.547325</td>\n",
              "      <td>6.637860</td>\n",
              "      <td>6.473251</td>\n",
              "      <td>6.580247</td>\n",
              "      <td>6.810700</td>\n",
              "      <td>6.436214</td>\n",
              "      <td>6.465021</td>\n",
              "      <td>6.975309</td>\n",
              "      <td>6.259259</td>\n",
              "      <td>0.283951</td>\n",
              "      <td>0.641975</td>\n",
              "      <td>2.588477</td>\n",
              "      <td>18.028807</td>\n",
              "      <td>18.584362</td>\n",
              "      <td>43.502058</td>\n",
              "      <td>190.502058</td>\n",
              "      <td>6.283951</td>\n",
              "      <td>3.621399</td>\n",
              "      <td>0.456790</td>\n",
              "      <td>6.228218</td>\n",
              "      <td>6.234115</td>\n",
              "      <td>6.338815</td>\n",
              "      <td>0.255144</td>\n",
              "      <td>0.559671</td>\n",
              "      <td>2.559671</td>\n",
              "      <td>15.983539</td>\n",
              "      <td>18.991770</td>\n",
              "      <td>44.345679</td>\n",
              "      <td>187.699588</td>\n",
              "      <td>6.209877</td>\n",
              "      <td>3.954733</td>\n",
              "      <td>0.530864</td>\n",
              "      <td>6.291379</td>\n",
              "      <td>6.303593</td>\n",
              "      <td>6.249334</td>\n",
              "      <td>0.209877</td>\n",
              "      <td>0.497942</td>\n",
              "      <td>...</td>\n",
              "      <td>19.468521</td>\n",
              "      <td>19.500761</td>\n",
              "      <td>19.372286</td>\n",
              "      <td>0.716049</td>\n",
              "      <td>1.670782</td>\n",
              "      <td>6.798354</td>\n",
              "      <td>50.399177</td>\n",
              "      <td>58.716049</td>\n",
              "      <td>137.349794</td>\n",
              "      <td>598.127572</td>\n",
              "      <td>19.810700</td>\n",
              "      <td>19.658917</td>\n",
              "      <td>19.672687</td>\n",
              "      <td>19.917954</td>\n",
              "      <td>0.798354</td>\n",
              "      <td>1.876543</td>\n",
              "      <td>7.662551</td>\n",
              "      <td>53.539095</td>\n",
              "      <td>57.790123</td>\n",
              "      <td>134.930041</td>\n",
              "      <td>578.641975</td>\n",
              "      <td>19.053498</td>\n",
              "      <td>19.189560</td>\n",
              "      <td>19.231114</td>\n",
              "      <td>19.256614</td>\n",
              "      <td>0.757202</td>\n",
              "      <td>1.753086</td>\n",
              "      <td>7.600823</td>\n",
              "      <td>52.646091</td>\n",
              "      <td>58.777778</td>\n",
              "      <td>136.781893</td>\n",
              "      <td>582.444444</td>\n",
              "      <td>19.872428</td>\n",
              "      <td>19.683003</td>\n",
              "      <td>19.595438</td>\n",
              "      <td>19.453147</td>\n",
              "      <td>6.547325</td>\n",
              "      <td>6.547325</td>\n",
              "      <td>6.497942</td>\n",
              "      <td>6.168724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>双子</th>\n",
              "      <td>6.511905</td>\n",
              "      <td>6.388889</td>\n",
              "      <td>6.650794</td>\n",
              "      <td>6.460317</td>\n",
              "      <td>6.436508</td>\n",
              "      <td>6.615079</td>\n",
              "      <td>6.777778</td>\n",
              "      <td>6.365079</td>\n",
              "      <td>6.289683</td>\n",
              "      <td>6.527778</td>\n",
              "      <td>6.587302</td>\n",
              "      <td>6.388889</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.599206</td>\n",
              "      <td>2.531746</td>\n",
              "      <td>18.031746</td>\n",
              "      <td>19.666667</td>\n",
              "      <td>45.674603</td>\n",
              "      <td>193.099206</td>\n",
              "      <td>6.543651</td>\n",
              "      <td>4.035714</td>\n",
              "      <td>0.507937</td>\n",
              "      <td>6.549164</td>\n",
              "      <td>6.532623</td>\n",
              "      <td>6.463820</td>\n",
              "      <td>0.242063</td>\n",
              "      <td>0.599206</td>\n",
              "      <td>2.492063</td>\n",
              "      <td>16.198413</td>\n",
              "      <td>19.563492</td>\n",
              "      <td>45.527778</td>\n",
              "      <td>190.952381</td>\n",
              "      <td>6.626984</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>0.480159</td>\n",
              "      <td>6.553102</td>\n",
              "      <td>6.512684</td>\n",
              "      <td>6.387504</td>\n",
              "      <td>0.297619</td>\n",
              "      <td>0.650794</td>\n",
              "      <td>...</td>\n",
              "      <td>19.571922</td>\n",
              "      <td>19.525636</td>\n",
              "      <td>19.405396</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>1.801587</td>\n",
              "      <td>7.083333</td>\n",
              "      <td>50.952381</td>\n",
              "      <td>59.023810</td>\n",
              "      <td>137.269841</td>\n",
              "      <td>594.035714</td>\n",
              "      <td>19.511905</td>\n",
              "      <td>19.611704</td>\n",
              "      <td>19.644026</td>\n",
              "      <td>19.801000</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>1.813492</td>\n",
              "      <td>7.904762</td>\n",
              "      <td>54.111111</td>\n",
              "      <td>57.432540</td>\n",
              "      <td>134.662698</td>\n",
              "      <td>572.099206</td>\n",
              "      <td>19.305556</td>\n",
              "      <td>19.214078</td>\n",
              "      <td>19.196382</td>\n",
              "      <td>19.097179</td>\n",
              "      <td>0.702381</td>\n",
              "      <td>1.702381</td>\n",
              "      <td>7.317460</td>\n",
              "      <td>52.916667</td>\n",
              "      <td>59.063492</td>\n",
              "      <td>137.337302</td>\n",
              "      <td>591.638889</td>\n",
              "      <td>19.472222</td>\n",
              "      <td>19.602296</td>\n",
              "      <td>19.633956</td>\n",
              "      <td>19.696425</td>\n",
              "      <td>6.650794</td>\n",
              "      <td>6.507937</td>\n",
              "      <td>6.460317</td>\n",
              "      <td>6.511905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>蟹</th>\n",
              "      <td>6.497942</td>\n",
              "      <td>6.534979</td>\n",
              "      <td>6.448560</td>\n",
              "      <td>6.539095</td>\n",
              "      <td>6.588477</td>\n",
              "      <td>6.526749</td>\n",
              "      <td>6.613169</td>\n",
              "      <td>6.283951</td>\n",
              "      <td>6.633745</td>\n",
              "      <td>6.502058</td>\n",
              "      <td>6.419753</td>\n",
              "      <td>6.411523</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.497942</td>\n",
              "      <td>2.477366</td>\n",
              "      <td>18.263374</td>\n",
              "      <td>19.559671</td>\n",
              "      <td>46.061728</td>\n",
              "      <td>195.115226</td>\n",
              "      <td>6.485597</td>\n",
              "      <td>3.979424</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>6.515699</td>\n",
              "      <td>6.546161</td>\n",
              "      <td>6.512120</td>\n",
              "      <td>0.218107</td>\n",
              "      <td>0.506173</td>\n",
              "      <td>2.267490</td>\n",
              "      <td>16.193416</td>\n",
              "      <td>20.242798</td>\n",
              "      <td>46.810700</td>\n",
              "      <td>200.271605</td>\n",
              "      <td>6.670782</td>\n",
              "      <td>3.909465</td>\n",
              "      <td>0.514403</td>\n",
              "      <td>6.715998</td>\n",
              "      <td>6.707030</td>\n",
              "      <td>6.675219</td>\n",
              "      <td>0.267490</td>\n",
              "      <td>0.609053</td>\n",
              "      <td>...</td>\n",
              "      <td>19.871278</td>\n",
              "      <td>19.826892</td>\n",
              "      <td>19.868695</td>\n",
              "      <td>0.695473</td>\n",
              "      <td>1.592593</td>\n",
              "      <td>7.456790</td>\n",
              "      <td>51.777778</td>\n",
              "      <td>59.053498</td>\n",
              "      <td>138.979424</td>\n",
              "      <td>583.662551</td>\n",
              "      <td>19.728395</td>\n",
              "      <td>19.725554</td>\n",
              "      <td>19.744569</td>\n",
              "      <td>19.497949</td>\n",
              "      <td>0.773663</td>\n",
              "      <td>1.843621</td>\n",
              "      <td>7.654321</td>\n",
              "      <td>54.267490</td>\n",
              "      <td>58.810700</td>\n",
              "      <td>135.810700</td>\n",
              "      <td>586.942387</td>\n",
              "      <td>19.559671</td>\n",
              "      <td>19.553347</td>\n",
              "      <td>19.503571</td>\n",
              "      <td>19.588015</td>\n",
              "      <td>0.810700</td>\n",
              "      <td>1.831276</td>\n",
              "      <td>7.596708</td>\n",
              "      <td>54.012346</td>\n",
              "      <td>56.325103</td>\n",
              "      <td>133.152263</td>\n",
              "      <td>573.411523</td>\n",
              "      <td>18.884774</td>\n",
              "      <td>18.849821</td>\n",
              "      <td>18.924968</td>\n",
              "      <td>19.045341</td>\n",
              "      <td>6.481481</td>\n",
              "      <td>6.432099</td>\n",
              "      <td>6.481481</td>\n",
              "      <td>6.497942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>獅子</th>\n",
              "      <td>6.564885</td>\n",
              "      <td>6.248092</td>\n",
              "      <td>6.255725</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>6.324427</td>\n",
              "      <td>6.515267</td>\n",
              "      <td>6.606870</td>\n",
              "      <td>6.538168</td>\n",
              "      <td>6.370229</td>\n",
              "      <td>6.774809</td>\n",
              "      <td>6.809160</td>\n",
              "      <td>6.492366</td>\n",
              "      <td>0.194656</td>\n",
              "      <td>0.469466</td>\n",
              "      <td>1.931298</td>\n",
              "      <td>17.057252</td>\n",
              "      <td>20.156489</td>\n",
              "      <td>46.389313</td>\n",
              "      <td>198.545802</td>\n",
              "      <td>6.729008</td>\n",
              "      <td>4.064885</td>\n",
              "      <td>0.511450</td>\n",
              "      <td>6.709268</td>\n",
              "      <td>6.667849</td>\n",
              "      <td>6.593702</td>\n",
              "      <td>0.274809</td>\n",
              "      <td>0.595420</td>\n",
              "      <td>2.354962</td>\n",
              "      <td>15.488550</td>\n",
              "      <td>18.881679</td>\n",
              "      <td>44.862595</td>\n",
              "      <td>195.064885</td>\n",
              "      <td>6.316794</td>\n",
              "      <td>4.206107</td>\n",
              "      <td>0.473282</td>\n",
              "      <td>6.315747</td>\n",
              "      <td>6.364473</td>\n",
              "      <td>6.462126</td>\n",
              "      <td>0.278626</td>\n",
              "      <td>0.675573</td>\n",
              "      <td>...</td>\n",
              "      <td>18.915976</td>\n",
              "      <td>19.032827</td>\n",
              "      <td>19.222384</td>\n",
              "      <td>0.748092</td>\n",
              "      <td>1.790076</td>\n",
              "      <td>7.019084</td>\n",
              "      <td>49.076336</td>\n",
              "      <td>60.477099</td>\n",
              "      <td>139.557252</td>\n",
              "      <td>602.564885</td>\n",
              "      <td>20.194656</td>\n",
              "      <td>20.140059</td>\n",
              "      <td>20.058828</td>\n",
              "      <td>20.034850</td>\n",
              "      <td>0.748092</td>\n",
              "      <td>1.729008</td>\n",
              "      <td>7.637405</td>\n",
              "      <td>51.950382</td>\n",
              "      <td>56.797710</td>\n",
              "      <td>133.809160</td>\n",
              "      <td>570.209924</td>\n",
              "      <td>18.916031</td>\n",
              "      <td>18.950076</td>\n",
              "      <td>19.001658</td>\n",
              "      <td>19.027451</td>\n",
              "      <td>0.648855</td>\n",
              "      <td>1.572519</td>\n",
              "      <td>6.961832</td>\n",
              "      <td>50.847328</td>\n",
              "      <td>60.099237</td>\n",
              "      <td>138.305344</td>\n",
              "      <td>589.320611</td>\n",
              "      <td>20.019084</td>\n",
              "      <td>19.993889</td>\n",
              "      <td>19.906406</td>\n",
              "      <td>19.715314</td>\n",
              "      <td>6.393130</td>\n",
              "      <td>6.408397</td>\n",
              "      <td>6.652672</td>\n",
              "      <td>6.564885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 216 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          1位        2位        3位  ...   月星座同属性1   月星座同属性2     当日の回答\n",
              "星座                                ...                              \n",
              "牡羊  6.550847  6.508475  6.432203  ...  6.635593  6.415254  6.550847\n",
              "牡牛  6.168724  6.695473  5.950617  ...  6.547325  6.497942  6.168724\n",
              "双子  6.511905  6.388889  6.650794  ...  6.507937  6.460317  6.511905\n",
              "蟹   6.497942  6.534979  6.448560  ...  6.432099  6.481481  6.497942\n",
              "獅子  6.564885  6.248092  6.255725  ...  6.408397  6.652672  6.564885\n",
              "\n",
              "[5 rows x 216 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4odILdszwdFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean.to_csv('/content/drive/My Drive/mean_20190531.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOnho6Dsv7PQ",
        "colab_type": "code",
        "outputId": "d707c49d-0003-4541-bd1b-f6b6c0eacc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!cat /content/output.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "項番,年,月,日,牡牛座1日成績,牡羊座1日成績,乙女座1日成績,蟹座1日成績,魚座1日成績,山羊座1日成績,獅子座1日成績,射手座1日成績,水瓶座1日成績,双子座1日成績,天秤座1日成績,蠍座1日成績\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNUonCj8nSss",
        "colab_type": "code",
        "outputId": "7c7923d9-115b-45d6-b4e1-fb06db758c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "df_mean = pd.DataFrame(countdown_raw.mean())\n",
        "df_mean = df_mean.drop([\"星座\",\"月\",\"日\",\"項番\"], axis=0)\n",
        "df_mean_sort = df_mean.sort_values(0)\n",
        "df_mean_sort = df_mean_sort.rename(columns={0: '順位平均'})\n",
        "df_mean_sort.head(12)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>順位平均</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>山羊座3日1位数</th>\n",
              "      <td>0.233080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>牡羊座3日1位数</th>\n",
              "      <td>0.243439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>双子座3日1位数</th>\n",
              "      <td>0.244475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>射手座3日1位数</th>\n",
              "      <td>0.245511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>魚座3日1位数</th>\n",
              "      <td>0.247583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>乙女座3日1位数</th>\n",
              "      <td>0.247583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>水瓶座3日1位数</th>\n",
              "      <td>0.249655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>牡牛座3日1位数</th>\n",
              "      <td>0.250691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>蟹座3日1位数</th>\n",
              "      <td>0.250691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>獅子座3日1位数</th>\n",
              "      <td>0.254834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>蠍座3日1位数</th>\n",
              "      <td>0.263122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>天秤座3日1位数</th>\n",
              "      <td>0.269337</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              順位平均\n",
              "山羊座3日1位数  0.233080\n",
              "牡羊座3日1位数  0.243439\n",
              "双子座3日1位数  0.244475\n",
              "射手座3日1位数  0.245511\n",
              "魚座3日1位数   0.247583\n",
              "乙女座3日1位数  0.247583\n",
              "水瓶座3日1位数  0.249655\n",
              "牡牛座3日1位数  0.250691\n",
              "蟹座3日1位数   0.250691\n",
              "獅子座3日1位数  0.254834\n",
              "蠍座3日1位数   0.263122\n",
              "天秤座3日1位数  0.269337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM3kGnZT9cGc",
        "colab_type": "code",
        "outputId": "75bd7bc0-c2b6-422c-baf1-ff48f1dc4e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "source": [
        "# 万が一順序性が影響を与えていると正確にデータが取れないので、順序の入れ替えを行う。\n",
        "data = countdown.sample(frac=1, random_state=0)\n",
        "# 項番を残しつつ、インデックスの振り直しをする。\n",
        "#data = data.reset_index(drop=True)\n",
        "data = data.reset_index()\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>項番</th>\n",
              "      <th>年</th>\n",
              "      <th>月</th>\n",
              "      <th>日</th>\n",
              "      <th>牡牛座3日成績</th>\n",
              "      <th>牡牛座7日成績</th>\n",
              "      <th>牡牛座30日成績</th>\n",
              "      <th>牡牛座1日成績</th>\n",
              "      <th>牡牛座_絶対値_前日-前々日</th>\n",
              "      <th>牡牛座_+-_前日-前々日</th>\n",
              "      <th>牡牛_3日_EMA</th>\n",
              "      <th>牡牛_7日_EMA</th>\n",
              "      <th>牡牛_30日_EMA</th>\n",
              "      <th>牡羊座3日成績</th>\n",
              "      <th>牡羊座7日成績</th>\n",
              "      <th>牡羊座30日成績</th>\n",
              "      <th>牡羊座前日成績</th>\n",
              "      <th>牡羊座_絶対値_前日-前々日</th>\n",
              "      <th>牡羊座_+-_前日-前々日</th>\n",
              "      <th>牡羊_3日_EMA</th>\n",
              "      <th>牡羊_7日_EMA</th>\n",
              "      <th>牡羊_30日_EMA</th>\n",
              "      <th>乙女座3日成績</th>\n",
              "      <th>乙女座7日成績</th>\n",
              "      <th>乙女座30日成績</th>\n",
              "      <th>乙女座前日成績</th>\n",
              "      <th>乙女座_絶対値_前日-前々日</th>\n",
              "      <th>乙女座_+-_前日-前々日</th>\n",
              "      <th>乙女_3日_EMA</th>\n",
              "      <th>乙女_7日_EMA</th>\n",
              "      <th>乙女_30日_EMA</th>\n",
              "      <th>蟹座3日成績</th>\n",
              "      <th>蟹座7日成績</th>\n",
              "      <th>蟹座30日成績</th>\n",
              "      <th>蟹座前日成績</th>\n",
              "      <th>蟹座_絶対値_前日-前々日</th>\n",
              "      <th>蟹座_+-_前日-前々日</th>\n",
              "      <th>蟹_3日_EMA</th>\n",
              "      <th>蟹_7日_EMA</th>\n",
              "      <th>...</th>\n",
              "      <th>蠍座前日成績</th>\n",
              "      <th>蠍座_絶対値_前日-前々日</th>\n",
              "      <th>蠍座_+-_前日-前々日</th>\n",
              "      <th>蠍_3日_EMA</th>\n",
              "      <th>蠍_7日_EMA</th>\n",
              "      <th>蠍_30日_EMA</th>\n",
              "      <th>火の属性3日成績</th>\n",
              "      <th>火の属性7日成績</th>\n",
              "      <th>火の属性30日成績</th>\n",
              "      <th>火の属性前日成績</th>\n",
              "      <th>火の属性3日_EMA</th>\n",
              "      <th>火の属性_7日_EMA</th>\n",
              "      <th>火の属性_30日_EMA</th>\n",
              "      <th>土の属性3日成績</th>\n",
              "      <th>土の属性7日成績</th>\n",
              "      <th>土の属性30日成績</th>\n",
              "      <th>土の属性前日成績</th>\n",
              "      <th>土の属性3日_EMA</th>\n",
              "      <th>土の属性_7日_EMA</th>\n",
              "      <th>土の属性_30日_EMA</th>\n",
              "      <th>風の属性3日成績</th>\n",
              "      <th>風の属性7日成績</th>\n",
              "      <th>風の属性30日成績</th>\n",
              "      <th>風の属性前日成績</th>\n",
              "      <th>風の属性3日_EMA</th>\n",
              "      <th>風の属性_7日_EMA</th>\n",
              "      <th>風の属性_30日_EMA</th>\n",
              "      <th>水の属性3日成績</th>\n",
              "      <th>水の属性7日成績</th>\n",
              "      <th>水の属性30日成績</th>\n",
              "      <th>水の属性前日成績</th>\n",
              "      <th>水の属性3日_EMA</th>\n",
              "      <th>水の属性_7日_EMA</th>\n",
              "      <th>水の属性_30日_EMA</th>\n",
              "      <th>月の星座</th>\n",
              "      <th>月星座同属性1</th>\n",
              "      <th>月星座同属性2</th>\n",
              "      <th>星座</th>\n",
              "      <th>当日の回答</th>\n",
              "      <th>星座.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1390</td>\n",
              "      <td>1391</td>\n",
              "      <td>2014</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>52</td>\n",
              "      <td>200</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8.884236</td>\n",
              "      <td>7.721243</td>\n",
              "      <td>6.774873</td>\n",
              "      <td>19</td>\n",
              "      <td>45</td>\n",
              "      <td>187</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.997916</td>\n",
              "      <td>5.614798</td>\n",
              "      <td>6.033229</td>\n",
              "      <td>21</td>\n",
              "      <td>46</td>\n",
              "      <td>198</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8.322662</td>\n",
              "      <td>7.336093</td>\n",
              "      <td>6.704500</td>\n",
              "      <td>24</td>\n",
              "      <td>46</td>\n",
              "      <td>209</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9.567863</td>\n",
              "      <td>7.968635</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.058102</td>\n",
              "      <td>6.395634</td>\n",
              "      <td>6.468552</td>\n",
              "      <td>55</td>\n",
              "      <td>132</td>\n",
              "      <td>558</td>\n",
              "      <td>15</td>\n",
              "      <td>15.553437</td>\n",
              "      <td>17.062819</td>\n",
              "      <td>18.201628</td>\n",
              "      <td>69</td>\n",
              "      <td>157</td>\n",
              "      <td>617</td>\n",
              "      <td>30</td>\n",
              "      <td>27.024075</td>\n",
              "      <td>23.929444</td>\n",
              "      <td>20.999764</td>\n",
              "      <td>44</td>\n",
              "      <td>123</td>\n",
              "      <td>539</td>\n",
              "      <td>6</td>\n",
              "      <td>10.901716</td>\n",
              "      <td>14.929923</td>\n",
              "      <td>18.095004</td>\n",
              "      <td>66</td>\n",
              "      <td>134</td>\n",
              "      <td>626</td>\n",
              "      <td>27</td>\n",
              "      <td>24.520772</td>\n",
              "      <td>22.077813</td>\n",
              "      <td>20.703604</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>2014/2/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>196</td>\n",
              "      <td>197</td>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>43</td>\n",
              "      <td>208</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4.932791</td>\n",
              "      <td>5.802851</td>\n",
              "      <td>6.550351</td>\n",
              "      <td>18</td>\n",
              "      <td>48</td>\n",
              "      <td>191</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6.522758</td>\n",
              "      <td>6.511411</td>\n",
              "      <td>6.575584</td>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>188</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>6.040624</td>\n",
              "      <td>5.963601</td>\n",
              "      <td>6.220642</td>\n",
              "      <td>18</td>\n",
              "      <td>45</td>\n",
              "      <td>198</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6.262757</td>\n",
              "      <td>6.246229</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3.094778</td>\n",
              "      <td>3.834215</td>\n",
              "      <td>5.232717</td>\n",
              "      <td>65</td>\n",
              "      <td>153</td>\n",
              "      <td>579</td>\n",
              "      <td>29</td>\n",
              "      <td>22.966157</td>\n",
              "      <td>21.477689</td>\n",
              "      <td>19.928085</td>\n",
              "      <td>52</td>\n",
              "      <td>124</td>\n",
              "      <td>604</td>\n",
              "      <td>8</td>\n",
              "      <td>15.464032</td>\n",
              "      <td>17.892233</td>\n",
              "      <td>19.758502</td>\n",
              "      <td>71</td>\n",
              "      <td>150</td>\n",
              "      <td>601</td>\n",
              "      <td>28</td>\n",
              "      <td>23.759127</td>\n",
              "      <td>21.954768</td>\n",
              "      <td>19.882038</td>\n",
              "      <td>46</td>\n",
              "      <td>119</td>\n",
              "      <td>556</td>\n",
              "      <td>13</td>\n",
              "      <td>15.810684</td>\n",
              "      <td>16.675311</td>\n",
              "      <td>18.431375</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2018/9/19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>50</td>\n",
              "      <td>185</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8.434679</td>\n",
              "      <td>7.476215</td>\n",
              "      <td>6.445106</td>\n",
              "      <td>27</td>\n",
              "      <td>55</td>\n",
              "      <td>226</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.975860</td>\n",
              "      <td>7.669592</td>\n",
              "      <td>7.248521</td>\n",
              "      <td>13</td>\n",
              "      <td>38</td>\n",
              "      <td>185</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4.109098</td>\n",
              "      <td>5.296992</td>\n",
              "      <td>6.100134</td>\n",
              "      <td>17</td>\n",
              "      <td>45</td>\n",
              "      <td>185</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>4.779360</td>\n",
              "      <td>5.972842</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5.964385</td>\n",
              "      <td>6.157597</td>\n",
              "      <td>5.964995</td>\n",
              "      <td>72</td>\n",
              "      <td>139</td>\n",
              "      <td>636</td>\n",
              "      <td>18</td>\n",
              "      <td>20.292048</td>\n",
              "      <td>20.161543</td>\n",
              "      <td>20.445089</td>\n",
              "      <td>42</td>\n",
              "      <td>132</td>\n",
              "      <td>565</td>\n",
              "      <td>15</td>\n",
              "      <td>16.359630</td>\n",
              "      <td>17.889969</td>\n",
              "      <td>19.005901</td>\n",
              "      <td>72</td>\n",
              "      <td>137</td>\n",
              "      <td>593</td>\n",
              "      <td>29</td>\n",
              "      <td>23.728278</td>\n",
              "      <td>21.091569</td>\n",
              "      <td>19.780084</td>\n",
              "      <td>48</td>\n",
              "      <td>138</td>\n",
              "      <td>546</td>\n",
              "      <td>16</td>\n",
              "      <td>17.620044</td>\n",
              "      <td>18.856919</td>\n",
              "      <td>18.768925</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>2018/7/2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2586</td>\n",
              "      <td>2587</td>\n",
              "      <td>2010</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>44</td>\n",
              "      <td>182</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7.400937</td>\n",
              "      <td>6.690078</td>\n",
              "      <td>6.066667</td>\n",
              "      <td>15</td>\n",
              "      <td>35</td>\n",
              "      <td>174</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.184074</td>\n",
              "      <td>4.514127</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>23</td>\n",
              "      <td>51</td>\n",
              "      <td>204</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8.473419</td>\n",
              "      <td>7.479705</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>27</td>\n",
              "      <td>64</td>\n",
              "      <td>212</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>10.231470</td>\n",
              "      <td>9.184512</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9.186192</td>\n",
              "      <td>8.067338</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>52</td>\n",
              "      <td>118</td>\n",
              "      <td>549</td>\n",
              "      <td>12</td>\n",
              "      <td>14.824654</td>\n",
              "      <td>16.416127</td>\n",
              "      <td>18.300000</td>\n",
              "      <td>61</td>\n",
              "      <td>139</td>\n",
              "      <td>599</td>\n",
              "      <td>28</td>\n",
              "      <td>23.607366</td>\n",
              "      <td>21.120673</td>\n",
              "      <td>19.966667</td>\n",
              "      <td>56</td>\n",
              "      <td>142</td>\n",
              "      <td>592</td>\n",
              "      <td>9</td>\n",
              "      <td>15.363973</td>\n",
              "      <td>18.507702</td>\n",
              "      <td>19.733333</td>\n",
              "      <td>65</td>\n",
              "      <td>147</td>\n",
              "      <td>600</td>\n",
              "      <td>29</td>\n",
              "      <td>24.204007</td>\n",
              "      <td>21.955499</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>2010/4/10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1043</td>\n",
              "      <td>1044</td>\n",
              "      <td>2015</td>\n",
              "      <td>6</td>\n",
              "      <td>22</td>\n",
              "      <td>19</td>\n",
              "      <td>57</td>\n",
              "      <td>220</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.546581</td>\n",
              "      <td>6.861211</td>\n",
              "      <td>7.317562</td>\n",
              "      <td>27</td>\n",
              "      <td>41</td>\n",
              "      <td>181</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8.740124</td>\n",
              "      <td>7.395028</td>\n",
              "      <td>6.364638</td>\n",
              "      <td>9</td>\n",
              "      <td>49</td>\n",
              "      <td>202</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4.833639</td>\n",
              "      <td>5.694890</td>\n",
              "      <td>6.533612</td>\n",
              "      <td>6</td>\n",
              "      <td>44</td>\n",
              "      <td>201</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3.116387</td>\n",
              "      <td>4.681126</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3.047670</td>\n",
              "      <td>4.721289</td>\n",
              "      <td>5.693194</td>\n",
              "      <td>81</td>\n",
              "      <td>123</td>\n",
              "      <td>561</td>\n",
              "      <td>28</td>\n",
              "      <td>25.454608</td>\n",
              "      <td>21.780819</td>\n",
              "      <td>19.375170</td>\n",
              "      <td>49</td>\n",
              "      <td>166</td>\n",
              "      <td>638</td>\n",
              "      <td>15</td>\n",
              "      <td>16.613453</td>\n",
              "      <td>19.945716</td>\n",
              "      <td>21.223273</td>\n",
              "      <td>77</td>\n",
              "      <td>124</td>\n",
              "      <td>545</td>\n",
              "      <td>29</td>\n",
              "      <td>25.564376</td>\n",
              "      <td>21.336753</td>\n",
              "      <td>18.837678</td>\n",
              "      <td>27</td>\n",
              "      <td>133</td>\n",
              "      <td>596</td>\n",
              "      <td>6</td>\n",
              "      <td>10.367563</td>\n",
              "      <td>14.936712</td>\n",
              "      <td>18.563879</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2015/6/22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 147 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   index    項番     年  月   日  ...  月星座同属性1  月星座同属性2  星座  当日の回答       星座.1\n",
              "0   1390  1391  2014  2  20  ...       12        4  12      1  2014/2/20\n",
              "1    196   197  2018  9  19  ...        2        6   6      2  2018/9/19\n",
              "2    253   254  2018  7   2  ...        2        6   4      7   2018/7/2\n",
              "3   2586  2587  2010  4  10  ...        4        8   1     11  2010/4/10\n",
              "4   1043  1044  2015  6  22  ...       10        2   4      2  2015/6/22\n",
              "\n",
              "[5 rows x 147 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoJjQUw9lbGK",
        "colab_type": "text"
      },
      "source": [
        "以下、モデル群。<br>\n",
        "ゴミファイルが多いため要注意。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9903Rn8k5T-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# qiita用\n",
        "# いろいろimport\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# LightGBM parameters\n",
        "\n",
        "params = {\n",
        "        'task': 'train',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'objective': 'multiclass',\n",
        "        'metric': {'multi_logloss'},\n",
        "        'num_class': 13,\n",
        "        'learning_rate': 0.01,\n",
        "        'num_leaves': 13,\n",
        "        'min_data_in_leaf': 5,\n",
        "        'num_iteration': 1000,\n",
        "        'verbose': 0\n",
        "}\n",
        "\n",
        "\n",
        "# 3点交差検証\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    xs_train = X.iloc[train_index]\n",
        "    y_train = Y.iloc[train_index]\n",
        "    xs_test = X.iloc[test_index]\n",
        "    y_test = Y.iloc[test_index] \n",
        "    xs_train_index = xs_train[[\"index\"]]\n",
        "    xs_train = xs_train.drop([\"index\"], axis=1)\n",
        "    lgb_train = lgb.Dataset(xs_train, y_train)\n",
        "    xs_test_index = xs_test[[\"index\"]]\n",
        "    xs_test = xs_test.drop([\"index\"], axis=1)\n",
        "    lgb_eval = lgb.Dataset(xs_test, y_test, reference=lgb_train)\n",
        "    gbm = lgb.train(params, lgb_train, num_boost_round=50, valid_sets=lgb_eval,early_stopping_rounds=20)\n",
        "    y_pred = gbm.predict(xs_test, num_iteration=gbm.best_iteration)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    \n",
        "    print(\"Accuracy\")\n",
        "    print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoQqjTgUvhah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LightGBM練習\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "# LightGBM parameters\n",
        "\n",
        "params = {\n",
        "        'task': 'train',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'objective': 'multiclass',\n",
        "        'metric': {'multi_logloss'},\n",
        "        'num_class': 13,\n",
        "        'learning_rate': 0.01,\n",
        "        'num_leaves': 13,\n",
        "        'min_data_in_leaf': 5,\n",
        "        'num_iteration': 1000,\n",
        "        'verbose': 0\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "params = {\n",
        "        'task': 'train',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'objective': 'multiclass',\n",
        "        'metric': {'multi_logloss'},\n",
        "        'num_class': 13,\n",
        "        'learning_rate': 0.01,\n",
        "        'num_leaves': 13,\n",
        "        'min_data_in_leaf': 1,\n",
        "        'num_iteration': 500,\n",
        "        'verbose': 0\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "params = {\n",
        "        'task': 'train',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'objective': 'multiclass',\n",
        "        'metric': {'multi_logloss'},\n",
        "        'num_class': 13,\n",
        "        'learning_rate': 0.1,\n",
        "        'num_leaves': 15,\n",
        "        'min_data_in_leaf': 1,\n",
        "        'num_iteration': 500,\n",
        "        'verbose': 0\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "#params = {\n",
        "#        'task': 'train',\n",
        "#        'boosting_type': 'gbdt',\n",
        "#        'objective': 'multiclass',\n",
        "#        'metric': {'multi_logloss'},\n",
        "#        'num_class': 13,\n",
        "#        'learning_rate': 0.1,\n",
        "#        'num_leaves': 23,\n",
        "#        'min_data_in_leaf': 1,\n",
        "#        'num_iteration': 100,\n",
        "#        'verbose': 0\n",
        "#}\n",
        "\n",
        "# train\n",
        "gbm = lgb.train(params, lgb_train, num_boost_round=50, valid_sets=lgb_eval,early_stopping_rounds=30)\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "df_all_pred = pd.DataFrame([[y_pred]])\n",
        "\n",
        "print(\"Accuracy\")\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "stack_xs_test = pd.DataFrame()\n",
        "stack_y_pred = []\n",
        "stack_data = pd.DataFrame()\n",
        "stack_stack_data = pd.DataFrame()\n",
        "\n",
        "#skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    xs_train = X.iloc[train_index]\n",
        "    y_train = Y.iloc[train_index]\n",
        "    xs_test = X.iloc[test_index]\n",
        "    y_test = Y.iloc[test_index] \n",
        "    xs_train_index = xs_train[[\"index\"]]\n",
        "    xs_train = xs_train.drop([\"index\"], axis=1)\n",
        "    lgb_train = lgb.Dataset(xs_train, y_train)\n",
        "    xs_test_index = xs_test[[\"index\"]]\n",
        "    xs_test = xs_test.drop([\"index\"], axis=1)\n",
        "    lgb_eval = lgb.Dataset(xs_test, y_test, reference=lgb_train)\n",
        "    gbm = lgb.train(params, lgb_train, num_boost_round=50, valid_sets=lgb_eval,early_stopping_rounds=20)\n",
        "    y_pred = gbm.predict(xs_test, num_iteration=gbm.best_iteration)\n",
        "    \n",
        "    # 後で削除\n",
        "    #print(\"タイプ\")\n",
        "    #print(type(y_pred))\n",
        "    #print(y_pred.shape)\n",
        "    \n",
        "    y_check_percent_pred = y_pred\n",
        "    \n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    y_pred_2 = y_check_percent_pred.argsort()\n",
        "    y_pred_sort = np.sort(y_check_percent_pred)\n",
        "    # 後で削除\n",
        "    #print(y_pred.shape)\n",
        "    print(\"Accuracy\")\n",
        "    print(accuracy_score(y_test, y_pred))\n",
        "    #print(xs_test)\n",
        "    #print(y_pred)\n",
        "    xs_test = xs_test.reset_index(drop=True)\n",
        "    xs_test_index = xs_test_index.reset_index(drop=True)\n",
        "    \n",
        "    \n",
        "    y_test = y_test.reset_index(drop=True)\n",
        "    \n",
        "    stack_data = pd.DataFrame()\n",
        "    y_pred_df = pd.DataFrame(y_pred)\n",
        "    df_y_pred_2 = pd.DataFrame(y_pred_2)\n",
        "    df_y_pred_sort = pd.DataFrame(y_pred_sort)\n",
        "    y_check_percent_pred_df = pd.DataFrame(y_check_percent_pred)\n",
        "    stack_data = pd.concat([xs_test, y_pred_df, y_test, y_check_percent_pred_df, df_y_pred_sort, df_y_pred_2], axis=1)\n",
        "    stack_stack_data = pd.concat([stack_stack_data, stack_data])\n",
        "    \n",
        "    #stack_xs_test = pd.concat([stack_xs_test, xs_test])\n",
        "    #stack_xs_test = stack_xs_test.reset_index(drop=True)\n",
        "    #stack_y_pred.append(y_pred)\n",
        "    #stack_y_pred.extend(y_pred)\n",
        "\n",
        "#print(stack_xs_test)\n",
        "#print(stack_y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHypHoagTCxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# テスト結果を確認するために保存\n",
        "stack_stack_data.to_csv('/content/drive/My Drive/stack_check_20190602.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTdc10W9DZvu",
        "colab_type": "code",
        "outputId": "62ce9c92-c0ec-42a1-9b1e-ab280ab5f863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3647
        }
      },
      "source": [
        "# XGboost\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# データ読み込み\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# xgboostモデルの作成\n",
        "clf = xgb.XGBClassifier()\n",
        "\n",
        "# ハイパーパラメータ探索\n",
        "#clf_cv = GridSearchCV(clf, {'max_depth': [2,4,6], 'n_estimators': [50,100,200]}, verbose=1)\n",
        "clf_cv = GridSearchCV(clf, {'max_depth': [2], 'n_estimators': [100]}, verbose=1)\n",
        "clf_cv.fit(X_train, y_train)\n",
        "print(clf_cv.best_params_, clf_cv.best_score_)\n",
        "\n",
        "# 改めて最適パラメータで学習\n",
        "clf = xgb.XGBClassifier(**clf_cv.best_params_)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 学習モデルの保存、読み込み\n",
        "# import pickle\n",
        "# pickle.dump(clf, open(\"model.pkl\", \"wb\"))\n",
        "# clf = pickle.load(open(\"model.pkl\", \"rb\"))\n",
        "\n",
        "# 学習モデルの評価\n",
        "pred = clf.predict(X_test)\n",
        "print(\"予想結果\")\n",
        "print(type(pred))\n",
        "print(pred)\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "stack_xs_test = pd.DataFrame()\n",
        "stack_y_pred = []\n",
        "stack_data = pd.DataFrame()\n",
        "stack_stack_data = pd.DataFrame()\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=False)\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    xs_train = X.iloc[train_index]\n",
        "    y_train = Y.iloc[train_index]\n",
        "    xs_test = X.iloc[test_index]\n",
        "    y_test = Y.iloc[test_index]\n",
        "    # xgboostモデルの作成\n",
        "    clf = xgb.XGBClassifier()\n",
        "    clf_cv = GridSearchCV(clf, {'max_depth': [2,4,6], 'n_estimators': [50,100,200]}, verbose=1)\n",
        "    clf_cv.fit(xs_train, y_train)\n",
        "    #print(clf_cv.best_params_, clf_cv.best_score_)\n",
        "    \n",
        "    # 改めて最適パラメータで学習\n",
        "    clf = xgb.XGBClassifier(**clf_cv.best_params_)\n",
        "    clf.fit(xs_train, y_train)\n",
        "    \n",
        "    # 学習モデルの評価\n",
        "    y_pred_proba = clf.predict_proba(xs_test)\n",
        "    y_pred = clf.predict(xs_test)\n",
        "    print(\"予想結果\")\n",
        "    print(type(y_pred))\n",
        "    print(y_pred.shape)\n",
        "    print(xs_test.shape)\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    \n",
        "    #xs_test = xs_test.reset_index(drop=True)\n",
        "    #stack_xs_test = pd.concat([stack_xs_test, xs_test])\n",
        "    #stack_xs_test = stack_xs_test.reset_index(drop=True)\n",
        "    #stack_y_pred.append(y_pred)\n",
        "    #stack_y_pred.extend(y_pred)\n",
        "\n",
        "    xs_test = xs_test.reset_index(drop=True)\n",
        "    \n",
        "    \n",
        "    y_test = y_test.reset_index(drop=True)\n",
        "    \n",
        "    stack_data = pd.DataFrame()\n",
        "    y_pred_df = pd.DataFrame(y_pred)\n",
        "    y_pred_proba_df = pd.DataFrame(y_pred_proba)\n",
        "    stack_data = pd.concat([xs_test, y_pred_df, y_test, y_pred_proba_df], axis=1)\n",
        "    stack_stack_data = pd.concat([stack_stack_data, stack_data])    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   13.8s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 2, 'n_estimators': 100} 0.21977124183006536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "予想結果\n",
            "<class 'numpy.ndarray'>\n",
            "[12  4  3 12  7  8  1  3  6  3  5 10  8  8  5  4  2  3  9  7  2  9  4  1\n",
            "  8 11  3  7  4  1  5  1  6 10  3  2  1  7  6  4 12 10  7  6  4  3  7 12\n",
            " 12 11  5 12  6  2  5  8  6  2  4  5  1  3  7  5  4  3  2  3  7  5  6 12\n",
            " 10 11  6 11  5  7  5  1 10  4  4  4 11  8  6  1  2  4  4 10  4  3  2 12\n",
            "  7  5 11  9 10 11 12  9  7  4  2  4  7  5 11  5  6  5 10  5  2 12 11  7\n",
            "  8 12  8  7  2  7  6 10 11 10  3  3  9  7  8  5  2 12  1  4  3 10  2  3\n",
            "  9  1  4  2  8  5  3 10 10 11  5  5 11  9  2  8  5  6 12  8  5  6 12  7\n",
            "  2  3  8  9  7 12  4 11  2  3  4 12  2 12  4  5  2 10 12  5  2 10  5  5\n",
            "  6 10  9  3  7  3  5 10  6 12  4  7 11  4  7  2  8 11 10  4 10  4  9  2\n",
            "  4  7 11 10  4  7  6 12 10 11  2  9  1  4  5  9  2 12  3 11  6  4  1  4\n",
            "  5  5  7  7  3  5  4  8  7  6  1  7  4  3  5  9  4 10  1  6 10  4  4  8\n",
            "  8  9 10  2  6  4 10  3  4  8  4  5  2 12 10  3  5  4  4  7  1 10 10  3\n",
            "  4  9  3  5  2  2  1  2  1  1  2  7  8 10  2  6 12  7]\n",
            "[[8 2 0 3 5 4 1 0 3 1 1 1]\n",
            " [2 6 2 2 1 4 3 0 2 5 0 0]\n",
            " [1 1 8 1 3 0 3 0 0 3 2 1]\n",
            " [1 0 0 7 1 0 3 1 2 2 0 2]\n",
            " [2 4 0 2 8 0 0 1 2 4 1 4]\n",
            " [0 3 4 1 1 4 1 0 1 2 1 1]\n",
            " [0 1 3 1 4 3 9 3 0 0 4 1]\n",
            " [0 3 2 5 3 3 2 7 1 1 2 2]\n",
            " [2 3 0 7 5 2 0 1 2 2 0 2]\n",
            " [1 7 0 2 1 1 3 0 1 7 1 1]\n",
            " [0 0 7 2 0 0 4 0 0 2 4 1]\n",
            " [1 1 1 8 2 0 1 6 1 0 2 7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.44      0.28      0.34        29\n",
            "           2       0.19      0.22      0.21        27\n",
            "           3       0.30      0.35      0.32        23\n",
            "           4       0.17      0.37      0.23        19\n",
            "           5       0.24      0.29      0.26        28\n",
            "           6       0.19      0.21      0.20        19\n",
            "           7       0.30      0.31      0.31        29\n",
            "           8       0.37      0.23      0.28        31\n",
            "           9       0.13      0.08      0.10        26\n",
            "          10       0.24      0.28      0.26        25\n",
            "          11       0.22      0.20      0.21        20\n",
            "          12       0.30      0.23      0.26        30\n",
            "\n",
            "    accuracy                           0.25       306\n",
            "   macro avg       0.26      0.25      0.25       306\n",
            "weighted avg       0.27      0.25      0.25       306\n",
            "\n",
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-8b448a07f84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mclf_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mclf_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;31m#print(clf_cv.best_params_, clf_cv.best_score_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "089af5d7-3948-4618-9761-906aa1e1cd65",
        "id": "9YDKWUtYhnuq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "y_pred_proba_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.033391</td>\n",
              "      <td>0.055183</td>\n",
              "      <td>0.055550</td>\n",
              "      <td>0.150161</td>\n",
              "      <td>0.105097</td>\n",
              "      <td>0.033167</td>\n",
              "      <td>0.068222</td>\n",
              "      <td>0.088152</td>\n",
              "      <td>0.022384</td>\n",
              "      <td>0.033929</td>\n",
              "      <td>0.021579</td>\n",
              "      <td>0.333184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060634</td>\n",
              "      <td>0.074967</td>\n",
              "      <td>0.087299</td>\n",
              "      <td>0.142323</td>\n",
              "      <td>0.013852</td>\n",
              "      <td>0.223304</td>\n",
              "      <td>0.011504</td>\n",
              "      <td>0.181766</td>\n",
              "      <td>0.014707</td>\n",
              "      <td>0.017362</td>\n",
              "      <td>0.063947</td>\n",
              "      <td>0.108334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.038104</td>\n",
              "      <td>0.013043</td>\n",
              "      <td>0.114951</td>\n",
              "      <td>0.235025</td>\n",
              "      <td>0.035107</td>\n",
              "      <td>0.008778</td>\n",
              "      <td>0.307472</td>\n",
              "      <td>0.042150</td>\n",
              "      <td>0.039092</td>\n",
              "      <td>0.029064</td>\n",
              "      <td>0.022452</td>\n",
              "      <td>0.114763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.045533</td>\n",
              "      <td>0.033328</td>\n",
              "      <td>0.288679</td>\n",
              "      <td>0.186005</td>\n",
              "      <td>0.039047</td>\n",
              "      <td>0.018427</td>\n",
              "      <td>0.118462</td>\n",
              "      <td>0.082890</td>\n",
              "      <td>0.038391</td>\n",
              "      <td>0.014362</td>\n",
              "      <td>0.092916</td>\n",
              "      <td>0.041958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.067056</td>\n",
              "      <td>0.039381</td>\n",
              "      <td>0.095361</td>\n",
              "      <td>0.242932</td>\n",
              "      <td>0.069257</td>\n",
              "      <td>0.049522</td>\n",
              "      <td>0.033299</td>\n",
              "      <td>0.161045</td>\n",
              "      <td>0.026759</td>\n",
              "      <td>0.093319</td>\n",
              "      <td>0.088903</td>\n",
              "      <td>0.033166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.033391  0.055183  0.055550  0.150161  0.105097  0.033167  0.068222   \n",
              "1  0.060634  0.074967  0.087299  0.142323  0.013852  0.223304  0.011504   \n",
              "2  0.038104  0.013043  0.114951  0.235025  0.035107  0.008778  0.307472   \n",
              "3  0.045533  0.033328  0.288679  0.186005  0.039047  0.018427  0.118462   \n",
              "4  0.067056  0.039381  0.095361  0.242932  0.069257  0.049522  0.033299   \n",
              "\n",
              "         7         8         9         10        11  \n",
              "0  0.088152  0.022384  0.033929  0.021579  0.333184  \n",
              "1  0.181766  0.014707  0.017362  0.063947  0.108334  \n",
              "2  0.042150  0.039092  0.029064  0.022452  0.114763  \n",
              "3  0.082890  0.038391  0.014362  0.092916  0.041958  \n",
              "4  0.161045  0.026759  0.093319  0.088903  0.033166  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c66a5916-889b-4d4f-eb0a-770601a6fbdb",
        "id": "eXNchb-ehnIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xgbst_percent.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2156, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9m0pYMOFqsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgbst_percent = stack_stack_data[[0,1,2,3,4,5,6,7,8,9,10,11]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rHIIQkhI0xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col = xgbst_percent.columns.values\n",
        "col[0] = 'del'\n",
        "xgbst_percent.columns = col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-uwNQfnJQQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgbst_percent = xgbst_percent.rename(columns={0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXvA-RfwJ58A",
        "colab_type": "code",
        "outputId": "e60bbd0f-add8-4006-8b84-fe7f9c114b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "xgbst_percent = xgbst_percent[[1,2,3,4,5,6,7,8,9,10,11,12]]\n",
        "xgbst_percent.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>0.211037</td>\n",
              "      <td>0.017548</td>\n",
              "      <td>0.042827</td>\n",
              "      <td>0.014119</td>\n",
              "      <td>0.132561</td>\n",
              "      <td>0.057475</td>\n",
              "      <td>0.074499</td>\n",
              "      <td>0.048253</td>\n",
              "      <td>0.083166</td>\n",
              "      <td>0.072817</td>\n",
              "      <td>0.131806</td>\n",
              "      <td>0.113893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>0.055364</td>\n",
              "      <td>0.103556</td>\n",
              "      <td>0.070126</td>\n",
              "      <td>0.060862</td>\n",
              "      <td>0.036146</td>\n",
              "      <td>0.098850</td>\n",
              "      <td>0.228095</td>\n",
              "      <td>0.051064</td>\n",
              "      <td>0.070446</td>\n",
              "      <td>0.052477</td>\n",
              "      <td>0.119152</td>\n",
              "      <td>0.053862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>0.034408</td>\n",
              "      <td>0.026480</td>\n",
              "      <td>0.110288</td>\n",
              "      <td>0.069939</td>\n",
              "      <td>0.047247</td>\n",
              "      <td>0.037155</td>\n",
              "      <td>0.128801</td>\n",
              "      <td>0.045240</td>\n",
              "      <td>0.025541</td>\n",
              "      <td>0.145897</td>\n",
              "      <td>0.177911</td>\n",
              "      <td>0.151093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>0.038820</td>\n",
              "      <td>0.035232</td>\n",
              "      <td>0.205343</td>\n",
              "      <td>0.026129</td>\n",
              "      <td>0.132862</td>\n",
              "      <td>0.059738</td>\n",
              "      <td>0.092921</td>\n",
              "      <td>0.057088</td>\n",
              "      <td>0.054189</td>\n",
              "      <td>0.023945</td>\n",
              "      <td>0.194667</td>\n",
              "      <td>0.079065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>0.029858</td>\n",
              "      <td>0.009548</td>\n",
              "      <td>0.142499</td>\n",
              "      <td>0.021367</td>\n",
              "      <td>0.046420</td>\n",
              "      <td>0.034972</td>\n",
              "      <td>0.075246</td>\n",
              "      <td>0.040792</td>\n",
              "      <td>0.069213</td>\n",
              "      <td>0.033798</td>\n",
              "      <td>0.420183</td>\n",
              "      <td>0.076104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           1         2         3         4         5         6         7   \\\n",
              "710  0.211037  0.017548  0.042827  0.014119  0.132561  0.057475  0.074499   \n",
              "711  0.055364  0.103556  0.070126  0.060862  0.036146  0.098850  0.228095   \n",
              "712  0.034408  0.026480  0.110288  0.069939  0.047247  0.037155  0.128801   \n",
              "713  0.038820  0.035232  0.205343  0.026129  0.132862  0.059738  0.092921   \n",
              "714  0.029858  0.009548  0.142499  0.021367  0.046420  0.034972  0.075246   \n",
              "\n",
              "           8         9         10        11        12  \n",
              "710  0.048253  0.083166  0.072817  0.131806  0.113893  \n",
              "711  0.051064  0.070446  0.052477  0.119152  0.053862  \n",
              "712  0.045240  0.025541  0.145897  0.177911  0.151093  \n",
              "713  0.057088  0.054189  0.023945  0.194667  0.079065  \n",
              "714  0.040792  0.069213  0.033798  0.420183  0.076104  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfzhfMuoGUTD",
        "colab_type": "code",
        "outputId": "7c6e197f-fc19-4725-a3ee-c5727286ee16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "test_plus_x_l = lightgbm_percent + xgbst_percent\n",
        "test_plus_x_l.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.097853</td>\n",
              "      <td>0.066092</td>\n",
              "      <td>0.138842</td>\n",
              "      <td>0.156172</td>\n",
              "      <td>0.083457</td>\n",
              "      <td>0.082247</td>\n",
              "      <td>0.086272</td>\n",
              "      <td>0.129224</td>\n",
              "      <td>0.503632</td>\n",
              "      <td>0.034891</td>\n",
              "      <td>0.325571</td>\n",
              "      <td>0.295746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.080466</td>\n",
              "      <td>0.204825</td>\n",
              "      <td>0.060055</td>\n",
              "      <td>0.100739</td>\n",
              "      <td>0.161471</td>\n",
              "      <td>0.083707</td>\n",
              "      <td>0.586205</td>\n",
              "      <td>0.064745</td>\n",
              "      <td>0.219048</td>\n",
              "      <td>0.091505</td>\n",
              "      <td>0.198800</td>\n",
              "      <td>0.148435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.105129</td>\n",
              "      <td>0.363339</td>\n",
              "      <td>0.048725</td>\n",
              "      <td>0.071730</td>\n",
              "      <td>0.340580</td>\n",
              "      <td>0.257149</td>\n",
              "      <td>0.087440</td>\n",
              "      <td>0.036761</td>\n",
              "      <td>0.287803</td>\n",
              "      <td>0.141805</td>\n",
              "      <td>0.046601</td>\n",
              "      <td>0.212939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.129122</td>\n",
              "      <td>0.106725</td>\n",
              "      <td>0.459729</td>\n",
              "      <td>0.073493</td>\n",
              "      <td>0.144143</td>\n",
              "      <td>0.200931</td>\n",
              "      <td>0.316742</td>\n",
              "      <td>0.068629</td>\n",
              "      <td>0.095874</td>\n",
              "      <td>0.099114</td>\n",
              "      <td>0.111410</td>\n",
              "      <td>0.194089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.178457</td>\n",
              "      <td>0.443559</td>\n",
              "      <td>0.096679</td>\n",
              "      <td>0.081863</td>\n",
              "      <td>0.057782</td>\n",
              "      <td>0.185187</td>\n",
              "      <td>0.087276</td>\n",
              "      <td>0.055788</td>\n",
              "      <td>0.097320</td>\n",
              "      <td>0.509387</td>\n",
              "      <td>0.092849</td>\n",
              "      <td>0.113854</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         1         2         3         4         5         6         7   \\\n",
              "0  0.097853  0.066092  0.138842  0.156172  0.083457  0.082247  0.086272   \n",
              "1  0.080466  0.204825  0.060055  0.100739  0.161471  0.083707  0.586205   \n",
              "2  0.105129  0.363339  0.048725  0.071730  0.340580  0.257149  0.087440   \n",
              "3  0.129122  0.106725  0.459729  0.073493  0.144143  0.200931  0.316742   \n",
              "4  0.178457  0.443559  0.096679  0.081863  0.057782  0.185187  0.087276   \n",
              "\n",
              "         8         9         10        11        12  \n",
              "0  0.129224  0.503632  0.034891  0.325571  0.295746  \n",
              "1  0.064745  0.219048  0.091505  0.198800  0.148435  \n",
              "2  0.036761  0.287803  0.141805  0.046601  0.212939  \n",
              "3  0.068629  0.095874  0.099114  0.111410  0.194089  \n",
              "4  0.055788  0.097320  0.509387  0.092849  0.113854  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP7gO3PqLh2p",
        "colab_type": "code",
        "outputId": "17908cfe-f948-485a-f3ab-51006edb27cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_plus_x_l_argmax = test_plus_x_l.idxmax(axis=1)\n",
        "test_plus_x_l_argmax_df = pd.DataFrame(test_plus_x_l_argmax)\n",
        "test_plus_x_l_argmax_df = test_plus_x_l_argmax_df.reset_index(drop=True)\n",
        "test_plus_x_l_argmax_df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2154</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2155</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "2151   1\n",
              "2152   7\n",
              "2153  12\n",
              "2154   3\n",
              "2155  11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWNXQ0HJO7sZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_stack_data.to_csv('/content/drive/My Drive/stack_check_uranai.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xssv3NhbPAJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_plus_x_l_argmax_df.to_csv('/content/drive/My Drive/stack_check_uranai_pred.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYWcWD8pNWBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_stack_data_test = pd.concat([stack_stack_data, test_plus_x_l_argmax_df], ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI7FMYv4F-YN",
        "colab_type": "code",
        "outputId": "2a152dbf-511d-44f4-b2f4-e68613f11faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "xgbst_percent.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>0.052760</td>\n",
              "      <td>0.033228</td>\n",
              "      <td>0.072422</td>\n",
              "      <td>0.085417</td>\n",
              "      <td>0.049468</td>\n",
              "      <td>0.053067</td>\n",
              "      <td>0.029015</td>\n",
              "      <td>0.057502</td>\n",
              "      <td>0.221288</td>\n",
              "      <td>0.016127</td>\n",
              "      <td>0.189635</td>\n",
              "      <td>0.140072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>0.034465</td>\n",
              "      <td>0.105637</td>\n",
              "      <td>0.023803</td>\n",
              "      <td>0.050645</td>\n",
              "      <td>0.106191</td>\n",
              "      <td>0.038049</td>\n",
              "      <td>0.271761</td>\n",
              "      <td>0.028030</td>\n",
              "      <td>0.126835</td>\n",
              "      <td>0.059405</td>\n",
              "      <td>0.082335</td>\n",
              "      <td>0.072842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.060641</td>\n",
              "      <td>0.193434</td>\n",
              "      <td>0.025325</td>\n",
              "      <td>0.030240</td>\n",
              "      <td>0.150351</td>\n",
              "      <td>0.115321</td>\n",
              "      <td>0.032838</td>\n",
              "      <td>0.015088</td>\n",
              "      <td>0.177088</td>\n",
              "      <td>0.096214</td>\n",
              "      <td>0.025783</td>\n",
              "      <td>0.077677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.066171</td>\n",
              "      <td>0.061077</td>\n",
              "      <td>0.267253</td>\n",
              "      <td>0.035850</td>\n",
              "      <td>0.069806</td>\n",
              "      <td>0.114834</td>\n",
              "      <td>0.130998</td>\n",
              "      <td>0.038079</td>\n",
              "      <td>0.038771</td>\n",
              "      <td>0.051311</td>\n",
              "      <td>0.052773</td>\n",
              "      <td>0.073076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.095654</td>\n",
              "      <td>0.232483</td>\n",
              "      <td>0.045376</td>\n",
              "      <td>0.042629</td>\n",
              "      <td>0.027456</td>\n",
              "      <td>0.119995</td>\n",
              "      <td>0.032855</td>\n",
              "      <td>0.027368</td>\n",
              "      <td>0.054110</td>\n",
              "      <td>0.214325</td>\n",
              "      <td>0.041363</td>\n",
              "      <td>0.066386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0         0         1         2         3         4         5         6   \\\n",
              "0   9  0.052760  0.033228  0.072422  0.085417  0.049468  0.053067  0.029015   \n",
              "1   7  0.034465  0.105637  0.023803  0.050645  0.106191  0.038049  0.271761   \n",
              "2   2  0.060641  0.193434  0.025325  0.030240  0.150351  0.115321  0.032838   \n",
              "3   3  0.066171  0.061077  0.267253  0.035850  0.069806  0.114834  0.130998   \n",
              "4   2  0.095654  0.232483  0.045376  0.042629  0.027456  0.119995  0.032855   \n",
              "\n",
              "         7         8         9         10        11  \n",
              "0  0.057502  0.221288  0.016127  0.189635  0.140072  \n",
              "1  0.028030  0.126835  0.059405  0.082335  0.072842  \n",
              "2  0.015088  0.177088  0.096214  0.025783  0.077677  \n",
              "3  0.038079  0.038771  0.051311  0.052773  0.073076  \n",
              "4  0.027368  0.054110  0.214325  0.041363  0.066386  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8kmf5mIqVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# スタックしたやつをXとYに分離\n",
        "\n",
        "X = stack_stack_data.drop(\"当日の回答\", axis=1)\n",
        "Y = stack_stack_data[[\"当日の回答\"]]\n",
        "X.head()\n",
        "#Y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVVMSIS1Wprj",
        "colab_type": "code",
        "outputId": "ffcb5e2e-99d3-4420-d3fd-2805eab0698f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# テスト用に使ったデータ\n",
        "#使わない\n",
        "# 予想した結果(stack_y_pred)をDataFrame(stack_y_pred_df)として変換\n",
        "stack_y_pred_df = pd.DataFrame(stack_y_pred)\n",
        "#stack_y_pred_df = pd.DataFrame(y_pred)\n",
        "#stack_y_pred_df.head()\n",
        "\n",
        "# DataFrame(stack_xs_test,stack_y_pred_df)を結合する。\n",
        "stack_check = pd.DataFrame()\n",
        "stack_check = pd.concat([stack_xs_test, stack_y_pred_df], axis=1)\n",
        "#stack_check = pd.concat([xs_test, stack_y_pred_df], axis=1)\n",
        "stack_check = pd.concat([stack_check, Y], axis=1)\n",
        "\n",
        "print(stack_check.shape)\n",
        "\n",
        "#stack_check.head()\n",
        "#stack_check.to_csv('/content/drive/My Drive/stack_check.csv')\n",
        "#!ls -ltr '/content/drive/My Drive/'\n",
        "\n",
        "# スタックしたやつをXとYに分離\n",
        "\n",
        "X = stack_check.drop(\"当日の回答\", axis=1)\n",
        "Y = stack_check[[\"当日の回答\"]]\n",
        "#X.head()\n",
        "#Y.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2156, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqR_ty0WxiEu",
        "colab_type": "code",
        "outputId": "ef65309b-c2f2-4ac4-960e-238085ce657a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stack_stack_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2156, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kvIVRoJGhjw",
        "colab_type": "code",
        "outputId": "701ce024-ddcd-4992-922f-99b22d479c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1674
        }
      },
      "source": [
        "# Stacking test to duration from here to \"# changed\"\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "stack_xs_test = pd.DataFrame()\n",
        "stack_y_pred = []\n",
        "stack_data = pd.DataFrame()\n",
        "stack_stack_data = pd.DataFrame()\n",
        "\n",
        "# 3分割交差検証を指定し、インスタンス化\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "# skf.split(X_train.Ytrain)で、X_trainとY_trainを3分割し、交差検証をする\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "  xs_train = X.iloc[train_index]\n",
        "  xs_test = X.iloc[test_index]\n",
        "  y_train = Y.iloc[train_index]\n",
        "  y_test = Y.iloc[test_index]\n",
        "  forest = RandomForestClassifier(random_state=1)\n",
        "  forest.fit(xs_train, y_train) # 学習\n",
        "  y_pred = forest.predict(xs_test) # 予測\n",
        "  #importances = model.feature_importances_\n",
        "  # acuuracyを表示\n",
        "  print(round(accuracy_score(y_test,forest.predict(xs_test))*100,2))\n",
        "  print(forest.feature_importances_)\n",
        "  \n",
        "  xs_test = xs_test.reset_index(drop=True)\n",
        "  stack_xs_test = pd.concat([stack_xs_test, xs_test])\n",
        "  stack_xs_test = stack_xs_test.reset_index(drop=True)\n",
        "  #stack_y_pred.append(y_pred)\n",
        "  stack_y_pred.extend(y_pred)\n",
        "  \n",
        "  xs_test = xs_test.reset_index(drop=True)\n",
        "  \n",
        "  y_test = y_test.reset_index(drop=True)\n",
        "  stack_data = pd.DataFrame()\n",
        "  y_pred_df = pd.DataFrame(y_pred)\n",
        "  stack_data = pd.concat([xs_test, y_pred_df, y_test], axis=1)\n",
        "  stack_stack_data = pd.concat([stack_stack_data, stack_data])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13.98\n",
            "[0.00734106 0.00802568 0.004309   0.00513819 0.00877677 0.00276205\n",
            " 0.00393306 0.00267348 0.00595035 0.00665567 0.00871994 0.00801827\n",
            " 0.00530777 0.00978869 0.00126887 0.00914884 0.01000348 0.01007309\n",
            " 0.00161114 0.003576   0.0047712  0.00481784 0.0051574  0.00641782\n",
            " 0.0073755  0.00728616 0.00869283 0.00126631 0.0115595  0.00872323\n",
            " 0.00772617 0.00385216 0.00135694 0.00320663 0.00302644 0.00399928\n",
            " 0.00912162 0.01150637 0.00403942 0.00549186 0.00207872 0.00505236\n",
            " 0.00992137 0.00990803 0.00107014 0.00407785 0.00276648 0.00475622\n",
            " 0.01003705 0.01007236 0.00791946 0.00784072 0.00734229 0.00344706\n",
            " 0.00843747 0.00999147 0.0101512  0.00364115 0.00197291 0.00235218\n",
            " 0.00614682 0.0082943  0.0068028  0.00708682 0.0094298  0.00508451\n",
            " 0.00186183 0.01006634 0.00622871 0.00931562 0.00374245 0.00251367\n",
            " 0.00528984 0.00336119 0.00831239 0.00961903 0.00626099 0.00568891\n",
            " 0.0089421  0.00150767 0.0072205  0.00690121 0.00685515 0.00313899\n",
            " 0.00174722 0.00468104 0.00448059 0.00658027 0.00757331 0.0071093\n",
            " 0.00722709 0.00540422 0.00113153 0.01086853 0.01156403 0.00567142\n",
            " 0.00148789 0.00148376 0.00350001 0.00242518 0.00813158 0.01073406\n",
            " 0.00694636 0.00435827 0.00469386 0.00139786 0.00804611 0.01189947\n",
            " 0.00767562 0.00356786 0.00238351 0.0027099  0.00538274 0.01186151\n",
            " 0.00962799 0.00849676 0.0066631  0.00728546 0.00287769 0.00668111\n",
            " 0.01057244 0.00804273 0.0032312  0.00129893 0.00378049 0.00434192\n",
            " 0.00588227 0.00955222 0.00887385 0.00986109 0.00559981 0.0014351\n",
            " 0.00721892 0.00993385 0.0112445  0.0035029  0.0032444  0.00380666\n",
            " 0.006688   0.00592823 0.00641895 0.0032128  0.008101   0.00573814\n",
            " 0.00215883 0.0079198  0.01071789 0.01108629 0.00072649 0.00241025\n",
            " 0.00440214 0.00477066 0.00751074 0.00886304 0.0074791  0.00697203\n",
            " 0.00533374 0.00349571 0.01068304 0.01104161 0.01108257 0.00649528]\n",
            "14.15\n",
            "[0.01082944 0.00819302 0.0022975  0.00634605 0.01055758 0.00388571\n",
            " 0.00268287 0.00431184 0.0034609  0.00812296 0.01048682 0.00555033\n",
            " 0.00894141 0.00451117 0.00272315 0.01085827 0.01678379 0.00689633\n",
            " 0.00120342 0.00166996 0.00316877 0.00637971 0.00531156 0.00728884\n",
            " 0.00869337 0.00574885 0.00964409 0.00077515 0.01196995 0.0141431\n",
            " 0.00784112 0.00133154 0.00380838 0.00446745 0.00518476 0.01165641\n",
            " 0.00910514 0.01154188 0.0076529  0.00580244 0.00160541 0.00856713\n",
            " 0.00819134 0.0074317  0.00253611 0.00111621 0.0020351  0.00735442\n",
            " 0.00816719 0.0048882  0.01204915 0.00485    0.00543985 0.00184028\n",
            " 0.00737223 0.01050356 0.01056405 0.0020688  0.00171239 0.00291669\n",
            " 0.00551455 0.00503084 0.00838669 0.00735329 0.00763534 0.00382854\n",
            " 0.00117801 0.00886312 0.00808779 0.0099805  0.00191693 0.00257462\n",
            " 0.00370672 0.00602612 0.00879367 0.00799768 0.00585064 0.00641762\n",
            " 0.00529022 0.00216771 0.00877853 0.00703482 0.01072636 0.00908659\n",
            " 0.00357418 0.00494111 0.00612558 0.00822569 0.00684126 0.00572616\n",
            " 0.00456037 0.00517381 0.00183123 0.00930238 0.0090266  0.00869871\n",
            " 0.0017311  0.00426552 0.00442431 0.00334112 0.00697165 0.00566814\n",
            " 0.00903637 0.00574542 0.00467291 0.00347384 0.00964099 0.00828008\n",
            " 0.00994832 0.00368181 0.00249013 0.00251967 0.00468246 0.00608943\n",
            " 0.00711607 0.00906219 0.00511752 0.00563693 0.00126363 0.00777343\n",
            " 0.00432903 0.01167385 0.0025877  0.00202385 0.0022547  0.00637723\n",
            " 0.00987572 0.00834308 0.00981975 0.00882333 0.00771002 0.00237283\n",
            " 0.00769754 0.00923431 0.00798031 0.00399551 0.00150308 0.00178756\n",
            " 0.00574201 0.00573362 0.00755109 0.00872903 0.00335026 0.00742178\n",
            " 0.00323079 0.00749913 0.01198052 0.00795569 0.00204784 0.00160247\n",
            " 0.00458181 0.00322004 0.00735609 0.00724698 0.00742922 0.0039129\n",
            " 0.00791732 0.00375927 0.00649372 0.00768115 0.00922083 0.00802229]\n",
            "12.45\n",
            "[0.005418   0.00596649 0.00415978 0.0055545  0.01073935 0.00327113\n",
            " 0.00270242 0.00573755 0.00482571 0.00853468 0.007863   0.00754248\n",
            " 0.00736463 0.00654312 0.00093455 0.01032101 0.00692965 0.01041114\n",
            " 0.00185435 0.00194654 0.00270042 0.00472513 0.00749036 0.00676645\n",
            " 0.00778069 0.00746052 0.00681318 0.0024764  0.00722253 0.01126812\n",
            " 0.00879048 0.00196466 0.00145872 0.00414503 0.00574718 0.0088769\n",
            " 0.00562219 0.01104458 0.00463797 0.00540152 0.00235436 0.00874399\n",
            " 0.01242907 0.00894621 0.00326778 0.00112956 0.00453438 0.00585486\n",
            " 0.00828069 0.00577109 0.006014   0.00724075 0.00446824 0.0022817\n",
            " 0.00666361 0.00787881 0.00717995 0.00217017 0.00224822 0.00405675\n",
            " 0.00228486 0.00582053 0.00719766 0.00833071 0.00823446 0.00629332\n",
            " 0.00239989 0.00971901 0.00833492 0.00955465 0.00242634 0.0033777\n",
            " 0.00468468 0.00412473 0.00998179 0.00962506 0.00663275 0.01359311\n",
            " 0.0053513  0.00152142 0.00815893 0.0081215  0.00662576 0.00327617\n",
            " 0.00313405 0.00300517 0.00639929 0.01090282 0.00635216 0.00829249\n",
            " 0.00894583 0.00678105 0.00334694 0.01122098 0.00989749 0.00872217\n",
            " 0.00263991 0.00482373 0.00411147 0.00642777 0.00633438 0.00472459\n",
            " 0.00832055 0.00783194 0.00557884 0.00151559 0.00721626 0.0121458\n",
            " 0.00689766 0.00120386 0.00277158 0.00214228 0.00384234 0.00962821\n",
            " 0.00729257 0.00805679 0.005542   0.00491667 0.00339694 0.01191245\n",
            " 0.00840791 0.01234551 0.00388556 0.00217525 0.00413837 0.00283856\n",
            " 0.00766032 0.00855122 0.01166009 0.00647749 0.00795278 0.00236247\n",
            " 0.01015058 0.01000472 0.0091899  0.00367509 0.00131577 0.00306888\n",
            " 0.00325242 0.00792747 0.00604762 0.00959124 0.00788733 0.00655339\n",
            " 0.0020929  0.00890005 0.00898129 0.00846981 0.00290491 0.00120366\n",
            " 0.00385025 0.00521532 0.00677773 0.00709093 0.00787162 0.00450863\n",
            " 0.00408884 0.00135866 0.00961983 0.01118455 0.00787669 0.00641121]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWNWs-82bmxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 予想した結果(stack_y_pred)をDataFrame(stack_y_pred_df)として変換\n",
        "stack_y_pred_df = pd.DataFrame(stack_y_pred)\n",
        "#stack_y_pred_df = pd.DataFrame(y_pred)\n",
        "#stack_y_pred_df.head()\n",
        "\n",
        "# DataFrame(stack_xs_test,stack_y_pred_df)を結合する。\n",
        "stack_check = pd.DataFrame()\n",
        "stack_check = pd.concat([stack_xs_test, stack_y_pred_df], axis=1)\n",
        "#stack_check = pd.concat([xs_test, stack_y_pred_df], axis=1)\n",
        "stack_check = pd.concat([stack_check, Y], axis=1)\n",
        "\n",
        "#stack_check.head()\n",
        "#stack_check.to_csv('/content/drive/My Drive/stack_check.csv')\n",
        "#!ls -ltr '/content/drive/My Drive/'\n",
        "\n",
        "# スタックしたやつをXとYに分離\n",
        "\n",
        "X = stack_check.drop(\"当日の回答\", axis=1)\n",
        "Y = stack_check[[\"当日の回答\"]]\n",
        "#X.head()\n",
        "#Y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMt1qZCc3Kvn",
        "colab_type": "code",
        "outputId": "f01ad8ac-fe76-4aef-dd76-0fed2f1ef410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stack_stack_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2156, 129)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpcQ_UcQKVhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# スタックしたやつをXとYに分離\n",
        "\n",
        "X = stack_stack_data.drop(\"当日の回答\", axis=1)\n",
        "Y = stack_stack_data[[\"当日の回答\"]]\n",
        "#X.head()\n",
        "#Y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKQiiw21OZE-",
        "colab_type": "code",
        "outputId": "3d9a1bd2-a140-48e2-f0fe-b3e0b9ec0f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1724, 125)\n",
            "(2156, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtt06o7GZ_UT",
        "colab_type": "code",
        "outputId": "1465f060-1e99-43db-ce68-917f02c84924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#訓練用サイズを指定する場合(80%)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,train_size=0.8)\n",
        "print(\"訓練用データの個数\")\n",
        "print(X_train.shape)\n",
        "print(\"試験用データの個数\")\n",
        "print(X_test.shape)\n",
        "#print(\"訓練用データの中身\")\n",
        "#print(X_train)\n",
        "#X_train.head()\n",
        "#print(Y_train)\n",
        "#Y_train.head()\n",
        "#print(\"試験用データの中身\")\n",
        "#print(X_test)\n",
        "#X_test.head()\n",
        "#print(Y_test)\n",
        "#Y_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練用データの個数\n",
            "(1224, 162)\n",
            "試験用データの個数\n",
            "(306, 162)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEjZO0c1SNf9",
        "colab_type": "code",
        "outputId": "5919debc-83e6-448a-9130-07836fac74e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7414
        }
      },
      "source": [
        "# data4用\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "model = preprocessing.StandardScaler()\n",
        "X = model.fit_transform(X_train)\n",
        "X_test = model.fit_transform(X_test)\n",
        "\n",
        "#X = np.array(X_train)\n",
        "# Yは0と1からなるリスト\n",
        "Y = to_categorical(Y_train)\n",
        "\n",
        "# モデル\n",
        "model = Sequential()\n",
        "# 全結合層(18を500に)\n",
        "model.add(Dense(input_dim=162, output_dim=1620))\n",
        "#model.add(Dense(input_dim=28, output_dim=500))\n",
        "# 活性化関数(ReLu関数) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(input_dim=1620, output_dim=1620))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(input_dim=1620, output_dim=1620))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(input_dim=1620, output_dim=1620))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(input_dim=1620, output_dim=1620))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.2))\n",
        "# 全結合層(500を2に) \n",
        "model.add(Dense(output_dim=13))\n",
        "\n",
        "model.add(Dense(10, input_dim=13,\n",
        "#model.add(Dense(10, input_dim=20,\n",
        "                kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "# 全結合層(500を2に) \n",
        "model.add(Dense(output_dim=13))\n",
        "#model.add(Dropout(0.3))\n",
        "# 活性化関数(ReLu関数) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "#model.add(Dropout(0.2))\n",
        "# softmax関数\n",
        "model.add(Activation(\"softmax\"))\n",
        "# コンパイル\n",
        "#optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.5, beta_2=0.5, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "# 実行\n",
        "model.fit(X, Y, nb_epoch=300, batch_size=10,validation_split=0.2)\n",
        "\n",
        "# 予測\n",
        "results = model.predict_proba(np.array(X_test))\n",
        "# 結果\n",
        "print(\"Predict:\\n\", results)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=162, units=1620)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1620, units=1620)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1620, units=1620)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1620, units=1620)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1620, units=1620)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=13)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=13)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 979 samples, validate on 245 samples\n",
            "Epoch 1/300\n",
            "979/979 [==============================] - 22s 22ms/step - loss: 4.6591 - acc: 0.0817 - val_loss: 2.8506 - val_acc: 0.0612\n",
            "Epoch 2/300\n",
            "979/979 [==============================] - 18s 19ms/step - loss: 4.4114 - acc: 0.0838 - val_loss: 2.8323 - val_acc: 0.1265\n",
            "Epoch 3/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 4.2854 - acc: 0.0878 - val_loss: 2.8177 - val_acc: 0.0776\n",
            "Epoch 4/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 4.1136 - acc: 0.0960 - val_loss: 2.7697 - val_acc: 0.0939\n",
            "Epoch 5/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.9386 - acc: 0.0981 - val_loss: 2.7681 - val_acc: 0.0939\n",
            "Epoch 6/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.8064 - acc: 0.0991 - val_loss: 2.7504 - val_acc: 0.0980\n",
            "Epoch 7/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.7413 - acc: 0.1001 - val_loss: 2.7206 - val_acc: 0.0776\n",
            "Epoch 8/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.6534 - acc: 0.0991 - val_loss: 2.7174 - val_acc: 0.1020\n",
            "Epoch 9/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.5945 - acc: 0.0868 - val_loss: 2.7024 - val_acc: 0.0980\n",
            "Epoch 10/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.4996 - acc: 0.1011 - val_loss: 2.7062 - val_acc: 0.0735\n",
            "Epoch 11/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.4410 - acc: 0.1052 - val_loss: 2.6911 - val_acc: 0.0980\n",
            "Epoch 12/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.3706 - acc: 0.0950 - val_loss: 2.6796 - val_acc: 0.0939\n",
            "Epoch 13/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.3143 - acc: 0.1267 - val_loss: 2.6795 - val_acc: 0.0939\n",
            "Epoch 14/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.2365 - acc: 0.1307 - val_loss: 2.6851 - val_acc: 0.1143\n",
            "Epoch 15/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.2312 - acc: 0.1226 - val_loss: 2.6528 - val_acc: 0.1224\n",
            "Epoch 16/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.1747 - acc: 0.1113 - val_loss: 2.6513 - val_acc: 0.1306\n",
            "Epoch 17/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.1074 - acc: 0.1532 - val_loss: 2.6520 - val_acc: 0.1347\n",
            "Epoch 18/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.1035 - acc: 0.1195 - val_loss: 2.6298 - val_acc: 0.1388\n",
            "Epoch 19/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.0460 - acc: 0.1430 - val_loss: 2.6276 - val_acc: 0.1714\n",
            "Epoch 20/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 3.0633 - acc: 0.1216 - val_loss: 2.6241 - val_acc: 0.1592\n",
            "Epoch 21/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.9867 - acc: 0.1389 - val_loss: 2.5868 - val_acc: 0.1755\n",
            "Epoch 22/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.9547 - acc: 0.1553 - val_loss: 2.6036 - val_acc: 0.1551\n",
            "Epoch 23/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.8883 - acc: 0.1675 - val_loss: 2.5960 - val_acc: 0.1755\n",
            "Epoch 24/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.8576 - acc: 0.1645 - val_loss: 2.6165 - val_acc: 0.1714\n",
            "Epoch 25/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.8907 - acc: 0.1634 - val_loss: 2.5958 - val_acc: 0.1388\n",
            "Epoch 26/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.8417 - acc: 0.1665 - val_loss: 2.5963 - val_acc: 0.1673\n",
            "Epoch 27/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.8155 - acc: 0.1726 - val_loss: 2.5844 - val_acc: 0.1796\n",
            "Epoch 28/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.7782 - acc: 0.1910 - val_loss: 2.5806 - val_acc: 0.1755\n",
            "Epoch 29/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.7613 - acc: 0.1900 - val_loss: 2.5744 - val_acc: 0.2041\n",
            "Epoch 30/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.7614 - acc: 0.1777 - val_loss: 2.5674 - val_acc: 0.1878\n",
            "Epoch 31/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.7354 - acc: 0.1920 - val_loss: 2.5811 - val_acc: 0.1673\n",
            "Epoch 32/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.6705 - acc: 0.2339 - val_loss: 2.5626 - val_acc: 0.1878\n",
            "Epoch 33/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.6725 - acc: 0.2135 - val_loss: 2.5625 - val_acc: 0.1755\n",
            "Epoch 34/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.6213 - acc: 0.2411 - val_loss: 2.5610 - val_acc: 0.1551\n",
            "Epoch 35/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.6015 - acc: 0.2462 - val_loss: 2.5440 - val_acc: 0.2041\n",
            "Epoch 36/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.5815 - acc: 0.2390 - val_loss: 2.5578 - val_acc: 0.1673\n",
            "Epoch 37/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.5692 - acc: 0.2594 - val_loss: 2.5525 - val_acc: 0.1796\n",
            "Epoch 38/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.5560 - acc: 0.2492 - val_loss: 2.5517 - val_acc: 0.1673\n",
            "Epoch 39/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.5309 - acc: 0.2676 - val_loss: 2.5436 - val_acc: 0.2082\n",
            "Epoch 40/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.4745 - acc: 0.2993 - val_loss: 2.5318 - val_acc: 0.2245\n",
            "Epoch 41/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.4752 - acc: 0.2717 - val_loss: 2.5303 - val_acc: 0.2163\n",
            "Epoch 42/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.4552 - acc: 0.2850 - val_loss: 2.5404 - val_acc: 0.1755\n",
            "Epoch 43/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.4353 - acc: 0.2983 - val_loss: 2.5191 - val_acc: 0.2122\n",
            "Epoch 44/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.4146 - acc: 0.3034 - val_loss: 2.5242 - val_acc: 0.2000\n",
            "Epoch 45/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.3665 - acc: 0.3309 - val_loss: 2.5265 - val_acc: 0.2082\n",
            "Epoch 46/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.3262 - acc: 0.3453 - val_loss: 2.5536 - val_acc: 0.1755\n",
            "Epoch 47/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.3464 - acc: 0.3371 - val_loss: 2.5428 - val_acc: 0.1796\n",
            "Epoch 48/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.3111 - acc: 0.3555 - val_loss: 2.5251 - val_acc: 0.1796\n",
            "Epoch 49/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.2820 - acc: 0.3524 - val_loss: 2.5146 - val_acc: 0.1959\n",
            "Epoch 50/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.2710 - acc: 0.3677 - val_loss: 2.5216 - val_acc: 0.2163\n",
            "Epoch 51/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.2446 - acc: 0.3728 - val_loss: 2.5126 - val_acc: 0.2245\n",
            "Epoch 52/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.1846 - acc: 0.4035 - val_loss: 2.4975 - val_acc: 0.2204\n",
            "Epoch 53/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.1907 - acc: 0.4014 - val_loss: 2.4948 - val_acc: 0.2082\n",
            "Epoch 54/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.1331 - acc: 0.4505 - val_loss: 2.5132 - val_acc: 0.2082\n",
            "Epoch 55/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.1205 - acc: 0.4454 - val_loss: 2.5007 - val_acc: 0.2163\n",
            "Epoch 56/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.1044 - acc: 0.4597 - val_loss: 2.4854 - val_acc: 0.2245\n",
            "Epoch 57/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.0826 - acc: 0.4831 - val_loss: 2.4836 - val_acc: 0.1959\n",
            "Epoch 58/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.0597 - acc: 0.4729 - val_loss: 2.5154 - val_acc: 0.1878\n",
            "Epoch 59/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.0505 - acc: 0.4484 - val_loss: 2.4923 - val_acc: 0.2000\n",
            "Epoch 60/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 2.0233 - acc: 0.4699 - val_loss: 2.4824 - val_acc: 0.2082\n",
            "Epoch 61/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.9864 - acc: 0.4985 - val_loss: 2.4647 - val_acc: 0.2245\n",
            "Epoch 62/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.9661 - acc: 0.5169 - val_loss: 2.4639 - val_acc: 0.2408\n",
            "Epoch 63/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.9551 - acc: 0.5087 - val_loss: 2.4742 - val_acc: 0.2163\n",
            "Epoch 64/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.9117 - acc: 0.5342 - val_loss: 2.4971 - val_acc: 0.2082\n",
            "Epoch 65/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.8831 - acc: 0.5495 - val_loss: 2.4837 - val_acc: 0.2082\n",
            "Epoch 66/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.9013 - acc: 0.5220 - val_loss: 2.4727 - val_acc: 0.2245\n",
            "Epoch 67/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.8395 - acc: 0.5781 - val_loss: 2.4741 - val_acc: 0.2245\n",
            "Epoch 68/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.8192 - acc: 0.5955 - val_loss: 2.4714 - val_acc: 0.2122\n",
            "Epoch 69/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.7990 - acc: 0.5863 - val_loss: 2.4485 - val_acc: 0.2408\n",
            "Epoch 70/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.7651 - acc: 0.5975 - val_loss: 2.4752 - val_acc: 0.2000\n",
            "Epoch 71/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.7856 - acc: 0.5935 - val_loss: 2.4782 - val_acc: 0.2041\n",
            "Epoch 72/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.7607 - acc: 0.5945 - val_loss: 2.4833 - val_acc: 0.1918\n",
            "Epoch 73/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.7115 - acc: 0.6159 - val_loss: 2.4866 - val_acc: 0.1837\n",
            "Epoch 74/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.6904 - acc: 0.6139 - val_loss: 2.4832 - val_acc: 0.1959\n",
            "Epoch 75/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.6809 - acc: 0.6272 - val_loss: 2.4877 - val_acc: 0.1837\n",
            "Epoch 76/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.6521 - acc: 0.6313 - val_loss: 2.4655 - val_acc: 0.2122\n",
            "Epoch 77/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.6213 - acc: 0.6619 - val_loss: 2.4748 - val_acc: 0.1878\n",
            "Epoch 78/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.6421 - acc: 0.6507 - val_loss: 2.4479 - val_acc: 0.1918\n",
            "Epoch 79/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.5820 - acc: 0.6639 - val_loss: 2.4750 - val_acc: 0.2041\n",
            "Epoch 80/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.5603 - acc: 0.6915 - val_loss: 2.4784 - val_acc: 0.2122\n",
            "Epoch 81/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.5491 - acc: 0.6701 - val_loss: 2.4621 - val_acc: 0.2122\n",
            "Epoch 82/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.5167 - acc: 0.6925 - val_loss: 2.4727 - val_acc: 0.2082\n",
            "Epoch 83/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.5243 - acc: 0.6864 - val_loss: 2.4609 - val_acc: 0.2082\n",
            "Epoch 84/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.5109 - acc: 0.6915 - val_loss: 2.4717 - val_acc: 0.2000\n",
            "Epoch 85/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.4774 - acc: 0.7099 - val_loss: 2.4788 - val_acc: 0.1714\n",
            "Epoch 86/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.4674 - acc: 0.7079 - val_loss: 2.4789 - val_acc: 0.1959\n",
            "Epoch 87/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.4216 - acc: 0.7181 - val_loss: 2.4598 - val_acc: 0.1918\n",
            "Epoch 88/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.4295 - acc: 0.7079 - val_loss: 2.4721 - val_acc: 0.1959\n",
            "Epoch 89/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.3671 - acc: 0.7600 - val_loss: 2.4823 - val_acc: 0.1959\n",
            "Epoch 90/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.4148 - acc: 0.7201 - val_loss: 2.4593 - val_acc: 0.2122\n",
            "Epoch 91/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.4116 - acc: 0.7283 - val_loss: 2.4916 - val_acc: 0.1918\n",
            "Epoch 92/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.3650 - acc: 0.7324 - val_loss: 2.4662 - val_acc: 0.1918\n",
            "Epoch 93/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.3724 - acc: 0.7497 - val_loss: 2.4547 - val_acc: 0.2082\n",
            "Epoch 94/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.3068 - acc: 0.7753 - val_loss: 2.4803 - val_acc: 0.2163\n",
            "Epoch 95/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.2964 - acc: 0.7549 - val_loss: 2.4809 - val_acc: 0.2122\n",
            "Epoch 96/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.3297 - acc: 0.7467 - val_loss: 2.4470 - val_acc: 0.2163\n",
            "Epoch 97/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.3050 - acc: 0.7640 - val_loss: 2.4443 - val_acc: 0.1878\n",
            "Epoch 98/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.2799 - acc: 0.7651 - val_loss: 2.4534 - val_acc: 0.2367\n",
            "Epoch 99/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.2852 - acc: 0.7538 - val_loss: 2.4529 - val_acc: 0.2327\n",
            "Epoch 100/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.2859 - acc: 0.7630 - val_loss: 2.4752 - val_acc: 0.2082\n",
            "Epoch 101/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.2609 - acc: 0.7783 - val_loss: 2.4531 - val_acc: 0.2245\n",
            "Epoch 102/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.2412 - acc: 0.7722 - val_loss: 2.4603 - val_acc: 0.2286\n",
            "Epoch 103/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.2277 - acc: 0.7937 - val_loss: 2.4861 - val_acc: 0.1959\n",
            "Epoch 104/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.2166 - acc: 0.7712 - val_loss: 2.4773 - val_acc: 0.2245\n",
            "Epoch 105/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1976 - acc: 0.7886 - val_loss: 2.4440 - val_acc: 0.2122\n",
            "Epoch 106/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1932 - acc: 0.7712 - val_loss: 2.4346 - val_acc: 0.2041\n",
            "Epoch 107/300\n",
            "979/979 [==============================] - 20s 20ms/step - loss: 1.1827 - acc: 0.7998 - val_loss: 2.4698 - val_acc: 0.1918\n",
            "Epoch 108/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1728 - acc: 0.7865 - val_loss: 2.5047 - val_acc: 0.2000\n",
            "Epoch 109/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1881 - acc: 0.7896 - val_loss: 2.4859 - val_acc: 0.2245\n",
            "Epoch 110/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1643 - acc: 0.8039 - val_loss: 2.4760 - val_acc: 0.2122\n",
            "Epoch 111/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.1564 - acc: 0.7978 - val_loss: 2.4541 - val_acc: 0.1959\n",
            "Epoch 112/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.1365 - acc: 0.8008 - val_loss: 2.4687 - val_acc: 0.2000\n",
            "Epoch 113/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1349 - acc: 0.7906 - val_loss: 2.4561 - val_acc: 0.2367\n",
            "Epoch 114/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.1309 - acc: 0.8029 - val_loss: 2.4583 - val_acc: 0.2286\n",
            "Epoch 115/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1230 - acc: 0.7916 - val_loss: 2.4283 - val_acc: 0.2041\n",
            "Epoch 116/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.1349 - acc: 0.7967 - val_loss: 2.4730 - val_acc: 0.2204\n",
            "Epoch 117/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0972 - acc: 0.8039 - val_loss: 2.4371 - val_acc: 0.2286\n",
            "Epoch 118/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0889 - acc: 0.8069 - val_loss: 2.4563 - val_acc: 0.2163\n",
            "Epoch 119/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0632 - acc: 0.8080 - val_loss: 2.4710 - val_acc: 0.2082\n",
            "Epoch 120/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0987 - acc: 0.8029 - val_loss: 2.4760 - val_acc: 0.2204\n",
            "Epoch 121/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0779 - acc: 0.8182 - val_loss: 2.4301 - val_acc: 0.2163\n",
            "Epoch 122/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.1122 - acc: 0.8008 - val_loss: 2.4442 - val_acc: 0.2327\n",
            "Epoch 123/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0673 - acc: 0.8100 - val_loss: 2.4670 - val_acc: 0.2204\n",
            "Epoch 124/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0623 - acc: 0.8223 - val_loss: 2.4748 - val_acc: 0.2122\n",
            "Epoch 125/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0735 - acc: 0.8029 - val_loss: 2.4782 - val_acc: 0.2000\n",
            "Epoch 126/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.0264 - acc: 0.8294 - val_loss: 2.4692 - val_acc: 0.1796\n",
            "Epoch 127/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0536 - acc: 0.8059 - val_loss: 2.4950 - val_acc: 0.2082\n",
            "Epoch 128/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.0161 - acc: 0.8233 - val_loss: 2.4919 - val_acc: 0.1959\n",
            "Epoch 129/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.0170 - acc: 0.8325 - val_loss: 2.4375 - val_acc: 0.2041\n",
            "Epoch 130/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.0263 - acc: 0.8253 - val_loss: 2.4694 - val_acc: 0.2041\n",
            "Epoch 131/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0194 - acc: 0.8315 - val_loss: 2.4541 - val_acc: 0.2245\n",
            "Epoch 132/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0075 - acc: 0.8253 - val_loss: 2.4372 - val_acc: 0.2286\n",
            "Epoch 133/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.9925 - acc: 0.8325 - val_loss: 2.4475 - val_acc: 0.2000\n",
            "Epoch 134/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 1.0058 - acc: 0.8294 - val_loss: 2.5105 - val_acc: 0.2000\n",
            "Epoch 135/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.9930 - acc: 0.8447 - val_loss: 2.4759 - val_acc: 0.2000\n",
            "Epoch 136/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.0009 - acc: 0.8315 - val_loss: 2.5095 - val_acc: 0.1796\n",
            "Epoch 137/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9844 - acc: 0.8488 - val_loss: 2.4646 - val_acc: 0.1959\n",
            "Epoch 138/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.9973 - acc: 0.8315 - val_loss: 2.4165 - val_acc: 0.2327\n",
            "Epoch 139/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 1.0143 - acc: 0.8202 - val_loss: 2.3948 - val_acc: 0.2653\n",
            "Epoch 140/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.9658 - acc: 0.8304 - val_loss: 2.4451 - val_acc: 0.2245\n",
            "Epoch 141/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9193 - acc: 0.8641 - val_loss: 2.4686 - val_acc: 0.1837\n",
            "Epoch 142/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9689 - acc: 0.8355 - val_loss: 2.4549 - val_acc: 0.1878\n",
            "Epoch 143/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9390 - acc: 0.8407 - val_loss: 2.4895 - val_acc: 0.2041\n",
            "Epoch 144/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.9501 - acc: 0.8447 - val_loss: 2.4604 - val_acc: 0.2122\n",
            "Epoch 145/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9252 - acc: 0.8529 - val_loss: 2.4421 - val_acc: 0.2204\n",
            "Epoch 146/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9307 - acc: 0.8498 - val_loss: 2.4446 - val_acc: 0.2122\n",
            "Epoch 147/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9419 - acc: 0.8376 - val_loss: 2.4485 - val_acc: 0.2327\n",
            "Epoch 148/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9002 - acc: 0.8550 - val_loss: 2.4569 - val_acc: 0.2000\n",
            "Epoch 149/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9580 - acc: 0.8355 - val_loss: 2.4444 - val_acc: 0.1918\n",
            "Epoch 150/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9330 - acc: 0.8396 - val_loss: 2.4800 - val_acc: 0.2041\n",
            "Epoch 151/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.8699 - acc: 0.8764 - val_loss: 2.4494 - val_acc: 0.2082\n",
            "Epoch 152/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.8951 - acc: 0.8764 - val_loss: 2.4428 - val_acc: 0.2163\n",
            "Epoch 153/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9030 - acc: 0.8590 - val_loss: 2.4489 - val_acc: 0.2204\n",
            "Epoch 154/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8914 - acc: 0.8488 - val_loss: 2.4287 - val_acc: 0.2245\n",
            "Epoch 155/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8921 - acc: 0.8611 - val_loss: 2.4318 - val_acc: 0.2286\n",
            "Epoch 156/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.9073 - acc: 0.8519 - val_loss: 2.4490 - val_acc: 0.2245\n",
            "Epoch 157/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9410 - acc: 0.8386 - val_loss: 2.4495 - val_acc: 0.2122\n",
            "Epoch 158/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8963 - acc: 0.8550 - val_loss: 2.4564 - val_acc: 0.2327\n",
            "Epoch 159/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8818 - acc: 0.8641 - val_loss: 2.4570 - val_acc: 0.2041\n",
            "Epoch 160/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8511 - acc: 0.8662 - val_loss: 2.4440 - val_acc: 0.2408\n",
            "Epoch 161/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8346 - acc: 0.8621 - val_loss: 2.4650 - val_acc: 0.2367\n",
            "Epoch 162/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8745 - acc: 0.8580 - val_loss: 2.4659 - val_acc: 0.2041\n",
            "Epoch 163/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.8616 - acc: 0.8570 - val_loss: 2.4589 - val_acc: 0.2000\n",
            "Epoch 164/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8378 - acc: 0.8672 - val_loss: 2.4260 - val_acc: 0.2245\n",
            "Epoch 165/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.9114 - acc: 0.8253 - val_loss: 2.4442 - val_acc: 0.1959\n",
            "Epoch 166/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8096 - acc: 0.8744 - val_loss: 2.4392 - val_acc: 0.2245\n",
            "Epoch 167/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8586 - acc: 0.8570 - val_loss: 2.4768 - val_acc: 0.2163\n",
            "Epoch 168/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8453 - acc: 0.8478 - val_loss: 2.4649 - val_acc: 0.2245\n",
            "Epoch 169/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.8229 - acc: 0.8672 - val_loss: 2.4450 - val_acc: 0.2163\n",
            "Epoch 170/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8490 - acc: 0.8590 - val_loss: 2.4669 - val_acc: 0.2122\n",
            "Epoch 171/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8316 - acc: 0.8560 - val_loss: 2.4967 - val_acc: 0.1837\n",
            "Epoch 172/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.8330 - acc: 0.8723 - val_loss: 2.4690 - val_acc: 0.2245\n",
            "Epoch 173/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7966 - acc: 0.8795 - val_loss: 2.4834 - val_acc: 0.1918\n",
            "Epoch 174/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.8662 - acc: 0.8509 - val_loss: 2.4871 - val_acc: 0.2041\n",
            "Epoch 175/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.7996 - acc: 0.8836 - val_loss: 2.4675 - val_acc: 0.2082\n",
            "Epoch 176/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.8193 - acc: 0.8621 - val_loss: 2.4454 - val_acc: 0.2041\n",
            "Epoch 177/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7933 - acc: 0.8774 - val_loss: 2.4454 - val_acc: 0.2204\n",
            "Epoch 178/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.7488 - acc: 0.8907 - val_loss: 2.4548 - val_acc: 0.2245\n",
            "Epoch 179/300\n",
            "979/979 [==============================] - 19s 19ms/step - loss: 0.7643 - acc: 0.8754 - val_loss: 2.4395 - val_acc: 0.2163\n",
            "Epoch 180/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7698 - acc: 0.8866 - val_loss: 2.4565 - val_acc: 0.2000\n",
            "Epoch 181/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.8224 - acc: 0.8519 - val_loss: 2.4528 - val_acc: 0.2286\n",
            "Epoch 182/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7369 - acc: 0.9030 - val_loss: 2.4825 - val_acc: 0.2204\n",
            "Epoch 183/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7741 - acc: 0.8917 - val_loss: 2.4726 - val_acc: 0.2245\n",
            "Epoch 184/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7711 - acc: 0.8836 - val_loss: 2.4660 - val_acc: 0.1918\n",
            "Epoch 185/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7774 - acc: 0.8836 - val_loss: 2.5079 - val_acc: 0.2122\n",
            "Epoch 186/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7795 - acc: 0.8693 - val_loss: 2.5116 - val_acc: 0.1918\n",
            "Epoch 187/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7811 - acc: 0.8713 - val_loss: 2.5099 - val_acc: 0.1837\n",
            "Epoch 188/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7831 - acc: 0.8744 - val_loss: 2.4894 - val_acc: 0.2163\n",
            "Epoch 189/300\n",
            "979/979 [==============================] - 19s 20ms/step - loss: 0.7981 - acc: 0.8682 - val_loss: 2.5117 - val_acc: 0.1878\n",
            "Epoch 190/300\n",
            "480/979 [=============>................] - ETA: 9s - loss: 0.7476 - acc: 0.8875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-56c8b5f83ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# 実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# 予測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVeZqOWwExY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "clf_rf = RandomForestClassifier()\n",
        "clf_rf.fit(X_train, y_train)\n",
        "y_pred = clf_rf.predict(X_test)\n",
        "\n",
        "accu = accuracy_score(y_test, y_pred)\n",
        "print('accuracy = {:>.4f}'.format(accu))\n",
        "\n",
        "# Feature Importance\n",
        "fti = clf_rf.feature_importances_   \n",
        "\n",
        "print('Feature Importances:')\n",
        "for i, feat in enumerate(X['feature_names']):\n",
        "    print('\\t{0:20s} : {1:>.6f}'.format(feat, fti[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWICXq3bdUoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# あとで株分けする\n",
        "# 月星座\n",
        "\n",
        "# 月星座のもとデータをDataFrame形式に変換\n",
        "df_moon = pd.read_csv(\"moon_test.csv\", encoding=\"shift-jis\", engine = \"python\")\n",
        "\n",
        "# df_moonの行数をカウント\n",
        "loop_count = len(df_moon) - 1\n",
        "\n",
        "# 空のDataFrame作成\n",
        "df_moon_supplement_tmp = pd.DataFrame()\n",
        "df_moon_supplement =  pd.DataFrame()\n",
        "\n",
        "# df_moonは全年月日の情報が入っていないため、情報を補う必要がある。\n",
        "# df_moonの各行で存在しない日付け分のデータを追加する。\n",
        "# 追加するときのデータのうち、星座については、前日の情報を追加する。\n",
        "\n",
        "for i in range(0, loop_count):\n",
        "  hoge = df_moon.iloc[i,0]\n",
        "  year = df_moon.iloc[i,1]\n",
        "  month = df_moon.iloc[i,2]\n",
        "  day = df_moon.iloc[i,3]\n",
        "  constallation = df_moon.iloc[i,4]\n",
        "  next_year = df_moon.iloc[i+1,1]\n",
        "  next_month = df_moon.iloc[i+1,2]\n",
        "  next_day = df_moon.iloc[i+1,3]\n",
        "  \n",
        "  if month == 2:\n",
        "    if year % 4 == 0:\n",
        "      end_of_month = 29\n",
        "    else:\n",
        "      end_of_month = 28\n",
        "  elif month == 4 or 6 or 9 or 11:\n",
        "    end_of_month = 30\n",
        "  else:\n",
        "    end_of_month = 31\n",
        "  \n",
        "  while (day + 1 < next_day and day + 1 <= end_of_month):\n",
        "    day += 1\n",
        "    df_moon_supplement_tmp = pd.DataFrame([[hoge,year,month,day,constallation]])\n",
        "    df_moon_supplement =  pd.concat([df_moon_supplement, df_moon_supplement_tmp], axis = 0)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAXLW8NHgPW7",
        "colab_type": "code",
        "outputId": "a774733f-1367-4654-b112-6b7d976f5419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "df_moon_supplement.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月04日23時13分〜 射手座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>射手座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月04日23時13分〜 射手座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>射手座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月07日10時43分〜 山羊座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>山羊座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月09日20時13分〜 水瓶座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>水瓶座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月09日20時13分〜 水瓶座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>水瓶座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月12日03時44分〜 魚座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>魚座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月14日09時23分〜 牡羊座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>牡羊座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月16日13時13分〜 牡牛座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>牡牛座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月18日15時30分〜 双子座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>双子座</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008年01月20日17時05分〜 蟹座</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>蟹座</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         0     1  2   3    4\n",
              "0  2008年01月04日23時13分〜 射手座   2008  1   5  射手座\n",
              "0  2008年01月04日23時13分〜 射手座   2008  1   6  射手座\n",
              "0  2008年01月07日10時43分〜 山羊座   2008  1   8  山羊座\n",
              "0  2008年01月09日20時13分〜 水瓶座   2008  1  10  水瓶座\n",
              "0  2008年01月09日20時13分〜 水瓶座   2008  1  11  水瓶座\n",
              "0   2008年01月12日03時44分〜 魚座   2008  1  13   魚座\n",
              "0  2008年01月14日09時23分〜 牡羊座   2008  1  15  牡羊座\n",
              "0  2008年01月16日13時13分〜 牡牛座   2008  1  17  牡牛座\n",
              "0  2008年01月18日15時30分〜 双子座   2008  1  19  双子座\n",
              "0   2008年01月20日17時05分〜 蟹座   2008  1  21   蟹座"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwz-gTndkxZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_moon_supplement.to_csv('/content/drive/My Drive/df_moon_supplement.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uToJ3uCYn9fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}